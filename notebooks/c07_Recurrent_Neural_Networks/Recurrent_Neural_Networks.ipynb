{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iALm8shtXMVK"
   },
   "source": [
    "# Recurrent Neural Networks: A Case study in well logs and LSTM's\n",
    "\n",
    "All the models we have discussed so far were looking at the inputs as isolated instances. But there are many cases were datapoints are not isolated instances and have connection to each other. *Sequential data* are the type of data where each instance is related to the instances came before. \n",
    "\n",
    "A good example for this type of data is time series data. At each point in time to the value of the time series depends on the value of the prior points. Another example is depth data, like well logs.\n",
    "\n",
    "Recurrent Neural Networks (RNN) are a class of networks which deal with sequential data. There are many variants of Recurrent Neural Networks, including:\n",
    "\n",
    "- Simple Recurrect Neural Networks (Simple RNN - or often just called RNN)\n",
    "- Gated Recurrent Unit (GRU)\n",
    "- **Long Short-Term Memory (LSTM)**\n",
    "\n",
    "In this notebook we will discuss LSTM; however, the general logic behind all these methods are the same. They only differ in the way they handle information internally. \n",
    "\n",
    "\n",
    "RNN's have been used for\n",
    "- translation\n",
    "- drawing chinese charectors\n",
    "- composing music\n",
    "- timeseries\n",
    "- depth\n",
    "- weather\n",
    "- many more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T01:56:58.434163Z",
     "start_time": "2020-10-05T01:54:05.428Z"
    }
   },
   "source": [
    "## A minute of Theory\n",
    "\n",
    "This is a hand on course, not theory so we will look at a high level view of one type of RNN, the LSTM. But lets look at the theory for a moment, to get some broad idea of how they work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below is from d2l.ai and shows how an RNN can operate on a text sequence to predict the next charector.\n",
    "\n",
    "![](images/rnn-train.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T02:02:23.588495Z",
     "start_time": "2020-10-05T02:02:23.566945Z"
    }
   },
   "source": [
    "How does the model itself work? Let look at an excerpt from the open source machine learning book [d2l.ai](d2l.ai):\n",
    "\n",
    "![](images/rnn.svg)\n",
    "\n",
    "> The figure below illustrates the computational logic of an RNN at three adjacent time steps. At any time step `t`, the computation of the hidden state can be treated as: \n",
    "\n",
    "> i) concatenating the input `Xt` at the current time step `t` and the hidden state `Ht−1` at the previous time step  `t−1` ; \n",
    "\n",
    "> ii) feeding the concatenation result into a fully-connected layer with the activation function `ϕ`. \n",
    "\n",
    "> The output of such a fully-connected layer is the hidden state  `Ht`  of the current time step  t . In this case, the model parameters are the concatenation of  `Wxh`  and  `Whh` , and a bias of  `bh`. The hidden state of the current time step  `t` , `Ht` , will participate in computing the hidden state  `Ht+1`  of the next time step  t+1 . What is more,  `Ht`  will also be fed into the fully-connected output layer to compute the output  `Ot`  of the current time step  `t` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T04:25:13.829839Z",
     "start_time": "2020-10-05T04:25:13.821494Z"
    }
   },
   "source": [
    "To understand more see these visualisations:\n",
    "\n",
    "- [distill.pub memorization in rnns](memorization-in-rnns)\n",
    "- [Chris Olah Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "\n",
    "And see these chapters:\n",
    "\n",
    "- [d2l.ai RNN's](http://d2l.ai/chapter_recurrent-neural-networks/rnn.html)\n",
    "- [d2l.ai LSTM's](http://d2l.ai/chapter_recurrent-modern/lstm.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands on example with well logs\n",
    "\n",
    "You can read more [here](http://d2l.ai/chapter_recurrent-neural-networks/rnn.html), but lets dive into a hand on example first and it will begin to make more sense. We will be focusing on\n",
    "\n",
    "- How do RNN's represent data\n",
    "- How do we implement them in pytorch\n",
    "- What are the key parameters and example values\n",
    "- Where might you use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:18.221104Z",
     "start_time": "2020-10-05T06:44:16.388824Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T01:33:08.720455Z",
     "start_time": "2020-09-27T01:33:08.715754Z"
    }
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low level\n",
    "\n",
    "[LSTMCell docs](https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html)\n",
    "\n",
    "Lets look at a low level implementation, and compare it to the figure we previously saw\n",
    "\n",
    "![](images/rnn.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:18.491860Z",
     "start_time": "2020-10-05T06:44:18.223526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  7,  8,  9,  5,  0,  1,  5,  3, 10,  9,  8,  9,  6])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Our input text\n",
    "text = list(\"\"\"Machine Learning\"\"\")\n",
    "e = LabelEncoder()\n",
    "input = e.fit_transform(text)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:18.519210Z",
     "start_time": "2020-10-05T06:44:18.494569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>char</th>\n",
       "      <td>M</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>L</td>\n",
       "      <td>e</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4  5  6  7  8  9  10  11 12 13 14 15\n",
       "char  M  a  c  h  i  n  e     L  e  a   r  n  i  n  g\n",
       "int   2  3  4  7  8  9  5  0  1  5  3  10  9  8  9  6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize it\n",
    "pd.DataFrame(list(zip(text, input)), columns=['char', 'int']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:18.533470Z",
     "start_time": "2020-10-05T06:44:18.521627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 20])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the low level LSTM Cell\n",
    "rnn = nn.LSTMCell(input_size=1, hidden_size=20)\n",
    "\n",
    "# Input [Sequence Length=6, BatchSize=1, input_size=1]\n",
    "input = torch.from_numpy(input)[:, None, None].float()\n",
    "\n",
    "# Initial states (Batch size, Hidden Size)\n",
    "hx = torch.randn(1, 20) # Initial hidden\n",
    "cx = torch.randn(1, 20) # Initial cell\n",
    "\n",
    "output = []\n",
    "# we manually call it on each part of the sequence\n",
    "for i in range(6):\n",
    "    # We manually handle states\n",
    "    hx, cx = rnn(input[i], (hx, cx))\n",
    "    output.append(hx)\n",
    "    \n",
    "# Seqence, Batch, Hidden size\n",
    "output = torch.stack(output)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:18.549072Z",
     "start_time": "2020-10-05T06:44:18.535697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LSTMCell in module torch.nn.modules.rnn:\n",
      "\n",
      "class LSTMCell(RNNCellBase)\n",
      " |  LSTMCell(input_size: int, hidden_size: int, bias: bool = True) -> None\n",
      " |  \n",
      " |  A long short-term memory (LSTM) cell.\n",
      " |  \n",
      " |  .. math::\n",
      " |  \n",
      " |      \\begin{array}{ll}\n",
      " |      i = \\sigma(W_{ii} x + b_{ii} + W_{hi} h + b_{hi}) \\\\\n",
      " |      f = \\sigma(W_{if} x + b_{if} + W_{hf} h + b_{hf}) \\\\\n",
      " |      g = \\tanh(W_{ig} x + b_{ig} + W_{hg} h + b_{hg}) \\\\\n",
      " |      o = \\sigma(W_{io} x + b_{io} + W_{ho} h + b_{ho}) \\\\\n",
      " |      c' = f * c + i * g \\\\\n",
      " |      h' = o * \\tanh(c') \\\\\n",
      " |      \\end{array}\n",
      " |  \n",
      " |  where :math:`\\sigma` is the sigmoid function, and :math:`*` is the Hadamard product.\n",
      " |  \n",
      " |  Args:\n",
      " |      input_size: The number of expected features in the input `x`\n",
      " |      hidden_size: The number of features in the hidden state `h`\n",
      " |      bias: If ``False``, then the layer does not use bias weights `b_ih` and\n",
      " |          `b_hh`. Default: ``True``\n",
      " |  \n",
      " |  Inputs: input, (h_0, c_0)\n",
      " |      - **input** of shape `(batch, input_size)`: tensor containing input features\n",
      " |      - **h_0** of shape `(batch, hidden_size)`: tensor containing the initial hidden\n",
      " |        state for each element in the batch.\n",
      " |      - **c_0** of shape `(batch, hidden_size)`: tensor containing the initial cell state\n",
      " |        for each element in the batch.\n",
      " |  \n",
      " |        If `(h_0, c_0)` is not provided, both **h_0** and **c_0** default to zero.\n",
      " |  \n",
      " |  Outputs: (h_1, c_1)\n",
      " |      - **h_1** of shape `(batch, hidden_size)`: tensor containing the next hidden state\n",
      " |        for each element in the batch\n",
      " |      - **c_1** of shape `(batch, hidden_size)`: tensor containing the next cell state\n",
      " |        for each element in the batch\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight_ih: the learnable input-hidden weights, of shape\n",
      " |          `(4*hidden_size, input_size)`\n",
      " |      weight_hh: the learnable hidden-hidden weights, of shape\n",
      " |          `(4*hidden_size, hidden_size)`\n",
      " |      bias_ih: the learnable input-hidden bias, of shape `(4*hidden_size)`\n",
      " |      bias_hh: the learnable hidden-hidden bias, of shape `(4*hidden_size)`\n",
      " |  \n",
      " |  .. note::\n",
      " |      All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
      " |      where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> rnn = nn.LSTMCell(10, 20)\n",
      " |      >>> input = torch.randn(6, 3, 10)\n",
      " |      >>> hx = torch.randn(3, 20)\n",
      " |      >>> cx = torch.randn(3, 20)\n",
      " |      >>> output = []\n",
      " |      >>> for i in range(6):\n",
      " |              hx, cx = rnn(input[i], (hx, cx))\n",
      " |              output.append(hx)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LSTMCell\n",
      " |      RNNCellBase\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_size: int, hidden_size: int, bias: bool = True) -> None\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  forward(self, input: torch.Tensor, hx: Union[Tuple[torch.Tensor, torch.Tensor], NoneType] = None) -> Tuple[torch.Tensor, torch.Tensor]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RNNCellBase:\n",
      " |  \n",
      " |  check_forward_hidden(self, input: torch.Tensor, hx: torch.Tensor, hidden_label: str = '') -> None\n",
      " |  \n",
      " |  check_forward_input(self, input: torch.Tensor) -> None\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should reimplement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  reset_parameters(self) -> None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from RNNCellBase:\n",
      " |  \n",
      " |  __annotations__ = {'bias': <class 'bool'>, 'hidden_size': <class 'int'...\n",
      " |  \n",
      " |  __constants__ = ['input_size', 'hidden_size', 'bias']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name: str, module: 'Module') -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Dict[str, torch.Tensor], strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Union[Set[ForwardRef('Module')], NoneType] = None, prefix: str = '')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |      \n",
      " |          The current implementation will not have the presented behavior\n",
      " |          for complex :class:`Module` that perform many operations.\n",
      " |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n",
      " |          contain the gradients for a subset of the inputs and outputs.\n",
      " |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n",
      " |          directly on a specific input or output to get the required gradients.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: torch.Tensor, persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: torch.nn.parameter.Parameter) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
      " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self) -> None\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As always you can read more about an LSTMCell in the help or docs\n",
    "help(nn.LSTMCell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High level\n",
    "\n",
    "Or we can use the high level API that handles it for you\n",
    "\n",
    "[LSTMdocs](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:18.565942Z",
     "start_time": "2020-10-05T06:44:18.551675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LSTM in module torch.nn.modules.rnn:\n",
      "\n",
      "class LSTM(RNNBase)\n",
      " |  LSTM(*args, **kwargs)\n",
      " |  \n",
      " |  Applies a multi-layer long short-term memory (LSTM) RNN to an input\n",
      " |  sequence.\n",
      " |  \n",
      " |  \n",
      " |  For each element in the input sequence, each layer computes the following\n",
      " |  function:\n",
      " |  \n",
      " |  .. math::\n",
      " |      \\begin{array}{ll} \\\\\n",
      " |          i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n",
      " |          f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n",
      " |          g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\\\n",
      " |          o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n",
      " |          c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n",
      " |          h_t = o_t \\odot \\tanh(c_t) \\\\\n",
      " |      \\end{array}\n",
      " |  \n",
      " |  where :math:`h_t` is the hidden state at time `t`, :math:`c_t` is the cell\n",
      " |  state at time `t`, :math:`x_t` is the input at time `t`, :math:`h_{t-1}`\n",
      " |  is the hidden state of the layer at time `t-1` or the initial hidden\n",
      " |  state at time `0`, and :math:`i_t`, :math:`f_t`, :math:`g_t`,\n",
      " |  :math:`o_t` are the input, forget, cell, and output gates, respectively.\n",
      " |  :math:`\\sigma` is the sigmoid function, and :math:`\\odot` is the Hadamard product.\n",
      " |  \n",
      " |  In a multilayer LSTM, the input :math:`x^{(l)}_t` of the :math:`l` -th layer\n",
      " |  (:math:`l >= 2`) is the hidden state :math:`h^{(l-1)}_t` of the previous layer multiplied by\n",
      " |  dropout :math:`\\delta^{(l-1)}_t` where each :math:`\\delta^{(l-1)}_t` is a Bernoulli random\n",
      " |  variable which is :math:`0` with probability :attr:`dropout`.\n",
      " |  \n",
      " |  Args:\n",
      " |      input_size: The number of expected features in the input `x`\n",
      " |      hidden_size: The number of features in the hidden state `h`\n",
      " |      num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
      " |          would mean stacking two LSTMs together to form a `stacked LSTM`,\n",
      " |          with the second LSTM taking in outputs of the first LSTM and\n",
      " |          computing the final results. Default: 1\n",
      " |      bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
      " |          Default: ``True``\n",
      " |      batch_first: If ``True``, then the input and output tensors are provided\n",
      " |          as (batch, seq, feature). Default: ``False``\n",
      " |      dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n",
      " |          LSTM layer except the last layer, with dropout probability equal to\n",
      " |          :attr:`dropout`. Default: 0\n",
      " |      bidirectional: If ``True``, becomes a bidirectional LSTM. Default: ``False``\n",
      " |  \n",
      " |  Inputs: input, (h_0, c_0)\n",
      " |      - **input** of shape `(seq_len, batch, input_size)`: tensor containing the features\n",
      " |        of the input sequence.\n",
      " |        The input can also be a packed variable length sequence.\n",
      " |        See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n",
      " |        :func:`torch.nn.utils.rnn.pack_sequence` for details.\n",
      " |      - **h_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
      " |        containing the initial hidden state for each element in the batch.\n",
      " |        If the LSTM is bidirectional, num_directions should be 2, else it should be 1.\n",
      " |      - **c_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
      " |        containing the initial cell state for each element in the batch.\n",
      " |  \n",
      " |        If `(h_0, c_0)` is not provided, both **h_0** and **c_0** default to zero.\n",
      " |  \n",
      " |  \n",
      " |  Outputs: output, (h_n, c_n)\n",
      " |      - **output** of shape `(seq_len, batch, num_directions * hidden_size)`: tensor\n",
      " |        containing the output features `(h_t)` from the last layer of the LSTM,\n",
      " |        for each `t`. If a :class:`torch.nn.utils.rnn.PackedSequence` has been\n",
      " |        given as the input, the output will also be a packed sequence.\n",
      " |  \n",
      " |        For the unpacked case, the directions can be separated\n",
      " |        using ``output.view(seq_len, batch, num_directions, hidden_size)``,\n",
      " |        with forward and backward being direction `0` and `1` respectively.\n",
      " |        Similarly, the directions can be separated in the packed case.\n",
      " |      - **h_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
      " |        containing the hidden state for `t = seq_len`.\n",
      " |  \n",
      " |        Like *output*, the layers can be separated using\n",
      " |        ``h_n.view(num_layers, num_directions, batch, hidden_size)`` and similarly for *c_n*.\n",
      " |      - **c_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
      " |        containing the cell state for `t = seq_len`.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight_ih_l[k] : the learnable input-hidden weights of the :math:`\\text{k}^{th}` layer\n",
      " |          `(W_ii|W_if|W_ig|W_io)`, of shape `(4*hidden_size, input_size)` for `k = 0`.\n",
      " |          Otherwise, the shape is `(4*hidden_size, num_directions * hidden_size)`\n",
      " |      weight_hh_l[k] : the learnable hidden-hidden weights of the :math:`\\text{k}^{th}` layer\n",
      " |          `(W_hi|W_hf|W_hg|W_ho)`, of shape `(4*hidden_size, hidden_size)`\n",
      " |      bias_ih_l[k] : the learnable input-hidden bias of the :math:`\\text{k}^{th}` layer\n",
      " |          `(b_ii|b_if|b_ig|b_io)`, of shape `(4*hidden_size)`\n",
      " |      bias_hh_l[k] : the learnable hidden-hidden bias of the :math:`\\text{k}^{th}` layer\n",
      " |          `(b_hi|b_hf|b_hg|b_ho)`, of shape `(4*hidden_size)`\n",
      " |  \n",
      " |  .. note::\n",
      " |      All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
      " |      where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
      " |  \n",
      " |  .. include:: ../cudnn_persistent_rnn.rst\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> rnn = nn.LSTM(10, 20, 2)\n",
      " |      >>> input = torch.randn(5, 3, 10)\n",
      " |      >>> h0 = torch.randn(2, 3, 20)\n",
      " |      >>> c0 = torch.randn(2, 3, 20)\n",
      " |      >>> output, (hn, cn) = rnn(input, (h0, c0))\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LSTM\n",
      " |      RNNBase\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  check_forward_args(self, input: torch.Tensor, hidden: Tuple[torch.Tensor, torch.Tensor], batch_sizes: Union[torch.Tensor, NoneType])\n",
      " |  \n",
      " |  forward(self, input, hx=None)\n",
      " |  \n",
      " |  permute_hidden(self, hx: Tuple[torch.Tensor, torch.Tensor], permutation: Union[torch.Tensor, NoneType]) -> Tuple[torch.Tensor, torch.Tensor]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RNNBase:\n",
      " |  \n",
      " |  __setattr__(self, attr, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, d)\n",
      " |  \n",
      " |  check_hidden_size(self, hx: torch.Tensor, expected_hidden_size: Tuple[int, int, int], msg: str = 'Expected hidden size {}, got {}') -> None\n",
      " |  \n",
      " |  check_input(self, input: torch.Tensor, batch_sizes: Union[torch.Tensor, NoneType]) -> None\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should reimplement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  flatten_parameters(self) -> None\n",
      " |      Resets parameter data pointer so that they can use faster code paths.\n",
      " |      \n",
      " |      Right now, this works only if the module is on the GPU and cuDNN is enabled.\n",
      " |      Otherwise, it's a no-op.\n",
      " |  \n",
      " |  get_expected_hidden_size(self, input: torch.Tensor, batch_sizes: Union[torch.Tensor, NoneType]) -> Tuple[int, int, int]\n",
      " |  \n",
      " |  reset_parameters(self) -> None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from RNNBase:\n",
      " |  \n",
      " |  all_weights\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from RNNBase:\n",
      " |  \n",
      " |  __annotations__ = {'batch_first': <class 'bool'>, 'bias': <class 'bool...\n",
      " |  \n",
      " |  __constants__ = ['mode', 'input_size', 'hidden_size', 'num_layers', 'b...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  add_module(self, name: str, module: 'Module') -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Dict[str, torch.Tensor], strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Union[Set[ForwardRef('Module')], NoneType] = None, prefix: str = '')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |      \n",
      " |          The current implementation will not have the presented behavior\n",
      " |          for complex :class:`Module` that perform many operations.\n",
      " |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n",
      " |          contain the gradients for a subset of the inputs and outputs.\n",
      " |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n",
      " |          directly on a specific input or output to get the required gradients.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: torch.Tensor, persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: torch.nn.parameter.Parameter) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
      " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self) -> None\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:18.575916Z",
     "start_time": "2020-10-05T06:44:18.568615Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        # Params\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        # High level LSTM library, nn.LSTMCell is a lower level one\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        \n",
    "        # Final layer\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.shape[1]\n",
    "        \n",
    "        output, (_, _) = self.lstm(x)\n",
    "        h = output.view(-1, seq_len, self.hidden_size)[:, -1]\n",
    "        \n",
    "        return self.linear(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vaL6j3pkCen3"
   },
   "source": [
    "## The well log classification problem \n",
    "\n",
    "In this scenario we are drilling downwards, and while well logs are reported instantly, there is a lag in facies of around 15 meter (see diagram), while they are interpreated by a petrophysicist. The problem is we would like to know the facies as soon as possible in order decide if, how, and where to drill.\n",
    "\n",
    "Lets apply machine learning. There are many ways to set up this problem, and geology is especially hard due to the important of context and the amount of undigitized information (much of it is in the brain of old and grizzled geologists).\n",
    "\n",
    "In this scenario we will apply an RNN. \n",
    "- It will travel down the well\n",
    "- Input are \n",
    "    - the last 200 meters of well logs \n",
    "    - and the geologist facies interpreation up to 15 meters ago\n",
    "- The label is the facies at the point in the well\n",
    "\n",
    "\n",
    "You may ask: \"Isn't it cheating? Because it knows the human labels from 15 meters above?\" \n",
    "\n",
    "We measure this and it gives a ~60% accuracy. So this is the naive baseline that we have to beat.\n",
    "\n",
    "<img src=\"images/diagram.png\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:18.619230Z",
     "start_time": "2020-10-05T06:44:18.580993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context length of 60.0 m or 400 intervals\n",
      "model can see human labels up to 15.0m above. Or 100 intervals\n"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "shift_length = 100\n",
    "seq_length = 400\n",
    "max_lithologies = 12\n",
    "max_wells = 20\n",
    "\n",
    "\n",
    "print(f'context length of {0.15*seq_length} m or {seq_length} intervals')\n",
    "print(f'model can see human labels up to {shift_length*0.15}m above. Or {shift_length} intervals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzlqXAj4EIBN"
   },
   "source": [
    "In this example we are going to look at well logs which are sequential data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:23.755692Z",
     "start_time": "2020-10-05T06:44:18.621880Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "uNl846nE-jjq",
    "lines_to_next_cell": 0,
    "outputId": "de7b4197-6a3f-4e88-e07e-2463adba90d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CALI</th>\n",
       "      <th>DTC</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>LITHOLOGY_GEOLINK</th>\n",
       "      <th>RDEP</th>\n",
       "      <th>RHOB</th>\n",
       "      <th>RMED</th>\n",
       "      <th>split</th>\n",
       "      <th>wlbCompletionDate</th>\n",
       "      <th>wlbCompletionYear</th>\n",
       "      <th>wlbKellyBushElevation</th>\n",
       "      <th>wlbTotalDepth</th>\n",
       "      <th>xc</th>\n",
       "      <th>yc</th>\n",
       "      <th>Well</th>\n",
       "      <th>DEPT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Well</th>\n",
       "      <th>DEPT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">30_11-3</th>\n",
       "      <th>2118.60</th>\n",
       "      <td>12.435000</td>\n",
       "      <td>109.432205</td>\n",
       "      <td>2118.744629</td>\n",
       "      <td>62.438549</td>\n",
       "      <td>Silt</td>\n",
       "      <td>1.321802</td>\n",
       "      <td>2.305019</td>\n",
       "      <td>1.439</td>\n",
       "      <td>train</td>\n",
       "      <td>1983-03-14T00:00:00</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4662.0</td>\n",
       "      <td>2.537631</td>\n",
       "      <td>60.044053</td>\n",
       "      <td>30_11-3</td>\n",
       "      <td>2118.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118.75</th>\n",
       "      <td>12.435000</td>\n",
       "      <td>109.432205</td>\n",
       "      <td>2118.744629</td>\n",
       "      <td>62.438549</td>\n",
       "      <td>Silt</td>\n",
       "      <td>1.321802</td>\n",
       "      <td>2.305019</td>\n",
       "      <td>1.439</td>\n",
       "      <td>train</td>\n",
       "      <td>1983-03-14T00:00:00</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4662.0</td>\n",
       "      <td>2.537631</td>\n",
       "      <td>60.044053</td>\n",
       "      <td>30_11-3</td>\n",
       "      <td>2118.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118.90</th>\n",
       "      <td>12.584001</td>\n",
       "      <td>102.456642</td>\n",
       "      <td>2118.896973</td>\n",
       "      <td>61.501503</td>\n",
       "      <td>Silt</td>\n",
       "      <td>1.478748</td>\n",
       "      <td>2.317000</td>\n",
       "      <td>1.439</td>\n",
       "      <td>train</td>\n",
       "      <td>1983-03-14T00:00:00</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4662.0</td>\n",
       "      <td>2.537631</td>\n",
       "      <td>60.044053</td>\n",
       "      <td>30_11-3</td>\n",
       "      <td>2118.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119.05</th>\n",
       "      <td>12.606000</td>\n",
       "      <td>95.108009</td>\n",
       "      <td>2119.049561</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>Silt</td>\n",
       "      <td>1.553000</td>\n",
       "      <td>2.327976</td>\n",
       "      <td>1.534</td>\n",
       "      <td>train</td>\n",
       "      <td>1983-03-14T00:00:00</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4662.0</td>\n",
       "      <td>2.537631</td>\n",
       "      <td>60.044053</td>\n",
       "      <td>30_11-3</td>\n",
       "      <td>2119.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119.20</th>\n",
       "      <td>12.391000</td>\n",
       "      <td>99.642990</td>\n",
       "      <td>2119.201904</td>\n",
       "      <td>61.905998</td>\n",
       "      <td>Silt</td>\n",
       "      <td>1.512000</td>\n",
       "      <td>2.312981</td>\n",
       "      <td>1.777</td>\n",
       "      <td>train</td>\n",
       "      <td>1983-03-14T00:00:00</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4662.0</td>\n",
       "      <td>2.537631</td>\n",
       "      <td>60.044053</td>\n",
       "      <td>30_11-3</td>\n",
       "      <td>2119.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">30_7-7</th>\n",
       "      <th>5022.15</th>\n",
       "      <td>5.961000</td>\n",
       "      <td>81.231377</td>\n",
       "      <td>5022.173828</td>\n",
       "      <td>59.574780</td>\n",
       "      <td>Silt</td>\n",
       "      <td>2.438013</td>\n",
       "      <td>2.455000</td>\n",
       "      <td>2.889</td>\n",
       "      <td>train</td>\n",
       "      <td>1979-01-07T00:00:00</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5127.0</td>\n",
       "      <td>2.268694</td>\n",
       "      <td>60.272028</td>\n",
       "      <td>30_7-7</td>\n",
       "      <td>5022.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022.30</th>\n",
       "      <td>5.941000</td>\n",
       "      <td>81.126503</td>\n",
       "      <td>5022.326660</td>\n",
       "      <td>60.271767</td>\n",
       "      <td>Silt</td>\n",
       "      <td>2.438000</td>\n",
       "      <td>2.463000</td>\n",
       "      <td>2.818</td>\n",
       "      <td>train</td>\n",
       "      <td>1979-01-07T00:00:00</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5127.0</td>\n",
       "      <td>2.268694</td>\n",
       "      <td>60.272028</td>\n",
       "      <td>30_7-7</td>\n",
       "      <td>5022.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022.45</th>\n",
       "      <td>5.887000</td>\n",
       "      <td>80.289490</td>\n",
       "      <td>5022.479004</td>\n",
       "      <td>59.796532</td>\n",
       "      <td>Silt</td>\n",
       "      <td>2.461923</td>\n",
       "      <td>2.455000</td>\n",
       "      <td>2.796</td>\n",
       "      <td>train</td>\n",
       "      <td>1979-01-07T00:00:00</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5127.0</td>\n",
       "      <td>2.268694</td>\n",
       "      <td>60.272028</td>\n",
       "      <td>30_7-7</td>\n",
       "      <td>5022.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022.60</th>\n",
       "      <td>5.902000</td>\n",
       "      <td>78.824585</td>\n",
       "      <td>5022.631348</td>\n",
       "      <td>55.645344</td>\n",
       "      <td>Silt</td>\n",
       "      <td>2.503865</td>\n",
       "      <td>2.465000</td>\n",
       "      <td>2.774</td>\n",
       "      <td>train</td>\n",
       "      <td>1979-01-07T00:00:00</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5127.0</td>\n",
       "      <td>2.268694</td>\n",
       "      <td>60.272028</td>\n",
       "      <td>30_7-7</td>\n",
       "      <td>5022.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022.75</th>\n",
       "      <td>5.902000</td>\n",
       "      <td>78.824585</td>\n",
       "      <td>5022.631348</td>\n",
       "      <td>55.645344</td>\n",
       "      <td>Silt</td>\n",
       "      <td>2.503865</td>\n",
       "      <td>2.465000</td>\n",
       "      <td>2.774</td>\n",
       "      <td>train</td>\n",
       "      <td>1979-01-07T00:00:00</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5127.0</td>\n",
       "      <td>2.268694</td>\n",
       "      <td>60.272028</td>\n",
       "      <td>30_7-7</td>\n",
       "      <td>5022.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165944 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      CALI         DTC        Depth         GR  \\\n",
       "Well    DEPT                                                     \n",
       "30_11-3 2118.60  12.435000  109.432205  2118.744629  62.438549   \n",
       "        2118.75  12.435000  109.432205  2118.744629  62.438549   \n",
       "        2118.90  12.584001  102.456642  2118.896973  61.501503   \n",
       "        2119.05  12.606000   95.108009  2119.049561  61.000000   \n",
       "        2119.20  12.391000   99.642990  2119.201904  61.905998   \n",
       "...                    ...         ...          ...        ...   \n",
       "30_7-7  5022.15   5.961000   81.231377  5022.173828  59.574780   \n",
       "        5022.30   5.941000   81.126503  5022.326660  60.271767   \n",
       "        5022.45   5.887000   80.289490  5022.479004  59.796532   \n",
       "        5022.60   5.902000   78.824585  5022.631348  55.645344   \n",
       "        5022.75   5.902000   78.824585  5022.631348  55.645344   \n",
       "\n",
       "                LITHOLOGY_GEOLINK      RDEP      RHOB   RMED  split  \\\n",
       "Well    DEPT                                                          \n",
       "30_11-3 2118.60              Silt  1.321802  2.305019  1.439  train   \n",
       "        2118.75              Silt  1.321802  2.305019  1.439  train   \n",
       "        2118.90              Silt  1.478748  2.317000  1.439  train   \n",
       "        2119.05              Silt  1.553000  2.327976  1.534  train   \n",
       "        2119.20              Silt  1.512000  2.312981  1.777  train   \n",
       "...                           ...       ...       ...    ...    ...   \n",
       "30_7-7  5022.15              Silt  2.438013  2.455000  2.889  train   \n",
       "        5022.30              Silt  2.438000  2.463000  2.818  train   \n",
       "        5022.45              Silt  2.461923  2.455000  2.796  train   \n",
       "        5022.60              Silt  2.503865  2.465000  2.774  train   \n",
       "        5022.75              Silt  2.503865  2.465000  2.774  train   \n",
       "\n",
       "                   wlbCompletionDate  wlbCompletionYear  \\\n",
       "Well    DEPT                                              \n",
       "30_11-3 2118.60  1983-03-14T00:00:00             1983.0   \n",
       "        2118.75  1983-03-14T00:00:00             1983.0   \n",
       "        2118.90  1983-03-14T00:00:00             1983.0   \n",
       "        2119.05  1983-03-14T00:00:00             1983.0   \n",
       "        2119.20  1983-03-14T00:00:00             1983.0   \n",
       "...                              ...                ...   \n",
       "30_7-7  5022.15  1979-01-07T00:00:00             1979.0   \n",
       "        5022.30  1979-01-07T00:00:00             1979.0   \n",
       "        5022.45  1979-01-07T00:00:00             1979.0   \n",
       "        5022.60  1979-01-07T00:00:00             1979.0   \n",
       "        5022.75  1979-01-07T00:00:00             1979.0   \n",
       "\n",
       "                 wlbKellyBushElevation  wlbTotalDepth        xc         yc  \\\n",
       "Well    DEPT                                                                 \n",
       "30_11-3 2118.60                   25.0         4662.0  2.537631  60.044053   \n",
       "        2118.75                   25.0         4662.0  2.537631  60.044053   \n",
       "        2118.90                   25.0         4662.0  2.537631  60.044053   \n",
       "        2119.05                   25.0         4662.0  2.537631  60.044053   \n",
       "        2119.20                   25.0         4662.0  2.537631  60.044053   \n",
       "...                                ...            ...       ...        ...   \n",
       "30_7-7  5022.15                   25.0         5127.0  2.268694  60.272028   \n",
       "        5022.30                   25.0         5127.0  2.268694  60.272028   \n",
       "        5022.45                   25.0         5127.0  2.268694  60.272028   \n",
       "        5022.60                   25.0         5127.0  2.268694  60.272028   \n",
       "        5022.75                   25.0         5127.0  2.268694  60.272028   \n",
       "\n",
       "                    Well     DEPT  \n",
       "Well    DEPT                       \n",
       "30_11-3 2118.60  30_11-3  2118.60  \n",
       "        2118.75  30_11-3  2118.75  \n",
       "        2118.90  30_11-3  2118.90  \n",
       "        2119.05  30_11-3  2119.05  \n",
       "        2119.20  30_11-3  2119.20  \n",
       "...                  ...      ...  \n",
       "30_7-7  5022.15   30_7-7  5022.15  \n",
       "        5022.30   30_7-7  5022.30  \n",
       "        5022.45   30_7-7  5022.45  \n",
       "        5022.60   30_7-7  5022.60  \n",
       "        5022.75   30_7-7  5022.75  \n",
       "\n",
       "[165944 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "xf = xr.open_zarr(\"../../data/processed/geolink_norge_dataset/geolink_norge_well_logs.zarr\")\n",
    "\n",
    "# We will use just the 30* wells\n",
    "xf = xf.where(xf['Well'].str.startswith('30')).dropna(dim='Well', how='all')\n",
    "\n",
    "df = xf.to_dataframe().swaplevel()\n",
    "df['LITHOLOGY_GEOLINK'] = df['LITHOLOGY_GEOLINK'].astype('category')\n",
    "df['Well'] = df.index.get_level_values(0).astype('category')\n",
    "df['DEPT'] = df.index.get_level_values(1)\n",
    "\n",
    "# Keep these cols\n",
    "feature_cols = ['CALI', 'DTC', 'GR', 'RDEP', 'RHOB',\n",
    "       'RMED', 'xc', 'yc', 'DEPT']\n",
    "df = df.dropna(how='any', subset=feature_cols+['LITHOLOGY_GEOLINK'])\n",
    "df = df.sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T01:33:08.708474Z",
     "start_time": "2020-09-27T01:33:08.703347Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T12:29:04.975385Z",
     "start_time": "2020-09-21T12:29:04.783670Z"
    }
   },
   "source": [
    "\n",
    "  <div class=\"alert alert-success\">\n",
    "  <h2>Exercise</h2>\n",
    "\n",
    "  Discussion: Are there better ways we should set this up?\n",
    "    \n",
    "  What are the benefits?\n",
    "    \n",
    "  What information are we missing?\n",
    "      \n",
    "\n",
    "  <details>\n",
    "  <summary><b>→ Hints</b></summary>\n",
    "\n",
    "  There is no right answer except experimentation, but on creating this demo we found:\n",
    "      \n",
    "  * Generalising to a new well is hard, and it's important to have a similar distribution in test and train. So we took the top of some wells, and the bottom of others as training. \n",
    "  * Seeing the previous labels is important, as this encodes how the particular geologist interprets facies in this well. Which can often have some subjectivity\n",
    "  * Long context help a lot, but also slow it down. We're using the last 200 meters, but seeing the whole well helps\n",
    "  * Using all wells, instead of just the 30* wells will help it learn to generalise\n",
    "  * Using all logs may help\n",
    "  * We could do infilling instead\n",
    "  * We could make it bi-directional\n",
    "  * We could make it a sequence to sequence model, instead of sequence to 1\n",
    "  * Transformer may do better\n",
    "  * We could normalise the logs per window or well\n",
    "  * Many more\n",
    "\n",
    "  </details>\n",
    "\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T01:33:08.700926Z",
     "start_time": "2020-09-27T01:33:08.695492Z"
    }
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:23.770104Z",
     "start_time": "2020-10-05T06:44:23.758260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30_4-1      23291\n",
       "30_7-7      18949\n",
       "30_2-1      15674\n",
       "30_11-3     13021\n",
       "30_6-11     12994\n",
       "30_3-2 R    11046\n",
       "30_6-8      10965\n",
       "30_6-5      10882\n",
       "30_3-3      10209\n",
       "30_3-4 R     8715\n",
       "30_6-23      8233\n",
       "30_6-14      7080\n",
       "30_4-2       7039\n",
       "30_3-5 S     4207\n",
       "30_6-22      3639\n",
       "Name: Well, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We  will stick to a group of long wells 29, 30, 31, 35 are valid groups\n",
    "# df=df[df['Well'].str.startswith('30')]\n",
    "counts = df['Well'].value_counts()\n",
    "counts[counts>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T05:06:21.803115Z",
     "start_time": "2020-09-19T05:06:21.799047Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:23.796592Z",
     "start_time": "2020-10-05T06:44:23.774851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shaly Silt                41607\n",
      "Marlstone                 40738\n",
      "Silt                      36834\n",
      "Argillaceous Limestone    12329\n",
      "Cross Bedded Sst          10106\n",
      "Silty Shale                7366\n",
      "Silty Sand                 5522\n",
      "Cinerite                   3721\n",
      "Limestone                  3708\n",
      "Sandstone                  1702\n",
      "Calcareous Cement          1381\n",
      "Coal                        930\n",
      "                              0\n",
      "Name: LITHOLOGY_GEOLINK, dtype: int64\n",
      "removed_labels CategoricalIndex([''], categories=['', 'Argillaceous Limestone', 'Calcareous Cement', 'Cinerite', 'Coal', 'Cross Bedded Sst', 'Limestone', 'Marlstone', ...], ordered=False, dtype='category')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Shaly Silt                41607\n",
       "Marlstone                 40738\n",
       "Silt                      36834\n",
       "Argillaceous Limestone    12329\n",
       "Cross Bedded Sst          10106\n",
       "Silty Shale                7366\n",
       "Silty Sand                 5522\n",
       "Cinerite                   3721\n",
       "Limestone                  3708\n",
       "Sandstone                  1702\n",
       "Calcareous Cement          1381\n",
       "Coal                        930\n",
       "rare                          0\n",
       "Name: LITHOLOGY_GEOLINK, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let take the top N lithologies, replacing the rest with \"rare\"\n",
    "# print(len(df))\n",
    "removed_labels = df[\"LITHOLOGY_GEOLINK\"].value_counts()[max_lithologies:].index\n",
    "print(df['LITHOLOGY_GEOLINK'].value_counts())\n",
    "print('removed_labels', removed_labels)\n",
    "l = df[\"LITHOLOGY_GEOLINK\"].values.remove_categories(removed_labels)\n",
    "df['LITHOLOGY_GEOLINK']  = l.add_categories('rare').fillna('rare')\n",
    "df['LITHOLOGY_GEOLINK'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:23.809247Z",
     "start_time": "2020-10-05T06:44:23.798878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[], Categories (12, object): ['Argillaceous Limestone', 'Calcareous Cement', 'Cinerite', 'Coal', ..., 'Shaly Silt', 'Silt', 'Silty Sand', 'Silty Shale']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets keep the top 12 lithologies, and rename the rest as \"rare\"  (if any)\n",
    "removed_labels = list(df[\"LITHOLOGY_GEOLINK\"].value_counts()[12:].keys())\n",
    "i = df[\"LITHOLOGY_GEOLINK\"].values.remove_categories(removed_labels)\n",
    "i[i.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:23.830093Z",
     "start_time": "2020-10-05T06:44:23.811410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Coal', 'Calcareous Cement', 'Sandstone', 'Limestone', 'Cinerite',\n",
       "       'Silty Sand', 'Silty Shale', 'Cross Bedded Sst',\n",
       "       'Argillaceous Limestone', 'Silt', 'Marlstone', 'Shaly Silt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unused categories, and order\n",
    "df['LITHOLOGY_GEOLINK'] = df['LITHOLOGY_GEOLINK'].values.remove_unused_categories()\n",
    "\n",
    "# sort categories (leads to nicer histograms)\n",
    "i = df['LITHOLOGY_GEOLINK'].values\n",
    "litho_sorted = i.value_counts().sort_values(ascending=True).index\n",
    "df['LITHOLOGY_GEOLINK'] = i.reorder_categories(list(litho_sorted), ordered=True)\n",
    "\n",
    "df['LITHOLOGY_GEOLINK'].values.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:24.234652Z",
     "start_time": "2020-10-05T06:44:23.832319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Shaly Silt                41607\n",
       "Marlstone                 40738\n",
       "Silt                      36834\n",
       "Argillaceous Limestone    12329\n",
       "Cross Bedded Sst          10106\n",
       "Silty Shale                7366\n",
       "Silty Sand                 5522\n",
       "Cinerite                   3721\n",
       "Limestone                  3708\n",
       "Sandstone                  1702\n",
       "Calcareous Cement          1381\n",
       "Coal                        930\n",
       "Name: LITHOLOGY_GEOLINK, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['LITHOLOGY_GEOLINK'].value_counts().plot.bar()\n",
    "df['LITHOLOGY_GEOLINK'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:24.256260Z",
     "start_time": "2020-10-05T06:44:24.236559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Well_int</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Well</th>\n",
       "      <th>DEPT</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">30_11-3</th>\n",
       "      <th>2118.60</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118.75</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118.90</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119.05</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119.20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">30_7-7</th>\n",
       "      <th>5022.15</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022.30</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022.45</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022.60</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022.75</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165944 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Well_int\n",
       "Well    DEPT             \n",
       "30_11-3 2118.60         0\n",
       "        2118.75         0\n",
       "        2118.90         0\n",
       "        2119.05         0\n",
       "        2119.20         0\n",
       "...                   ...\n",
       "30_7-7  5022.15        14\n",
       "        5022.30        14\n",
       "        5022.45        14\n",
       "        5022.60        14\n",
       "        5022.75        14\n",
       "\n",
       "[165944 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gvie each well an number, since the model needs numbers\n",
    "well_index = df['Well'].values\n",
    "well_int = well_index.rename_categories(range(len(well_index.categories))).astype(int)\n",
    "df['Well_int']= well_int\n",
    "df[['Well_int']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:24.283118Z",
     "start_time": "2020-10-05T06:44:24.258160Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select the N longest well logs\n",
    "wells = sorted(df['Well'].unique())\n",
    "n_wells = min(len(wells), max_wells)\n",
    "selected_wells = wells[:n_wells]\n",
    "df = df.loc[selected_wells]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:24.293583Z",
     "start_time": "2020-10-05T06:44:24.285407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of wells, ordered by frequency\n",
    "well_counts = df['Well'].value_counts()\n",
    "well_counts = well_counts[well_counts>0]\n",
    "wells = list(well_counts.index)\n",
    "# well_counts.plot.bar()\n",
    "1\n",
    "# well_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:24.322226Z",
     "start_time": "2020-10-05T06:44:24.295471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LITHOLOGY_GEOLINK</th>\n",
       "      <th>LITH_ABV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Well</th>\n",
       "      <th>DEPT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">30_11-3</th>\n",
       "      <th>2118.60</th>\n",
       "      <td>Silt</td>\n",
       "      <td>Shaly Silt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118.75</th>\n",
       "      <td>Silt</td>\n",
       "      <td>Shaly Silt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118.90</th>\n",
       "      <td>Silt</td>\n",
       "      <td>Shaly Silt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119.05</th>\n",
       "      <td>Silt</td>\n",
       "      <td>Shaly Silt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119.20</th>\n",
       "      <td>Silt</td>\n",
       "      <td>Shaly Silt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">30_7-7</th>\n",
       "      <th>5022.15</th>\n",
       "      <td>Silt</td>\n",
       "      <td>Silt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022.30</th>\n",
       "      <td>Silt</td>\n",
       "      <td>Silt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022.45</th>\n",
       "      <td>Silt</td>\n",
       "      <td>Silt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022.60</th>\n",
       "      <td>Silt</td>\n",
       "      <td>Cross Bedded Sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022.75</th>\n",
       "      <td>Silt</td>\n",
       "      <td>Cross Bedded Sst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165944 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                LITHOLOGY_GEOLINK          LITH_ABV\n",
       "Well    DEPT                                       \n",
       "30_11-3 2118.60              Silt        Shaly Silt\n",
       "        2118.75              Silt        Shaly Silt\n",
       "        2118.90              Silt        Shaly Silt\n",
       "        2119.05              Silt        Shaly Silt\n",
       "        2119.20              Silt        Shaly Silt\n",
       "...                           ...               ...\n",
       "30_7-7  5022.15              Silt              Silt\n",
       "        5022.30              Silt              Silt\n",
       "        5022.45              Silt              Silt\n",
       "        5022.60              Silt  Cross Bedded Sst\n",
       "        5022.75              Silt  Cross Bedded Sst\n",
       "\n",
       "[165944 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to see the facies N intervals above\n",
    "df['LITH_ABV'] = df[\"LITHOLOGY_GEOLINK\"].shift(shift_length).fillna('Shaly Silt')\n",
    "df['LITH_ABV_INT'] = df['LITH_ABV'].values.codes\n",
    "df[['LITHOLOGY_GEOLINK', 'LITH_ABV']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T12:36:30.117841Z",
     "start_time": "2020-09-21T12:36:30.112925Z"
    }
   },
   "source": [
    "### Split data\n",
    "\n",
    "There are many ways to split the data, the best way would be to split by well, but this is too hard and leads to poor results.\n",
    "\n",
    "We could split randomly but this is too easy, since seeing the lithology at 1000 m gives you 90% of the answer at 1010 m.\n",
    "\n",
    "Lets split the wells by depth, this way the model gets some idea about each well, but can't peek ahead. We will take the top of the well as training for even numbered wells, and vice versa. There is a graph below showing the outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:24.752514Z",
     "start_time": "2020-10-05T06:44:24.324016Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (83611, 21) test (82324, 21)\n",
      "Train 50%, test 50%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from functools import partial\n",
    "\n",
    "def get_depth_thresh(x, even_bottom=True):\n",
    "    \"\"\"\n",
    "    On even number well codes take the bottom of the well for trainin\n",
    "    \"\"\"\n",
    "    if len(x)==0: return x\n",
    "    \n",
    "    # if the well code is even take the top \n",
    "    code_is_even = (x['Well'].values.codes[0]%2)==0\n",
    "    if code_is_even:\n",
    "        even_bottom = not even_bottom\n",
    "    \n",
    "    d = x['DEPT']\n",
    "    thresh = np.round(d.mean())\n",
    "    x['thresh'] = thresh\n",
    "    if even_bottom:\n",
    "        return x[d>thresh]\n",
    "    else:\n",
    "        return x[d<thresh]\n",
    "\n",
    "\n",
    "df_test = df.groupby(level=0).apply(partial(get_depth_thresh, even_bottom=False))\n",
    "df_train = df.groupby(level=0).apply(partial(get_depth_thresh, even_bottom=True))\n",
    "print('train', df_train.shape, 'test', df_test.shape)\n",
    "print(f'Train {len(df_train)/len(df):.0%}, test {len(df_test)/len(df):.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:24.924667Z",
     "start_time": "2020-10-05T06:44:24.754269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (82972, 20) test (82972, 20)\n",
      "Train 50%, test 50%\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "test = []\n",
    "for i, well in enumerate(selected_wells):\n",
    "    df_well = df.loc[well]\n",
    "    df_well.name = well\n",
    "    i_halfway = int(len(df_well)*0.5)\n",
    "    df_top = df_well.iloc[:i_halfway]\n",
    "    df_bottom = df_well.iloc[i_halfway:]\n",
    "    is_even = i%2==0\n",
    "    if is_even==0:\n",
    "        train.append(df_top)\n",
    "        test.append(df_bottom)\n",
    "    else:\n",
    "        train.append(df_bottom)\n",
    "        test.append(df_top)\n",
    "        \n",
    "df_test = pd.concat(test).set_index(['Well', 'DEPT'], drop=False)\n",
    "df_train = pd.concat(train).set_index(['Well', 'DEPT'], drop=False)\n",
    "print('train', df_train.shape, 'test', df_test.shape)\n",
    "print(f'Train {len(df_train)/len(df):.0%}, test {len(df_test)/len(df):.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:25.406391Z",
     "start_time": "2020-10-05T06:44:24.926712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEqCAYAAADkoHzAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlVUlEQVR4nO3de7xU5X3v8c9XRAFB5SZBUCHWaNQYVELMMRfNRcGmXhI15mJIag65GOtpchKhPd5OQkt68VhOq4ltUzWWGhJjpQkmqFXjOdHgBjEKSCHe2EKUUFG8gEB+/WOtrcNms9fMmrVmZu/5vl+vee21n5n1zG/NPDO/edZ6nrUUEZiZmfVmj2YHYGZmrc/JwszMMjlZmJlZJicLMzPL5GRhZmaZnCzMzCyTk4VZDyRdL+mbzY6jN5UxSnqPpFXNjsn6LycLszpJukfS55oZQ0TcFxGHV8T0pKQPNjMm61+cLMzMLJOThRkg6VhJSyVtlvR9YFDFfcMl/VjSBknPp8vj0/tmA+8B/lbSS5L+Ni3/G0lrJb0oaYmk9/Ty3KdJWpE+9zOS/mdafpKkTkl/Ium3aW/hk7up4yRJneny94CDgX9LY/p6QS+TtTEnC2t7kvYC/hX4HjAC+AHw0YqH7AH8E3AIyZfwq8DfAkTEnwL3AV+OiKER8eV0nQeBSWl984AfSBpEz/4R+HxEDAOOBv694r43AaOAccB04DpJh+9axRsi4nzgaeAP0pj+IuMlMMvkZGEGJwADgasjYltE/JDkyx6AiNgYEbdExCsRsRmYDbyvtwoj4qZ0ve0R8dfA3sDuvuS3AUdK2jcino+Ipd3uvzQitkbEvcBPgHPzbaZZfk4WZnAg8EzsfFbNp7oWJA2R9B1JT0l6Efg5sL+kAburUNJXJa2U9IKkTcB+JD2EnnwUOA14StK9kt5Vcd/zEfFyt7gOrGnrzArgZGEG64FxklRRdnDF8ldJegXvjIh9gfem5V2P3+nUzenxiUtIegDDI2J/4IWKx+8kIh6MiDOAA0h2h82vuHu4pH26xbWuim3y6aStUE4WZnA/sB34I0l7SvoIMKXi/mEkxyk2SRoBXN5t/WeBN3d7/HZgA7CnpMuAfXt6Ykl7SfqkpP0iYhvwIrCj28OuTB/3HuDDJMdUsnSPyawuThbW9iLiNeAjwGeA54GPAT+qeMjVwGDgt8ADwE+7VfE3wNnpSKm5wM+A24H/INlttAVY20sI5wNPpru4vgB8quK+36QxrQP+GfhCRDxWxWb9OfC/JG3qGl1lVg/54kdmrUnSScBNETG+yaGYuWdhZmbZ+kyykDRV0ipJayTNbHY8ZmbtpE/shkqHKP4H8CGgk2QM/McjYkVTAzMzaxN9pWcxBVgTEY+nByNvBs5ockxmZm1jz2YHUKVx7DyapBN4Z/cHSZoBzADYZ599jj/iiCMaE52ZWT+xZMmS30bE6O7lfSVZ9DSZaZf9ZxFxHXAdwOTJk6Ojo6PsuMzM+hVJT/VU3ld2Q3UCB1X8P57qZrGamVkB+kqyeBA4TNLE9Ayh5wELmhyTmVnb6BO7oSJiu6Qvk8yMHQB8NyKWNzksM7O20SeSBUBELAQWNjsOM7N21Fd2Q5mZWRM5WZiZWSYnCzMzy+RkYWZmmZwszMwsk5OFmZllcrIwM7NMThZmZpbJycLMzDI5WZiZWSYnCzMzy+RkYWZmmZwszMwsk5OFmZllcrIwM7NMThZmZpbJycLMzDI5WZiZWSYnCzMzy+RkYWZmmZwszMwsk5OFmZllcrIwM7NMThZmZpbJycLMzDI5WZiZWSYnCzMzy+RkYWZmmZwszMwsU2nJQtJ3JT0n6dGKshGS7pC0Ov07vOK+WZLWSFol6dSK8uMlPZLeN1eSyorZzMx6VmbP4npgareymcBdEXEYcFf6P5KOBM4DjkrXuUbSgHSda4EZwGHprXudZmZWstKSRUT8HPjPbsVnADekyzcAZ1aU3xwRWyPiCWANMEXSWGDfiLg/IgK4sWIdMzNrkEYfsxgTEesB0r8HpOXjgLUVj+tMy8aly93LeyRphqQOSR0bNmwoNHAzs3bWKge4ezoOEb2U9ygirouIyRExefTo0YUFZ2bW7hqdLJ5Ndy2R/n0uLe8EDqp43HhgXVo+vodyMzNroEYniwXA9HR5OnBbRfl5kvaWNJHkQPbidFfVZkknpKOgPl2xjpmZNcieZVUs6V+Ak4BRkjqBy4E5wHxJFwBPA+cARMRySfOBFcB24MKI2JFW9UWSkVWDgdvTm5mZNZCSQUb9z+TJk6Ojo6PZYZiZ9SmSlkTE5O7lrXKA28zMWpiThZmZZXKyMDOzTE4WZmaWycnCzMwyOVmYmVkmJwszM8vkZGFmZpmcLMzMLJOThZmZZXKyMDOzTE4WZmaWycnCzMwyOVmYmVkmJwszM8vkZGFmZpmcLMzMLJOThZmZZXKyMDOzTE4WZmaWycnCzMwyOVmYmVkmJwszM8vkZGFmZpmcLMzMLJOThZmZZdqz2QGYmTWKrlRd68flUVAkfY97FmZmlsk9C7MWV++vYdj1F7F/YVutSutZSDpI0t2SVkpaLunitHyEpDskrU7/Dq9YZ5akNZJWSTq1ovx4SY+k982VVP+np4Gk+m99Ic6+qK+8N2bNVmbPYjvw1YhYKmkYsETSHcBngLsiYo6kmcBM4BJJRwLnAUcBBwJ3SnpLROwArgVmAA8AC4GpwO0lxm5mlqmden2l9SwiYn1ELE2XNwMrgXHAGcAN6cNuAM5Ml88Abo6IrRHxBLAGmCJpLLBvRNwfEQHcWLFO2/IvYjNrpIYc4JY0ATgW+CUwJiLWQ5JQgAPSh40D1las1pmWjUuXu5f39DwzJHVI6tiwYUOh22Bm1s5KTxaShgK3AP8jIl7s7aE9lEUv5bsWRlwXEZMjYvLo0aNrD9YK5d6PWf9RarKQNJAkUfxzRPwoLX423bVE+ve5tLwTOKhi9fHAurR8fA/lZmbWIGWOhhLwj8DKiLiq4q4FwPR0eTpwW0X5eZL2ljQROAxYnO6q2izphLTOT1esY2ZmDVDmaKgTgfOBRyQtS8v+BJgDzJd0AfA0cA5ARCyXNB9YQTKS6sJ0JBTAF4HrgcEko6A8EsrMrIFKSxYR8f/o+XgDwAd2s85sYHYP5R3A0cVF17t695WH5yu1Nbcf6498ug8zM8vkZGFmZpmcLMzMLJOThZmZZXKyMDOzTE4WZmaWycnCzMwyOVmYmVkmXynPzNrHFXXOeLy8mDD6IvcszMwsk5OFmZllcrIwM7NMThZmZpbJycLMzDI5WZiZWaaqh85KGgCMqVwnIp4uIygzsz6h3qG40GeG41aVLCRdRLJJzwK/S4sDOKakuMzMrIVU27O4GDg8IjaWGYyZmbWmapPFWuCFMgOxGl1R57U7gaRzaGaWrddkIekr6eLjwD2SfgJs7bo/Iq4qMTYzK4tPe2E1yupZDEv/Pp3e9kpv4J+lZmZto9dkERFXAkg6JyJ+UHmfpHPKDMzMzFpHtccsZgE/qKLMeuLjC63L741ZVbKOWUwDTgPGSZpbcde+wPYyAzMzs9aR1bNYB3QApwNLKso3A39cVlBmu6M6OwLhToC1uhYdfJB1zOJh4GFJ8wABR5D0uVdFxGvlhGRmZq2m2mMWHwK+A/yaJGlMlPT5iLi9tMjMzKxlVJssrgJOjog1AJIOBX4COFmYmbWBapPFc12JIvU48FwJ8ZiZlcbHrPKr9hTlyyUtlPQZSdOBfwMelPQRSR/paQVJgyQtlvSwpOWSuuZsjJB0h6TV6d/hFevMkrRG0ipJp1aUHy/pkfS+uVK9hznNzKwW1SaLQSRnnH0fcBKwARgB/AHw4d2ssxV4f0S8HZgETJV0AjATuCsiDgPuSv9H0pHAecBRwFTgmvS06ADXAjOAw9Lb1Kq30MzM6lbVbqiI+GytFUdEAC+l/w5MbwGcQZJwAG4A7gEuSctvjoitwBOS1gBTJD0J7BsR9wNIuhE4Ex8vMTNrmGqvZ/EWkl/3YyLiaEnHAKdHxDcz1htAMj/j94C/i4hfShoTEesBImK9pAPSh48DHqhYvTMt25Yudy/v6flmkPRAOPjgg6vZNCuTZ0eb9RvV7ob6e5LTe2wDiIhfkewy6lVE7IiIScB4kl7C0b08vKdvluilvKfnuy4iJkfE5NGjR2eFZ2ZmVap2NNSQiFjc7bhy1af7iIhNku4hOdbwrKSxaa9iLG+MquoEDqpYbTzJDPLOdLl7ubWjunsr7qmY5VFtsvhtOrciACSdDazvbQVJo4FtaaIYDHwQ+BawAJgOzEn/3pausgCYJ+kq4ECSA9mLI2KHpM3pwfFfAp8G/m8N22jWt7XRdZ6tdVWbLC4ErgOOkPQM8ATwyYx1xgI3pMct9gDmR8SPJd0PzJd0Ack1Ms4BiIjlkuYDK0h6LRdGxI60ri8C1wODSQ5sl3tw279ezcx2Uu2V8gAWAneTfPG/DHyUZGZ3j9LjGsf2UL4R+MBu1pkNzO6hvAPo7XiHmZmVqNor5R0OvINkl5GA84GflxiXmZm1kGqvlLcIOC4iNqf/X4EvfGRmba6dTh9S7dDZg4HKU5K/BkwoPBozM2tJ1R7g/h6wWNKtJEdvzyKZfW1mZm2g2tN9zJZ0O/CetOizEfFQeWGZmVkrqbZnQUQsBZaWGIvVIC5vo52lZtZ01R6zMDOzNlZ1z8KsFbhHZdYc7lmYmVkmJwszM8vk3VBmbaidJpNZMdyzMDOzTE4WZmaWycnCzMwyOVmYmVkmH+C2tuZ5G2bVcbJoAH8htRlfadH6IScLM7MW0qrDmn3MwszMMjlZmJlZJu+Gsjd4X7u1EF1Zb3v08cIiuWdhZmaZnCzMzCyTk4WZmWVysjAzs0xOFmZmlsnJwszMMjlZmJlZJs+zMLNC1DsvwnMiWlvpPQtJAyQ9JOnH6f8jJN0haXX6d3jFY2dJWiNplaRTK8qPl/RIet9cSfXP1jEzs6o1YjfUxcDKiv9nAndFxGHAXen/SDoSOA84CpgKXCNpQLrOtcAM4LD0NrUBcZuZWarUZCFpPPD7wD9UFJ8B3JAu3wCcWVF+c0RsjYgngDXAFEljgX0j4v6ICODGinXMzKwByj5mcTXwdWBYRdmYiFgPEBHrJR2Qlo8DHqh4XGdati1d7l5uLc77oM36j9J6FpI+DDwXEUuqXaWHsuilvKfnnCGpQ1LHhg0bqnxaMzPLUuZuqBOB0yU9CdwMvF/STcCz6a4l0r/PpY/vBA6qWH88sC4tH99D+S4i4rqImBwRk0ePHl3ktpiZtbXSkkVEzIqI8RExgeTA9b9HxKeABcD09GHTgdvS5QXAeZL2ljSR5ED24nSX1WZJJ6SjoD5dsY6ZmTVAM+ZZzAHmS7oAeBo4ByAilkuaD6wAtgMXRsSOdJ0vAtcDg4Hb05uZmTVIQ5JFRNwD3JMubwQ+sJvHzQZm91DeARxdXoRmZtYbn+7DzMwyOVmYmVkmnxvKzIpxRZ3zai4vJgwrh5OFWYuLdp3bWG/yASegAnk3lJmZZXKyMDOzTE4WZmaWycnCzMwyOVmYmVkmJwszM8vkZGFmZpmcLMzMLJOThZmZZXKyMDOzTD7dh5kVom1PS9Im3LMwM7NM7ln0IC73TyQzs0ruWZiZWSYnCzMzy+RkYWZmmZwszMwsk5OFmZllaqvRUNu2baOzs5MtW7Y0O5RSDRo0iPHjxzNw4MBmh2Jm/URbJYvOzk6GDRvGhAkTkNTscEoREWzcuJHOzk4mTpzY7HDMrJ9oq91QW7ZsYeTIkf02UQBIYuTIkf2+92T9X0T9NytOWyULoF8nii7tsI1m1lhtlyzMzKx2bXXMojtdWewv8KzThGzatIl58+bxpS99qea6r776ambMmMGQIUPyhmdmlpt7Fg20adMmrrnmmlzrXn311bzyyisFR2RmVp227lk02syZM/n1r3/NpEmT+NCHPsQBBxzA/Pnz2bp1K2eddRZXXnklL7/8Mueeey6dnZ3s2LGDSy+9lGeffZZ169Zx8sknM2rUKO6+++5mb4qZtZlSk4WkJ4HNwA5ge0RMljQC+D4wAXgSODcink8fPwu4IH38H0XEz9Ly44HrgcHAQuDiiL431mHOnDk8+uijLFu2jEWLFvHDH/6QxYsXExGcfvrp/PznP2fDhg0ceOCB/OQnPwHghRdeYL/99uOqq67i7rvvZtSoUU3eCjNrR43YDXVyREyKiMnp/zOBuyLiMOCu9H8kHQmcBxwFTAWukTQgXedaYAZwWHqb2oC4S7Vo0SIWLVrEsccey3HHHcdjjz3G6tWredvb3sadd97JJZdcwn333cd+++3X7FDNzJqyG+oM4KR0+QbgHuCStPzmiNgKPCFpDTAl7Z3sGxH3A0i6ETgTuL2hURcsIpg1axaf//znd7lvyZIlLFy4kFmzZnHKKadw2WWXNSFCM7M3lJ0sAlgkKYDvRMR1wJiIWA8QEeslHZA+dhzwQMW6nWnZtnS5e/kuJM0g6YFw8MEHF7kdhRg2bBibN28G4NRTT+XSSy/lk5/8JEOHDuWZZ55h4MCBbN++nREjRvCpT32KoUOHcv311++0rndDtT5fPMv6o7KTxYkRsS5NCHdIeqyXx/Y0jjV6Kd+1MElG1wFMnjw58xPb6A/1yJEjOfHEEzn66KOZNm0an/jEJ3jXu94FwNChQ7nppptYs2YNX/va19hjjz0YOHAg1157LQAzZsxg2rRpjB071ge4zazhSk0WEbEu/fucpFuBKcCzksamvYqxwHPpwzuBgypWHw+sS8vH91DeJ82bN2+n/y+++OKd/j/00EM59dRTd1nvoosu4qKLLio1NjOz3SntALekfSQN61oGTgEeBRYA09OHTQduS5cXAOdJ2lvSRJID2YvTXVabJZ2g5DwWn65Yx8zMGqDMnsUY4Nb0PEV7AvMi4qeSHgTmS7oAeBo4ByAilkuaD6wAtgMXRsSOtK4v8sbQ2dvp4we3zcz6mtKSRUQ8Dry9h/KNwAd2s85sYHYP5R3A0UXHaGZm1fHpPszMLJOThZmZZXKyMDOzTG2dLKRib1nynnX2tNNOY9OmTbVvoJlZQdo6WTTa7pLFjh07enj0GxYuXMj+++9fUlRmZtl8ivIGqjxF+cCBAxk6dChjx45l2bJlrFixgjPPPJO1a9eyZcsWLr74YmbMmAHAhAkT6Ojo4KWXXmLatGm8+93v5he/+AXjxo3jtttuY/DgwU3eMjPr79yzaKA5c+Zw6KGHsmzZMv7yL/+SxYsXM3v2bFasWAHAd7/7XZYsWUJHRwdz585l48aNu9SxevVqLrzwQpYvX87+++/PLbfc0ujNMLM25J5FE02ZMoWJEye+/v/cuXO59dZbAVi7di2rV69m5MiRO60zceJEJk2aBMDxxx/Pk08+2ahwzayNOVk00T777PP68j333MOdd97J/fffz5AhQzjppJPYsmXLLuvsvffery8PGDCAV199tSGxmll7826oBqo8RXl3L7zwAsOHD2fIkCE89thjPPDAAz0+zsysGdq6Z9HoC7NWnqJ88ODBjBkz5vX7pk6dyre//W2OOeYYDj/8cE444YTGBoevw2Bmu6c+eCnrqkyePDk6Ojp2Klu5ciVvfetbmxRRY7XTtppZcSQtqbgM9uu8G8rMzDI5WZiZWaa2Sxb9dbdbpXbYRjNrrLZKFoMGDWLjxo39+ss0Iti4cSODBg1qdihm1o+01Wio8ePH09nZyYYNG5odSqkGDRrE+PHjsx9oZlaltkoWAwcO3GnGtJmZVaetdkOZmVk+ThZmZpbJycLMzDL12xnckjYAT5VU/Sjgty1ep2Ns3TodY2vWV0adfSHG7g6JiNHdC/ttsiiTpI6epsO3Up2OsXXrdIytWV8ZdfaFGKvl3VBmZpbJycLMzDI5WeRzXR+o0zG2bp2OsTXrK6POvhBjVXzMwszMMrlnYWZmmZwszMwsk5OFmZllcrJoEZIOl/T3rV6nWRZJ/13SYemyJP2TpBcl/UrScc2Oz/JxssiQNvZzJZ2TLn9A0lxJX5JU8+sn6RhJiyQ9KumbksZIugW4C1iRM8bC68x4viNKqPOynOudKukCSRO6lf9hQXENlXScpP1zrn9MEXHU8Hy53htJe3S1Z0l7pds8ImcYFwNPpssfB44BJgJfAf4mZ52VsQ7soWxUvfWm9fx7nesX+n2R1nlwV/uTNEHS2ZKOrifOPJwssv0dcC5wPvA94AtAB/Be4P/kqO/vgXnAR4ENwFLgceD3IiJPfWXV2ZtFJdT5uVpXkPRnwJ8CbwPuknRRxd1fzhOEpGsqlt9Nkmz/GnhE0mk5qnxI0hpJ35B0ZJ6YalTzeyPpTGA98IykM4D7gL8CfiXpD3LEsD0itqXLHwZujIiNEXEnsE+O+rriPFlSJ7Au/XE0oeLuPNv9q263R4ATu/7PGWah3xeSZgL3Ag9I+hzwU2Aa8H1JX8kZYy4eOptB0iMR8bb018xvgLER8ZqkPYGHIuJtNda3LCImVfy/FpgQETvqiLGMOufu7i5gekTsm6POF3upc3BE1HR9lfTDfWxEbE9/ec0DVkXEH0t6KCKOzRHj0og4Ll2+G/hqRCyV9GZgfq2nWZD0EMkXx8eBjwEvA/8C3BwRT9YaX1pnoe9NGuM0YDDwMPCOiFgl6RDglhzbvBT4feB5kvOzvT8ilqf3rYyIt9ZSX0W9DwKfiYjlks4G/hw4PyIeyPN+S1oAvAh8E3iV5PW7D3g3QETUfG65Er4vlgOTgSEkvbU3R8QGSfsAv4yIhvUw2uriRzltB4iIbZIejIjX0v+3S8rzZTxI0rEkDRPgJeAYSUrrXdoidX4W+CqwtYf7Pp6jPoBNJF9Ez3a/I01wtdozIrren03pr+DrJP0A2CtnjJX27XrtIuJxSQNy1BER8ShJD+hPJU0BzgPuk7Q2Iv5bjjoLf28i4jcAkp6OiFVp2VM5d51cRvJregCwoCJRvI+kx5vXXl11RcQPJa0EfpT++q75V29EnC7pLJJJbn8VEQskbcuTJCoU/X2xIyJelfQaSULbmNb3cvrxbhgni2y/kTQ0Il6KiKldhZLeBLyWo771wFWV9Vf8H8D7W6TOB4FHI+IX3e+QdEWO+gBuBA4BdkkWJL2CWv1a0vsi4l6AtCd1gaRvkuySy+OIdBeEgAmShkfE8+mX5i77yquw0yc6IhYDiyV9lWTXRB6FvzeS9oiI3wF/WFE2gBxJNyJ+nPZKhkXE8xV3dZD0rvLaJulNXYkt7WF8APgxcGieCiPiVkmLgG+ku3nq/ZFR9PfFUknzSHbf3QXcIOmnJJ/pwo9H9sa7oXJKu4H7RMRzzY6lDEoObm6JiFeaHcvuSBoMEBGv9nDfuIh4Jkedh3QrWpf+ShwFvDciflRjfZ+IiDyJsLc6C31vJL0DeCQitnQrnwC8OyJuKuJ56iXpg8CGiHi4W/l+wJcjYnad9b8deFdEfLueenZTd67vi3T31TkkP/p+CEwBPgE8DfxdRLxcdKy7jcXJonaSroiIK5odR6NJOi7nLq1q6j4iIh7Lue7AigOqXWWjIqKQc/4Xvd1lvI59IcYylBVnPe0xXb+0Ntms98ajofI5vdkBNMk/lFh3ntEshY6O6UXR213G69gXYixDWXHmaj8NapNNeW98zCKfxh5Zah11bXfGKJ79c1T5F8CpFaNj7pB0fkQ8QLHvUdHvdxntp2VjlDQUeAvweERsKqrerupzr1h8e4TGtMmmfP+4Z5HP8fVWoBInFqV1famouipcWef6nwUeBZZ0u3WQ7+DfTqNjgDNJDgCeRY7RMb2od7vLrq+MOnPXp+LnqvSmnu0uuj1CY9pkGe0nk3sWOaSjRpB0WUT871rWlXQyyWSdvdPx7TMqxtsvAmo+HYJ2nZwjYJakQWm8V+26Vi4H1rl+0aN4Ch8dI2kvYFukB/PS9+tQSdMi4vYc9R0TETtN8IqIf80TWw91v75fvKvOvPvFu4bIRsTv0tfgaUkjIuI/c4R2QsXyN4AzK+eqAAtz1Lk79bTJMkb8Fdomi26P9XCyqM/ngJqSBeV0U68k+QAur6hjADAsZ31lJaCzgS093RERE3PUNxMYQzJUuKueznQ8f64Z3CRfICcBz0v6GnAWyWv7FUnvjYhZNdb3kKQnSCbi/UtE1D3csegfHEpmcH8H+J2kLwB/QjJ58C2SvhgR/1ZHuEXMVemKs+g2WXR7hOLbZNHtMb+I8K2XG8kMz55um0lOa1BrfQ93+/8oYFXaCJbmjPFgkmF13wKGpGWP17ndm4Hvk0ywujy9Pd+1XODre1zB71dd9ZH80uxa7iCZWQ7JD6tf5ajvIeBoYDawhmSG9EySGfZ5Y3wQOCpdPhtYDZzQ9Xw5Y3wTyfmbXgQOT8sPATpy1PcK8CvgkbQdDU/L96h8fVuxTRbdHuuts+j2WNd2NPLJ+uKNZDzzmN3ctzZHfR3Am7qVjQeWAZvrjPUM4P+nXyD1JovCE9BunidXgiyrPuAXwNHp8k8rvugG5fmi6x4PyTj5q4C1wC9yxljoD47KBNN9G3PWd0i328C0fBTwkTrem9LbZNHtsd46i26P9dy8Gypb0bOOy9h10lXPbZLuINkt1VlnXU8DZys5sdwdkso4ISG03iieLwD/LOlh4DmgQ9K9JGdO/bN644liZnCXcaymyBncu5wuo2JuQE2TGrvV24g22Woj1Ypuj7l5Ul4LaPVJWpKGkCSgd0ZE3i+43dV9ZhR0wLeo+tIvyVNIhnvuSZJ4fxY5hn2WNIO70JnMjZjBrYoTNBahrDZZdHssos4i22M9nCzqUO8sz4p6Cv0glVXnbp7nloio6jxMuxnZcRywIvKNNCq0vhqfu+rtbkZ9ZdRZT33KeRbgnM9VVZxltJ9mtcky2k93nmdRn6JmZLZa17cWb67hsQ+STnZKR3bMJjkt9lck/XmO5y66vlrUst3NqK+MOuupr5FzA6qNs4z206w2WUb72YmPWWQoaZZnd31hktbu1NI1HRBvnIX0Y8B7Ijn98hySCzbVOgyw6PpqUXSXvIwuftNiLHjeRq2qjbOM9tOsNln6LiL3LLIVPstT3S5hSfpBqifIMuoswYt643KQvyUZ0QHJj5Y8bbHo+qwAKv7Ke2Upo/302zbpnkW2Qmd5ljEBquRJVZlPX8Njix7Z0cyRIq02iqsRdVZb3+XA29nNlfeAMtsjVB9nGe2nWW2y9N3OPsCdQcVfO6DQS1iWVWcNz31KRFR97KbokR3NGilS63Y3ur4y6qy2vsqD2ZIejYpLfzZi4EUt211G+2lGmyyj/eyikZM6+vON5Eu5msc9VLFc9wSoEuvcD5gDPEZyKceNwMq0bP9WeC3LqK/o7S7jdWz1GElmhO+RLk+pKB/QvX02+7VsRnuspc5mfg673/r0PrQWU/VoBL1xXeO6J0CVWOd8klMpnBQRIyNiJHByWvaDvHFWqZmjeIre7jJex1aPcQZpu4tkEmKXg0i+5PJqVpts5ki1Zn4Od9bIzNSfb1T5Cx54BzCoh/IJwKdyPncZda7Kc18jX8sy6it6u8t4HftCjFU+b02/2JsYZ9NOAdLMz2H3m3sWDRYRD0a3mbJp+ZNRMVNW0i3NrBN4StLXJY2pWH+MpEtIzmvUXxW93WW8jn0hxmrU+ou9Hdtky2yzk0Vxih6N0OxJWh8DRgL3Snpe0n8C9wAjgHNLiK1SM0caFb3dZbyOfSHGatQ6uqZZcTZzpFozP4c78WiogpQw8qTppwCRNAWIiHhQ0lHAVGBlRBR58ZqenrepI42K3u4yXse+EGMVz1lzG29SnE0dqdasz+EucThZ9E7JydlmkVwecXRa/BxwGzAnShoO1+xkIelykuG4ewJ3kJxa+17ggyTDAGs6WV1aZ6GvZRnvTdHbXdLr2PIxVvm8D0UN54sqYbvLaD9Ft/GmvDc9auQBkr54A34GXELFNShILhRzCXBHic/7UDPrJLlwzQBgCMkFcfZNyweT86IrRb+WZbw3RW93Sa9jy8dY5fOe0uTtLqP9FN3Gm/Le9BhLI5+sL95o3giMmj5IRdfJznM3Hup237JWeC3LeG+K3u6SXseWjpGS5gaUEGdfGKlWePvJe/MB7myFjkaQtJ+kOZIek7Qxva1My/bvelzUto+98DqB15RcMwDg+MrnAn5XQz2V+sIonqK3u4zXsdVjLGtuQNFx9oWRamW0n1ycLLIVPRqhL0zSAnhvpKc4ieQKal0GAtNz1tkXRvEUvd1lvI6tHuOEiPhWpFfyS+v9TUR8i+TSqHkVHWdfGKlWRvvJxQe4q1DkaARJqyLi8Frva3SdZekPo3isd5IWAXcCN0TEs2nZGOAzwIci4oNNDG8nfWGkWqvwWWczVI5GUHJ9667RCDMlHRu1j0Z4StLX6fmDVFfXt+A6C1f0a1nCe2PF+BjJtebvlXRAWvYssIAGzw3oTRntpz+3SfcsMkh6BJgE7A38BhgfES9KGgz8MiKOqbG+4SQfpDOA7h+kb0WOi8OUUWcZSngtC63P2ksZ7ac/t0n3LLJtj4gdwCuSfh0RLwJEcvWrmg8wRXIVrUvSWyHKqLMkhb6WJdRnBem2K+ZIkl0xj7XYrpgy2k+/bZNOFtlekzQkPchUyGiEMj5IfeTDWfRrWfh7Y/XrYVfMO0kO8rbarpgy2k+/bZPeDZVB0t4RsbWH8lHA2Ih4pMb6us/I7PogFTmjt+46y1DCa1lofVaMvrIrpoz205/bpJNFg3k/qfV32vlKea8vp/8vi4hJTQvOcvM8i8bbHhE70m7qTvs0yd9NLaNOs7xaZiKZFcfJovH6woxes3q0zEQyK453QzWY95OaWV/kZGFmZpm8G8rMzDI5WZiZWSYnCzMzy+RkYWZmmf4LRo56pxibhg8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data split\n",
    "well_split = []\n",
    "for i, well in enumerate(selected_wells):\n",
    "    df_well = df.loc[well]\n",
    "    i_halfway = int(len(df_well)*0.5)\n",
    "    is_even = i%2==0\n",
    "    well_split.append(dict(\n",
    "        well=well,\n",
    "        top=df_well.Depth.min(),\n",
    "        half=df_well.Depth.iloc[i_halfway],\n",
    "        bottom=df_well.Depth.max(),\n",
    "        train_top=is_even,\n",
    "    ))\n",
    "    \n",
    "df_well_split = pd.DataFrame(well_split)\n",
    "\n",
    "well_top = df_well_split[df_well_split.train_top]\n",
    "well_bottom = df_well_split[~df_well_split.train_top]\n",
    "\n",
    "# Do the ones where train is at top\n",
    "plt.bar(\n",
    "    x=well_top.well,\n",
    "    height=well_top.bottom,\n",
    "    color=\"green\",\n",
    "    label=\"test\"\n",
    ")\n",
    "plt.bar(\n",
    "    x=well_top.well,\n",
    "    height=well_top.half,\n",
    "    color=\"blue\",\n",
    "    label=\"train\"\n",
    ")\n",
    "plt.bar(\n",
    "    x=well_top.well,\n",
    "    height=well_top.top,\n",
    "    color=\"white\",\n",
    ")\n",
    "\n",
    "\n",
    "# Others\n",
    "plt.bar(\n",
    "    x=well_bottom.well,\n",
    "    height=well_bottom.bottom,\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.bar(\n",
    "    x=well_bottom.well,\n",
    "    height=well_bottom.half,\n",
    "    color=\"green\",\n",
    ")\n",
    "plt.bar(\n",
    "    x=well_bottom.well,\n",
    "    height=well_bottom.top,\n",
    "    color=\"white\",\n",
    ")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.legend()\n",
    "plt.title('data split')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:25.690561Z",
     "start_time": "2020-10-05T06:44:25.408594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Double check there is not overlap\n",
    "a=set(df_train.index)\n",
    "b=set(df_test.index)\n",
    "assert len(a.intersection(b))==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T01:52:24.643324Z",
     "start_time": "2020-09-19T01:52:24.637474Z"
    }
   },
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to process the input and target data. The input data needs to be normalised with a standard scaler, and the output data needs to be converted from text to numbers. To convert text to numbers we use `LabelEncoder` from Scikit Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:25.750654Z",
     "start_time": "2020-10-05T06:44:25.695998Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Coal', 'Calcareous Cement', 'Sandstone', 'Limestone', 'Cinerite',\n",
      "       'Silty Sand', 'Silty Shale', 'Cross Bedded Sst',\n",
      "       'Argillaceous Limestone', 'Silt', 'Marlstone', 'Shaly Silt'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Make a encoder, that order by frequency\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Instead of fitting, use the same codes as the pandas.Category\n",
    "encoder.classes_ = df[\"LITHOLOGY_GEOLINK\"].values.categories\n",
    "print(encoder.classes_)\n",
    "feat_cols = feature_cols = ['CALI', 'DTC', 'GR', 'RDEP', 'RHOB', 'RMED', 'xc', 'yc', 'DEPT', \"LITH_ABV_INT\"]\n",
    "scaler.fit(df[feat_cols].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LabelEncoder` converts each type to a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:25.758841Z",
     "start_time": "2020-10-05T06:44:25.753320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.transform([\"Shaly Silt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:15:40.525819Z",
     "start_time": "2020-09-21T13:15:40.521470Z"
    }
   },
   "source": [
    "### To pytorch sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T00:18:44.902602Z",
     "start_time": "2020-10-05T00:18:44.895402Z"
    }
   },
   "source": [
    "We will be using depth and other measurements to determine the lithology. We dealt with the same problem in the tablular data. But in tabular data we only look at the measurements at each depth to find the class, while here we can look at the variations in the measurements as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:25.768893Z",
     "start_time": "2020-10-05T06:44:25.761388Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_sequences(df, seq_length = 10):\n",
    "    \"\"\"Take moving sequences of a dataframe\"\"\"\n",
    "    \n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    features = scaler.transform(df.loc[:, feat_cols].values)\n",
    "    targets = encoder.transform(df.loc[:, \"LITHOLOGY_GEOLINK\"])\n",
    "\n",
    "    # Add prev labels, as one hot, to inputs\n",
    "    one_hot_targets = np.eye(len(encoder.classes_))[targets]\n",
    "    prev_one_host_targets = np.roll(one_hot_targets, shift=shift_length)\n",
    "    features = np.concatenate([features, prev_one_host_targets], 1)\n",
    "\n",
    "    for i in range(len(targets) - seq_length):\n",
    "        xi = features[i : i + seq_length, :]\n",
    "        yi = targets[i + seq_length - 1]\n",
    "        x.append(xi)\n",
    "        y.append(yi)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:25.778075Z",
     "start_time": "2020-10-05T06:44:25.770905Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_numpy(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        x = x.cpu().detach().numpy()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:26.057114Z",
     "start_time": "2020-10-05T06:44:25.780209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 22) ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.02499888,  0.42871696, -0.07652671, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.02499888,  0.42871696, -0.07652671, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01682694,  0.07395274, -0.10962604, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.02945864, -1.00597892, -0.42426624, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.02216017, -1.31547127, -0.42426624, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01542336, -2.31119823, -0.47057116, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = get_sequences(df_train, seq_length=seq_length)\n",
    "x_test, y_test = get_sequences(df_test, seq_length=seq_length)\n",
    "\n",
    "# What's the shape or one row of data? \n",
    "print(x_test[0].shape, y_test[0].shape)\n",
    "x_test[0], y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of a classification model is a value for each type. The type with the highest value is the one the model thinks is most likely to be associated with the input data. Therefore, the output size of the model should be the number of types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:26.066743Z",
     "start_time": "2020-10-05T06:44:26.059170Z"
    }
   },
   "outputs": [],
   "source": [
    "output_size = len(df[\"LITHOLOGY_GEOLINK\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important that we make sure the training and test set have close distribution. For instance, if there is a certain type in test data that doesn't exist in training data, the model will not be able to predict it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T03:23:56.736864Z",
     "start_time": "2020-10-05T03:23:56.631126Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:27.692393Z",
     "start_time": "2020-10-05T06:44:26.069313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAFiCAYAAADm7CPVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxdElEQVR4nO3deZwcVbn/8c83IRACYUvCGiCR9SKyRvarRI0QVDaRTeR33SIKiAu8BK+oiF7xuoAoGIKCuACiwCVCkACGRQFJgmEJawQlAyohCoSdwPP741Rnejo9Mz1JVfVM5ft+veY1U1U9/ZyZ6X6m6tQ5z1FEYGZmA9+gdjfAzMzy4YRuZlYRTuhmZhXhhG5mVhFO6GZmFbFSuwKPHDkyxowZ067wZmYD0uzZs5+OiFHNjrUtoY8ZM4ZZs2a1K7yZ2YAk6W/dHXOXi5lZRbSU0CXtK+khSfMkndzk+EmS5mQf90l6XdI6+TfXzMy602tClzQYOAeYCGwDHCFpm/rHRMS3I2KHiNgBOAW4OSL+VUB7zcysG630oe8CzIuIRwEkXQocANzfzeOPAC5Zlsa89tprdHR08PLLLy/Ltw8oQ4cOZfTo0QwZMqTdTTGzimgloW8EzK/b7gB2bfZAScOAfYHjujk+CZgEsMkmmyx1vKOjg+HDhzNmzBgktdC0gSkiWLhwIR0dHYwdO7bdzTGzimilD71ZZu2uotf7gD92190SEVMiYlxEjBs1aulRNy+//DIjRoyodDIHkMSIESNWiCsRMytPKwm9A9i4bns08GQ3jz2cZexuqal6Mq9ZUX5OMytPKwl9JrCFpLGSViYl7amND5K0JvB24Kp8m2hmZq3otQ89IhZLOg64DhgMXBARcyUdkx2fnD30IGB6RLyQV+POvP7hvJ4KgM9O2LLH48888wwXX3wxn/rUp/r0vPvttx8XX3wxa6211nK0zsxs+bQ0UzQipgHTGvZNbtj+KfDTvBrWDs888wznnnvuUgn99ddfZ/Dgwd1+37Rp07o9ZmZtNOObfXv8+FOKaUdJ2jb1vz86+eST+ctf/sIOO+zAkCFDWH311dlggw2YM2cO999/PwceeCDz58/n5Zdf5oQTTmDSpElAZxmD559/nokTJ7LXXntx2223sdFGG3HVVVex6qqrtvknM7MVgaf+1znjjDPYbLPNmDNnDt/+9re58847+cY3vsH996ch9xdccAGzZ89m1qxZnH322SxcuHCp53jkkUc49thjmTt3LmuttRaXX3552T+Gma2gfIbeg1122aXLOPGzzz6bK6+8EoD58+fzyCOPMGLEiC7fM3bsWHbYYQcAdt55Z/7617+W1VwzW8E5ofdgtdVWW/L1TTfdxA033MDtt9/OsGHD2HvvvZuOI19llVWWfD148GBeeumlUtpqZuYulzrDhw9n0aJFTY89++yzrL322gwbNowHH3yQO+64o+TWmZn1rF+fofc2zDBvI0aMYM8992Tbbbdl1VVXZb311ltybN9992Xy5Mlst912bLXVVuy2226lts3MrDf9OqG3w8UXX9x0/yqrrMK1117b9Fitn3zkyJHcd999S/afeOKJubfPzKw77nIxM6sIJ3Qzs4pwQjczqwgndDOzinBCNzOrCCd0M7OK6N/DFvtaKa03vVRSW9byuQBnnXUWkyZNYtiwYcvaOjMbgJalzHdRc2x8hl6nVj53WZx11lm8+OKLObfIzKx1/fsMvWT15XMnTJjAuuuuy2WXXcYrr7zCQQcdxGmnncYLL7zAoYceSkdHB6+//jqnnnoq//znP3nyyScZP348I0eOZMaMGe3+UcxsBeSEXueMM87gvvvuY86cOUyfPp3f/OY33HnnnUQE+++/P7fccgsLFixgww035JprrgFSjZc111yT733ve8yYMYORI0e2+acwsxWVu1y6MX36dKZPn86OO+7ITjvtxIMPPsgjjzzCW97yFm644Qa+8IUvcOutt7Lmmmu2u6lmZoDP0LsVEZxyyil84hOfWOrY7NmzmTZtGqeccgrvfve7+fKXv9yGFpqZdeUz9Dr15XP32WcfLrjgAp5//nkAnnjiCZ566imefPJJhg0bxlFHHcWJJ57IXXfdtdT3mpm1Q/8+Qy95wdb68rkTJ07kyCOPZPfddwdg9dVX5xe/+AXz5s3jpJNOYtCgQQwZMoQf/ehHAEyaNImJEyeywQYb+KaombVFSwld0r7A94HBwI8j4owmj9kbOAsYAjwdEW/PrZUlaiyfe8IJJ3TZ3myzzdhnn32W+r7jjz+e448/vtC2mZn1pNeELmkwcA4wAegAZkqaGhH31z1mLeBcYN+IeFzSugW118zMutFKH/ouwLyIeDQiXgUuBQ5oeMyRwBUR8ThARDyVbzPNzKw3rST0jYD5ddsd2b56WwJrS7pJ0mxJRzd7IkmTJM2SNGvBggVNg0VEC00a+FaUn9PMytNKQleTfY3ZaCVgZ+A9wD7AqZKWKlYQEVMiYlxEjBs1atRSTzp06FAWLlxY+WQXESxcuJChQ4e2uylmViGt3BTtADau2x4NPNnkMU9HxAvAC5JuAbYH+lS1ZvTo0XR0dNDd2XuVDB06lNGjR7e7GWZWIa0k9JnAFpLGAk8Ah5P6zOtdBfxQ0krAysCuwJl9bcyQIUMYO3ZsX7/NzMxoIaFHxGJJxwHXkYYtXhARcyUdkx2fHBEPSPodcA/wBmlo431FNtzMzLpqaRx6REwDpjXsm9yw/W3g2/k1zczM+sJT/83MKsIJ3cysIpzQzcwqwgndzKwinNDNzCrCCd3MrCKc0M3MKsIJ3cysIpzQzcwqwgndzKwinNDNzCrCCd3MrCJaKs5lZpanM6/v01IJAHx2wlJr5lgDn6GbmVWEE7qZWUU4oZuZVYQTuplZRTihm5lVhBO6mVlFOKGbmVWEE7qZWUW0lNAl7SvpIUnzJJ3c5Pjekp6VNCf7+HL+TTUzs570OlNU0mDgHGAC0AHMlDQ1Iu5veOitEfHeAtpoZmYtaOUMfRdgXkQ8GhGvApcCBxTbLDMz66tWEvpGwPy67Y5sX6PdJd0t6VpJb272RJImSZoladaCBQuWoblmZtadVhK6muyLhu27gE0jYnvgB8D/NXuiiJgSEeMiYtyoUaP61FAzM+tZKwm9A9i4bns08GT9AyLiuYh4Pvt6GjBE0sjcWmlmZr1qJaHPBLaQNFbSysDhwNT6B0haX5Kyr3fJnndh3o01M7Pu9TrKJSIWSzoOuA4YDFwQEXMlHZMdnwwcAnxS0mLgJeDwiGjsljEzswK1tMBF1o0yrWHf5Lqvfwj8MN+mmZlZX3imqJlZRTihm5lVhBO6mVlFOKGbmVWEE7qZWUU4oZuZVURLwxbNzKy53R6fsgzf9Z3c2wE+QzczqwwndDOzinBCNzOrCCd0M7OKcEI3M6sIJ3Qzs4pwQjczqwgndDOzinBCNzOrCM8UNbPS9afZlVXiM3Qzs4pwQjczqwgndDOzinBCNzOrCCd0M7OKaCmhS9pX0kOS5kk6uYfHvVXS65IOya+JZmbWil4TuqTBwDnARGAb4AhJ23TzuG8B1+XdSDMz610rZ+i7APMi4tGIeBW4FDigyeOOBy4HnsqxfWZm1qJWEvpGwPy67Y5s3xKSNgIOAib39ESSJkmaJWnWggUL+tpWMzPrQSsJXU32RcP2WcAXIuL1np4oIqZExLiIGDdq1KgWm2hmZq1oZep/B7Bx3fZo4MmGx4wDLpUEMBLYT9LiiPi/PBppZma9ayWhzwS2kDQWeAI4HDiy/gERMbb2taSfAlc7mZuZlavXhB4RiyUdRxq9Mhi4ICLmSjomO95jv7mZmZWjpWqLETENmNawr2kij4j/Wv5mmZktv9sfXdinx+8+vqCGlMQzRc3MKsIJ3cysIpzQzcwqwgndzKwinNDNzCrCCd3MrCKc0M3MKsIJ3cysIpzQzcwqwgndzKwinNDNzCrCCd3MrCKc0M3MKsIJ3cysIpzQzcwqwgndzKwinNDNzCrCCd3MrCKc0M3MKsIJ3cysIpzQzcwqoqWELmlfSQ9Jmifp5CbHD5B0j6Q5kmZJ2iv/ppqZWU9W6u0BkgYD5wATgA5gpqSpEXF/3cNuBKZGREjaDrgM2LqIBpuZWXOtnKHvAsyLiEcj4lXgUuCA+gdExPMREdnmakBgZmalaiWhbwTMr9vuyPZ1IekgSQ8C1wAfafZEkiZlXTKzFixYsCztNTOzbrSS0NVk31Jn4BFxZURsDRwInN7siSJiSkSMi4hxo0aN6lNDzcysZ60k9A5g47rt0cCT3T04Im4BNpM0cjnbZmZmfdBKQp8JbCFprKSVgcOBqfUPkLS5JGVf7wSsDCzMu7FmZta9Xke5RMRiSccB1wGDgQsiYq6kY7Ljk4H3A0dLeg14CTis7iapmZmVoNeEDhAR04BpDfsm1339LeBb+TbNzMz6wjNFzcwqwgndzKwinNDNzCrCCd3MrCKc0M3MKsIJ3cysIpzQzcwqwgndzKwinNDNzCrCCd3MrCKc0M3MKsIJ3cysIpzQzcwqwgndzKwinNDNzCrCCd3MrCKc0M3MKsIJ3cysIpzQzcwqwgndzKwinNDNzCqipYQuaV9JD0maJ+nkJsc/KOme7OM2Sdvn31QzM+tJrwld0mDgHGAisA1whKRtGh72GPD2iNgOOB2YkndDzcysZ62coe8CzIuIRyPiVeBS4ID6B0TEbRHx72zzDmB0vs00M7PetJLQNwLm1213ZPu681Hg2mYHJE2SNEvSrAULFrTeSjMz61UrCV1N9kXTB0rjSQn9C82OR8SUiBgXEeNGjRrVeivNzKxXK7XwmA5g47rt0cCTjQ+StB3wY2BiRCzMp3lmZtaqVs7QZwJbSBoraWXgcGBq/QMkbQJcAXwoIh7Ov5lmZtabXs/QI2KxpOOA64DBwAURMVfSMdnxycCXgRHAuZIAFkfEuOKabWZmjVrpciEipgHTGvZNrvv6Y8DH8m2amTU68/q+XQB/dsKWfQ8y45t9/57xp/T9eyx3nilqZlYRTuhmZhXhhG5mVhFO6GZmFeGEbmZWEU7oZmYV4YRuZlYRTuhmZhXhhG5mVhFO6GZmFeGEbmZWES3VcjGzFcftj/a9+vXu4wtoiPWZz9DNzCrCCd3MrCKc0M3MKsIJ3cysIpzQzcwqwgndzKwinNDNzCrCCd3MrCKc0M3MKqKlhC5pX0kPSZon6eQmx7eWdLukVySdmH8zzcysN71O/Zc0GDgHmAB0ADMlTY2I++se9i/g08CBRTTSzMx618oZ+i7AvIh4NCJeBS4FDqh/QEQ8FREzgdcKaKOZmbWgleJcGwHz67Y7gF2XJZikScAkgE022WRZnsKsf5rxzb5/z/hT8m+HrdBaOUNXk32xLMEiYkpEjIuIcaNGjVqWpzAzs260cobeAWxctz0aeLKY5pgNTC45a/1BK2foM4EtJI2VtDJwODC12GaZmVlf9XqGHhGLJR0HXAcMBi6IiLmSjsmOT5a0PjALWAN4Q9JngG0i4rnimm4rJPdVm3WrpRWLImIaMK1h3+S6r/9B6ooxswLt9viUPn7Hdwpph/VPnilqZlYRTuhmZhXhhG5mVhFO6GZmFeGEbmZWEU7oZmYV4YRuZlYRLY1DN+svPMXerHtO6CuKvs6wXJbZlZ7FadZW7nIxM6sIJ3Qzs4pwQjczqwj3oa8g+noz0TcSzQYeJ3TLjUegmLWXu1zMzCrCCd3MrCLc5dJmZ17/cJ+/57MTtiygJWY20PkM3cysInyG3pMyZleameVkQCZ0d1OYmS1tQCb0spQxdrvvi/6CF/41s2bch25mVhEtJXRJ+0p6SNI8SSc3OS5JZ2fH75G0U/5NNTOznvTa5SJpMHAOMAHoAGZKmhoR99c9bCKwRfaxK/Cj7HMh3E1hZra0Vs7QdwHmRcSjEfEqcClwQMNjDgB+FskdwFqSNsi5rWZm1gNFRM8PkA4B9o2Ij2XbHwJ2jYjj6h5zNXBGRPwh274R+EJEzGp4rknApGxzK+ChZWz3SODpZfxex2tfrKrHq/LPVna8Kv9syxtv04gY1exAK6Nc1GRf43+BVh5DREwBlqW/pGswaVZEjFve53G8av9sZcer8s9Wdrwq/2xFxmuly6UD2LhuezTw5DI8xszMCtRKQp8JbCFprKSVgcOBqQ2PmQocnY122Q14NiL+nnNbzcysB712uUTEYknHAdcBg4ELImKupGOy45OBacB+wDzgReDDxTUZyKHbxvHaEqvq8ar8s5Udr8o/W2Hxer0pamZmA4NnipqZVYQTuplZRTihNyFplVb2mQFIWq3dbbD+TdKerexbXk7ozd3e4r7cSFpV0lZFxmhnvKJJWqenj4Ji7iHpfuCBbHt7SecWESt7/htb2ZdjPEk6StKXs+1NJO1SVLyK+0GL+5aLE3odSetL2hlYVdKOknbKPvYGhhUY933AHOB32fYOkhqHhg7keMMknSrp/Gx7C0nvzTnMbGBW9nkB8DDwSPb17Jxj1ZwJ7AMsBIiIu4G35R1E0tDsn9JISWvX/aMaA2yYd7w65wK7A0dk24tIdZ0KIelbrezLMd56kn4i6dpsextJH805xu6SPg+MkvS5uo+vkkYN5qrfJ3RJiyQ91+RjkaTncg63D6mK12jge8B3s4/PAV/MOVa9r5Jq5jwDEBFzgDEVinch8AopOUCaiPb1PANExNiIeBNpeO37ImJkRIwA3gtckWeshrjzG3a9XkCYT5D+KW2dfa59XEWBCZZU4uNY4GWAiPg3sHKB8SY02TexwHg/Jb1eav8UHwY+k3OMlYHVSUPEh9d9PAccknOs/r/ARUQMLzHWRcBFkt4fEZeXFRdYHBHPSs0qKFQi3mYRcZikIwAi4iUVF/ytEXFMbSMirpV0ekGx5kvaA4hs0t2nybpf8hQR3we+L+n4iMj9Mr0Hr2XVVgNA0ijgjbyDSPok8CngTZLuqTs0HPhj3vHqjIyIyySdAkvm3OT6DzkibgZulvTTiPhbns/dTL9P6I0krQsMrW1HxOMFhLla0pGks9Ylv6OI+FoBsQDuy+INlrQFKTHcVlCsdsR7VdKqdCaGzUhn7EV4WtKXgF9k8Y4i6xIpwDHA94GNSFcd04FjC4oF8A9JwyNiUfYz7gR8PSLuKije2cCVwLqSvkE6o/xSAXEuBq4FvgnUr7ewKCL+VUC8mhckjaDzdbkb8GyeAST9tu75lzoeEfvnGm+gTCyStD+p+2ND4ClgU+CBiHhzAbF+R/rDzqbuEjoivpt3rCzeMOC/gXeTCp1dB5weES9XJN67s3jbkJLensCHI2JGAbHWAb5CZ1/2LcBpBSeGUki6JyK2k7QXKfl9B/hiRBS29oCkrYF3kl4nN0ZE7lcgvd20Lupvp7QQzw+AbYH7gFHAIRFxT4/f2LcYb+/peHYGn5uBlNDvBt4B3BARO0oaDxwREZN6+dZliXVfRGyb9/OuyLIzod1IieGOiCizVGmuJP2AJtVEayLi0wXF/XP22v8mcG9EXFzbV0S8LOZgYD26XqnmelUs6TE6f5+Np7GR3RsphKSVSKW8BTwUEa8VFasMA6nL5bWIWChpkKRBETGjwDvgt0l6S0TcW9DzdyFpS+BElu7ieUdF4t0YEe8ErmmyL+9YZfxss3p/SCGekHQe8C7gW0pzIwob2CDpeNLVzj9JV6oiJd7t8owTEWPzfL4+2oXO18pOkoiIn+X15JIui4hDJd1L15MAkf5Z5fq7HEhn6DcABwJnACNI3S5vjYg9Coh1P7A58Bipr7eQX35dvLuBySzdxVPIcLuy4kkaShruOQPYm86zrzWAayPiP/KMl8Us9XdZpqyrbF/S2fkjSquCvSUiphcUbx5ppEtR9yBqcbaOiAfVzVrERd0jkPRzYDPSEN7aayXyvMKStEFE/F3Sps2O532jdCAl9NVIw6cEfBBYE/hlES+2sn75dfFmR8TORTx3O+NJOoE0DGxDutbHfw44PyJ+WEDM0n6X2aiPL5DuDdTfqM/1SidL5K/VugOUJoTtB/wtIgobkilpBjAhIhYXFSOLMyUiJmXxapYkpgKvHB8AtokSk2DW9fg24PEiTjL6/Tj0moh4gbRs076kUQuXFnXmkCXujYF3ZF+/SLG/q99K+pSkDVTw7MYy40XE97PL6ROzceK1j+2LSOaZMn+XvyQNUxwLnAb8lbR+QN5+RzZPQNLmpFnLbwKOzfrTi/IocJOkU1Q3KaaAOD+WtH5EjI+I8aTx4c+TblTmPla7zn3A+gU+P5KulrRt9vUGWcyPAD+X9Jnc4w2gM/RDgW8DN5HO0v8TOCkiflNArK8A44CtImJLSRsCv46I3GsvZPEea7K7sJtBZcWT9I6I+L2kg5sdL+LssszfZe1qoDb6JNt3c0T0OLJhGeLcGxFvyb4+HVgnIo5VGvs+u3Ysb9n7YCkRcVrOce4C3hUR/5L0NtJC9McDOwD/ERGFJPXsimAH4E7qhtHmOZRQ0tzaSDxJXwS2joijJQ0H/ph3N+5Auin636Q+86dgyeXuDUDuCR04CNgRuAsgIp7M/gCFKPumUInx3g78Hnhfs2ZQwAzOkn+XtRERf5f0HlK30ugC4tSfdb2DdGJDRLwqKfeJPkuCZok7e+1HRDxfUKjBdUMTDwOmRJrYd7mkOQXFhDRjumj1o2beCZwPkM0lyP1vN5AS+qBaMs8spLhukFcjIiTVJgQUWk1P0hDgk3SOnb4JOK+oIVRlxYuIr0gaRLoBelmez92T7BK3sV87t5ELdb4uaU3g86TxzGsAny0gzj2SvgM8QbpZPx1A0loFxFoi+z3+HFgn234aODoi5uYcarCklbK++ncC9UORC8tREXGzpPWAt2a77mzIMXmYn40W6iBNBKvVT1oVGJJzrAHV5fJt0nCpS7JdhwH3RMQXCoh1IrAFqbbEN0l9XhdHQdOuJf2Y9Me9KNv1IeD1iPhYReLdEhG5F63qJtZXSCNqtiEtjTgR+ENRl+1lyN78JwAbkJaAvDvbvweprMLPC4p7G/DfkU0AUypS9z95jyyT9N+km7xPA5sAO2UnVJsDFxXY1Vl4N67SzPavkf5259RGJCnNo9k5Ir6TVywYAAk9+6OuFxF/zPpi9yL98v9NGuXyl4LiTqBuJmVEXF9EnCzW3RGxfW/7BnC8U4GXgF8BL9T2RwEzALPxvtsDf46I7bMzsB9HRLNun+WNNQr4OEuPef9I3rHaoczXidK0+w2A6dkAiNqcgtULHLZ4N2kUT5du3KLeB2UYCF0uZ5FVOsxuol0BIGlcdiz3N2oW63pJfyL7HUlap4gElHld0ma1f06S3kQxVfvaFa+W4OrrnARppEbeXoqINyQtlrQGab5CUTMNrwJuJd3LKfL31y6PZv+Ma1cAR5HmZuQuIu5osu/hImLVKbMbtxQDIaGPiSa1FSJillI96NxJ+gTpMuklUnW52gy5ohLDScAMSY9msTalMwkO+Hgl36iclfUtn0+aXPQ8aRRDEYYV0eXXj3yENByzdvP6FuC/2taa/P1O0nV07ca9to3tWW4DoctlXkRs3tdjyxnzEWD3KKneiDqXt6vVlHgQICIKqUjYhnjDSDXlN8kmkGxBGhJ6dRHx6uKOAdZodkKQ0/N/HbgtIqYV8fztJukDEfHr3vYNZA3duLdExJUFxSnyCr8zzgBI6JcAv4+I8xv2fxR4d0QcVkDM3wEHR8SLeT93N/Huioidets3gOP9inS2fHREbJvd5Ls9InbIMcamwDMR8Wy2PZ5UKuJvwA8j4tUcYy0iXbEJWI00hrk2mzIiYo28YmXxlpRgbSbPcdMNcUt9nZRN0rcar7Ca7csp1iOkEgMXkkZ9FZJ4B0KXy2eAKyV9kM6lxMaRVgI5qKCYp5AKdP2JrhMOcq2iJ2l9Ui3tVSXtCF1qneS+5F3Z8eqUscDFZaTXw7OSdgB+TRqhtD1pKbXcRvBEiYuuZGojIQ4mzWz8RbZ9BGl2aq4kTSSNOtlI0tl1h9ag8x9XFUwglW6oN7HJvjxsSSqq9hHgB9lJzk/zvk/Q7xN6RPwT2CM746qVtL0mIn5fYNjzSBNi7qWAFVrq7EPqkxxNqvVeS3KLKGbJu7Lj1ZSxwMWqEVGrF3MUaXjfd7Nx8HPyDNTD1cBfSUPTcrsagM6a2ZJObxj++VtJt+QZK/MkqaLk/nRdj3URxYyzL5XasEJSdkZ+PXB99nr5BfCpbKTNyRGRzyL0EeGPhg9Sv2iZ8d5f8XgTgJtJCzb/kpT49s45xr11X98F7FO3fU/Osf4EbJh9vQNp/PTnSeP6f1zg7/EB4E1122NJi7wUFW9I3ddrA9uV+bop8OdakzTU9BLSgIDaxzoFxhxBmkswi1RG+mDSCfU44LG84vT7M/Q2mSFpEvBbuna5FHVTY3Q2xG4RaXTGTqT/2oWURS07XqQhoHfRucDFCZH/DeffS7oM+Dsp+fwelhREyvWMmRKvBhp8llQs69FsewxpAemiXK+0UthKpJ9rgVKtmiIKdJUm0pXVs0rL+P0jIl7JJk1tJ+lnEfFMAWFvJw3/PDAiOur2z5I0Oa8g/f6maDuo/GJZd0eaBLMPaaz2qcCFUdxNylLjZTE3Ip0F1U/Aya27IOuTP4w0OeWyiHgi278jsG5EXJdjrPpiWXcBp9SeX3WFuoqQjVDaOtt8MAoamZTF+nOkFZI+BmwcqZRDoT9fmZTqxIwj/WO8DphKGn21XwGxFCUkW5+hNxHlr6BS68vej5RY7y7gpmHb4imtLHUYMJfOexJBGteci+zNcmmT/X/OK0adMq8Glqgb/rlpRHxc0haSihz+uVL2Mx1KKo5XNW9ExOJs6OJZEfEDSbm+XlTyItFO6E20Ydz0bEnTSX2ipyhVtyvyZmzZ8Q4k/f4KO5ss2WfovBrYKzqLmq1PsYnvQtJNyt2z7Q7SaJ6iXpdfI525/jEiZmYzih8pKFY7vJaNvDqazhnneRfMyrVWS2/c5dJEGeOmG+INIt1cezQinlFa1WSjKG5CTNnxrgU+EMWVX10hSJoVEeNUtzC0CqzBU3WStgGOIb23L5E0FjgsIs5oc9OWmc/Qmytj3DRaeg3FNxXb07JEkKoRvpd0FrYadaVmC/AiMEfSjRQ4rh9A0nuBaRFR5BVHu5Qx/HMJpeJYPyIVx9tW0nbA/hHx9aJiliki7gc+Xbf9GGnN4txlV/nfZOmyzrnel3NCb66sN853s89DgZ2Be0j929uRhsbtVUBMSBNt3iAtlvA10miXy+msC523qdlHGQ4Hvi/pctL9gQdKiluGr5DqaW8s6ZfAnhRbW+V8Ut2f8wAi4h5JFwMDOqErVeTsaeZtETd9LyT9/c4ExgMfpvNeVm6c0Jsr5Y0Taf1EJF0KTIqIe7PtbYET845XZ9eI2Kl2Aygi/q20nFkhIuKi3h+VW6yjsiGZRwAXKi1SciFwSUQsyjNW2VcDJQ3/rDcsIu5suGqswkzR97Yh5qoRcWM22uVvwFcl3UrKNblxQm+iDW+crWvJPIt/XzZ9vSivSRpM5xXIKAq4KSrpsog4tLszoqKGv0XEc9kZ+qqkG5gHASdJOjvyXaSklKuBJl1zf88+byJpkyioXjjwdHZ1WnudHFIXe8CKiL9lr//rIuJdJYV9Obt39Yik40irT62bdxDfFK2TjcseHg0rlijVkXkqClrkQqkA2Quk6cBBmqyyekQcUVC8D5JGaexEmt14CPClyLmKnqT/JP2j6Gg4tCnwZETMyzNeFnN/0uXsZqSJHBdFxFPZyKUHImLTnOPVrgY+TPrb5X41oLSYMaSuuXHA3dR1zUVEIV1z2aiWKcAepAVlHgOOioi/FhGvbJKmAh/KJhoVHeutpJm+awGnk2ar/m80qQO/XHGc0DtJugN4X0QsaNi/PnBlROze/DuXO+5Quq7xeQvwo4h4uYh4WcytSes3CrixiLNLSVcDX2wcPaO0OMlXophVhH5Gmn6/1Bh3Se+MiBsLiDmS9E/4M6Q37eZA3lcDta65bzR2zUXEf+UZp0nc1UiLQeTaZdVu2VyC3Ug1VupX0sr9Zn1ZnNDr9DQLrkoz5AAkrQ1sTNeZm7leuku6LyK27ebYktmWOccssyRq2VcDcxqHzjbbl2O8tUhjtMfQ9XUyYBNePUn/r9n+Iu75ZCOGTmLp2dLvyDOO+9C7GqrO1ceXkDSE1B9bCEl7Al9l6T92UaUGTifd5P0LnX3bQRr1kqeehkIW9fsssyTqIcCZjVcDEfGipCJWgHpAaYHv+q65IkfxTAPuoPiqo21R5s160gSwyaSRQ4UtV+iE3tUVwPmSjovOhWpXA86mcxmuIvyEVHhpNuWsTXkoaax9YdPUMzMlfTyaL04yu5vvWSbqLIm6mUoqiQr8vTGZ164GiujaIV0NfJJUtQ+yrrkC4tQMjQFeiKsnZY0NzyyOiCL/VoC7XLqQtBJpjO3HSCvdAGxCSrin1k3xzjvunyJi1yKeu5t4lwOfjK4L5BYRZz3gSlJ9k6UWJ4mIf+QYa01SXZVvAifXHVoUBVXJVPMVfSrTNSfps6Q1Wa+mnKqjpZL0BzrHhr+PbGx4ROQ2lFDSOtmXnyYtWH4lBf4undCbyCYV1dYqnRcRLxUc7wxgMOkqoP6PXchwtOym5FXAfQ3xilrKrH5xkrlRwOIkdW+cpvJ849RfDQD1I3WGk+qeHJVXrCxeOybCIOlY4BvAM3Xxo6iuwLJJmh0RO6tr9cxbI+I/c4zxGJ3LFTbK/XfphN4P1A1Lqxd53zCpizeXNPuvS99oZCvjDER1bxxY+s2T6xun7KsBpRWSIJU6hnQDFuCDwIsR8bW8Y2Zx/0KahFbKYullk/RH4D+B35AqZj4BnBERW7W1YcvBCX0FpLRIwdvb3Y6BqsyrgYa4f4yIPXvbl2O8qcDhUdJi6WUrY2x4FmN+rXtR0tHA+0ldul91l0tFSXoP8Ga63pwp6szre6SulqmU0MVTBklbR8SDTWZVAvn+bGVeDTTEnQMcFxF/yLb3AM4tcNjilaTX5AwKLqpWVdmM83dFxL8kvY1Us/94UrXT/4iIQ/KM51EuTWTDCOdExAuSjiLNqPx+pBoMRcSbDAwjFe35MWk43J1FxMrsmH3erW5fEcMWy/R54ON0Fjyrl+vPFuUvgFLzUeCCrMsngGdJq8gX5f+yj0rJrjy6lfO9pMF1Z+GHAVMi4nLg8uwfdK58ht5ENuxte9LU6p+TRrkcXFQ3RW1kRN3n1YErIuLdRcSz5VPm1UA38dcgvXcLn7JeRZIWAPNJi0T/iYarrDzvJUm6D9gh0spID5KK8N1SO9bdxLtl5TP05hZHREg6gHRm/pPuZpXlpDaK5kVJGwL/Iq0mlCtJR0XELyQ1HVscEd/LO2ZZSu6rLO1qoF42DPR/gA0jYqLSAg27R8RPco7TlqJqJVqfNAHtCOBI4BpS/Z25BcS6BLhZ0tOk9/mtAJI2J11h5coJvblFkk4hzcR7m1JltryXpqp3dTbN+n/pHK/94wLirJZ9Ht7k2EC/VDsPeBdA1ld5Bp19lVNI3Vi5iIiPZ5/H5/WcLfopqfhXbZm7h4Ffka4g81SbuNSOMrOFi4jXSeWxf6e06PYRwE2SvpZ3/Z2I+IbSwi4bANOjs0tkEOn1mSt3uTSRFeM6EpgZEbdK2gTYOyJ+lnOcZmeVRwEPUsAd8F7a8pmIOKuseHlT3VJsks4BFkTEV7PtXOudlD1yoS7uzIh4q7ouQVdYLZdu2lDYqJoyZYn8PaRkPoY0QOCCiHiine1aXoPa3YD+KCL+ERHfi4hbs+3H807mmfPIVomvO6s8j3QpNqWAeD0Z6FO8B2czfSFVkayfvJT3lWizv9vPKP7v9oLS+q+1+uS7UcBley82KTle7iRdBNxGGuxwWkS8NSJOH+jJHNzl0pSkRXR2QaxM6m55PiLWzDlUqXfAe1HKYqYFKrOvsl1/t8+RziQ3yybFjCLHrqQWVeGS/kOkcrlbAp9W54pMIg07XaNdDVteTuhNRESXPmZJBwK7FBBqsDqrO74TmFR3rOy/zYB+o5bcV9mWv1tE3CXp7cBWpOTzUBRQX0jSwd0dosCqo2WJiMr2TDihtyAi/k/Syb0/ss9KvQPecOXR5RDVeKMuNcMvIh4uIFSpf7fsuTcFXoiIpyUNJy0gvjnFjBPvaeGRqwuIZznxTdEmGs5QBpEqBL49ClixKOsHrZ1V1kr2bklagm7AztysujL/bpJOJdWvD9JMw3cBNwG7AndHxGfyjGcDlxN6E5IurNtcDPwVOD8KLjdr1oyk+0nDL4cBjwPrR1pEYyXSjOZcJ6fYwOUulyYi4sPtboNZnZcjLUbyqqS/1IplZbMPi16kxAYQJ/QmJI0GfgDsSbrM/QNwQkQ0rl5vVoa1sm5AAWvUdQmKVCHQDHCXS1OSrgcuprPu9FHAByNiQvtaZSuqhi7ApRR1RSnpA8DvImKRpC+Rxm1/3fd2+i8n9Caazb4re0aeWbvVFYvbi7SYx3eAL0aJyyVa31R2POZyelrSUZIGZx9HAQvb3SizktUWLH8P8KOIuIo00c76KSf05j4CHAr8A/g7aTZekXWnzfqjJySdR3ovTMvqnzhn9GPucjGzpiQNA/YF7o2IRyRtALwlIqa3uWnWDf+3bULSlpJuzIrTI2m77KaQWdtI+kA2SxRJX5J0RXeLbORkJDALeCWrODqEVAnU+imfoTch6WbgJOC8ujKlua8uYtYXZd+krFvgQqS1bseS6se8uYh4tvx8ht7csIhoXNNzcVtaYtap1JuUEfGWiNgu+7wFqUDdH4qKZ8vPCb25pyVtRmfd6UNIN0fN2qmtNymz8edvLSue9Z27XJqQ9CbSQgV7AP8GHiNNLPpbWxtmK7Syb1I2rD07iDSxaERE7FNEPFt+nvrfIFs/9JMR8S5JqwGDImJRu9tlRqrueE1EvCJpb2A70kpJRalfF2AxaTHlywuMZ8vJZ+hNSPp9RBSycrvZsspWQxpHWgPzOtLqRVtFxH4Fxx1OWsnn+SLj2PLzGXpzf5Y0Ffg1aakqACLiivY1yYw3sgqLBwNnRcQPJP25qGCStiXVM1on234a+H8RcV9RMW35OKE3tw5pqn/9WXoATujWTq9JOgI4ms5VhYYUGG8K8LmImAGQdfPU7i1ZP+QuF7MBQtI2wDHA7RFxiaSxwGERcUZB8e6OiO1722f9hxN6E5KGAh8F3kyaUAFARLiei7WVpJVJq9VDQYtE18W6EriLrmWkx0XEgUXFtOXjcejN/RxYH9gHuBkYDXiki7VV1uXxCHAOcC7wsKS3FRjyI8AoUlfjFaRSAF7Nqx/zGXoTkv4cETvWTbUeAlznkS/WTpJmA0dGxEPZ9pbAJRGxc8FxV/cIl4HBZ+jN1S5jn8nu9K9JGipm1k5DaskcICIepsCbopL2yBaovj/b3l7SuUXFs+XnUS7NTZG0NvAl0ljf1YEvt7dJZsyW9BM6+7Q/CMwuMN6ZpG7HqQARcXfBXTy2nNzlYjZAZLVbjgX2IlVAvAU4NyJeKSjenyJi11oXZLbPo1z6MZ+hNyHpf4D/jYhnsu21gc9HhGuiW1tIGgTMzko4f6+ksPMl7QFENrrm08ADJcW2ZeA+9OYm1pI5QET8Gyh0erVZTyLiDeDubKGJshxDuiLYCOgAdsi2rZ/yGXpzgyWtUruUlbQqsEqb22S2ATBX0p10LUmxfxHBIuJpUj+9DRBO6M39ArhR0oWkKf8fAS5qb5PMOK3MYJIuAk5o6Hr8rifY9V++KdoNSROBd5JuPk2PiOva3CRbQUnaHFgvIv7YsP9twBMR8ZeC4i65GdrTPus/fIbejYi4Fri23e0wA84Cvthk/4vZsfc1OZaHQZLWzu4hIWkdnDP6Nf9x6khaRLbsXOMhUj3oNUpukhnAmIi4p3FnRMySNKbAuN8FbpP0m2z7A8A3Coxny8kJvU5EDO/9UWalG9rDsVWLChoRP8vKDYwnndQcHBH3FxXPlp8Teg8krUvXaouPt7E5tuKaKenjEXF+/U5JH6XYmaJExFxJC8jeB5I28fug//JN0SYk7U+63NwQeArYFHggIt7c1obZCknSesCVwKt0JvBxwMrAQRHxj4Li+n0wwDihNyHpbtJqRTdkVRfHA0dExKQ2N81WYNnrcNtsc25E/L7geH4fDDDucmnutYhYKGmQpEERMUPSt9rdKFuxZUvBzSgxpN8HA4wTenPPSFqdVPzol5KeAha3uU1mZfP7YIBxl0sTklYDXiLVuvkgqR76LyNiYVsbZlai7H3wMmmEi98HA4ATep12zcgzM8uDqy12dRbN1w6tzcgzqzxJiyQ91+RjkaTn2t0+65770Ltq14w8s37DE+wGLif0rtoyI8+sP8lqtnQrIv5VVlusb5zQu2rbjDyzfmQ2qaaRmhwL4E3lNsda5Zuiddo1I8/MLA9O6E2UPSPPrD+RtHVEPChpp2bHI+KusttkrXFCN7MuJE2JiEmSms1KjYh4R+mNspY4oZuZVYRvippZU5IObrL7WeDeiHiq7PZY73yGbmZNSboG2J3OgmB7A3cAWwJfi4ift6lp1g2foZtZd94A/iMi/glLRoH9CNiVVLDLCb2f8dR/M+vOmFoyzzwFbJlNLHqtTW2yHvgM3cy6c6ukq4FfZ9vvB27JqjA+07ZWWbfch25m3ZL0fmAv0qzRPwCXh5NGv+WEbmZLkTQIuCcitu31wdZvuA/dzJYSEW8Ad0vapN1tsda5D93MurMBMFfSncALtZ0RsX/7mmQ9cUI3s+6c1u4GWN+4D93MWiJpT+DIiDi23W2x5nyGbmbdkrQDcCRwKPAYcHlbG2Q9ckI3sy4kbQkcDhwBLAR+RbqaH9/Whlmv3OViZl1IegO4FfhoRMzL9j0aEV6pqJ/zsEUza/R+4B/ADEnnS3onzZejs37GZ+hm1lQ2xf9AUtfLO4CLgCsjYno722Xdc0I3s15JWgf4AHCYVyzqv5zQzcwqwn3oZmYV4YRuZlYRTuhmZhXhhG5mVhH/H04oYah2ib9YAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_distribution(y, label):\n",
    "    y = to_numpy(y)\n",
    "    plt.hist(y, output_size * 2, alpha=0.5, label=label, density=True)\n",
    "    plt.xticks(ticks=range(len(encoder.classes_)), labels=encoder.classes_, rotation=90)\n",
    "\n",
    "show_distribution(y_train, 'train')\n",
    "show_distribution(y_test, 'test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline accuracy\n",
    "\n",
    "When you experiment with a machine learning problem it's important to use a baseline, to check if the model is actually doing any work. Sometimes you can use humans, or a prior work, but in novel problems we look at a naive answer, then aim to do better.\n",
    "\n",
    "Below we investigate several methods of naive estimation and try to beat the best.\n",
    "\n",
    "[more](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:27.832533Z",
     "start_time": "2020-10-05T06:44:27.694182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy=21.15% for most_frequent\n",
      "baseline accuracy=8.29% for uniform\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "score_fn=accuracy_score\n",
    "\n",
    "true = np.array(y_test)\n",
    "for strategy in [\"most_frequent\", \"uniform\"]:\n",
    "    dummy_clf = DummyClassifier(strategy=strategy)\n",
    "    dummy_clf.fit(x_train, y_train)\n",
    "    score = dummy_clf.score(x_test, y_test)\n",
    "    print(f\"baseline accuracy={score:2.2%} for {strategy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:27.842599Z",
     "start_time": "2020-10-05T06:44:27.834464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy 62.14% for prev 100 facies values or 15.0m above\n"
     ]
    }
   ],
   "source": [
    "# Prev litho Baseline, this is like a model that says \"the same as the last lithology\"\n",
    "pred_baseline = np.roll(true, shift=shift_length)\n",
    "score_prev_base=score_fn(true, pred_baseline)\n",
    "print(f'baseline accuracy {score_prev_base:2.2%} for prev {shift_length} facies values or {shift_length*0.15}m above')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so which baseline do we use? The highest is the one we need to beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T14:59:48.884309Z",
     "start_time": "2020-09-21T14:59:48.546101Z"
    }
   },
   "source": [
    "## Train\n",
    "\n",
    "Note that this can be simplified with libraries like pytorch lightning or fast-ai, but they are not yet approved at many companies. So we do it manually, this also helps you see the details of the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:27.851589Z",
     "start_time": "2020-10-05T06:44:27.844556Z"
    }
   },
   "outputs": [],
   "source": [
    "class NumpyDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset wrapping arrays.\n",
    "    Each sample will be retrieved by indexing array along the first dimension.\n",
    "    Arguments:\n",
    "        *arrays (numpy.array): arrays that have the same size of the first dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *arrays):\n",
    "        self.arrays = arrays\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return tuple(array[index] for array in self.arrays)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.arrays[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:27.881223Z",
     "start_time": "2020-10-05T06:44:27.853751Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def train_epoch(x_train, y_train, model, bs=128, max_epoch_iters=128*128):\n",
    "    model.train()\n",
    "\n",
    "    training_loss = []\n",
    "    training_accuracy = []\n",
    "\n",
    "    # Put data into a loader\n",
    "    dset_train = NumpyDataset(x_train, y_train)\n",
    "    load_train = torch.utils.data.dataloader.DataLoader(\n",
    "        dset_train, \n",
    "        batch_size=bs, pin_memory=True,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    for x, y in tqdm(load_train, leave=False, desc='train'):\n",
    "        # make it a pytorch gpu variable\n",
    "        x = x.float().to(device)\n",
    "        y = y.long().to(device)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x) # Make prediction\n",
    "        loss = loss_func(preds, y) # Measure error/lopss\n",
    "        \n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record stats\n",
    "        training_loss.append(loss.item())\n",
    "        accuracy = score_fn(\n",
    "            to_numpy(y), to_numpy(preds).argmax(-1)\n",
    "        )\n",
    "        training_accuracy.append(accuracy)\n",
    "\n",
    "    return [np.mean(training_loss), np.mean(training_accuracy)]\n",
    "\n",
    "def test_epoch(x_test, y_test, model, bs=512, max_epoch_iters=128*128):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    true = []\n",
    "\n",
    "    test_loss = []\n",
    "\n",
    "    dset_test = NumpyDataset(x_test[:max_epoch_iters//4], y_test[:max_epoch_iters//4])\n",
    "    load_test = torch.utils.data.dataloader.DataLoader(dset_test, batch_size=bs, pin_memory=True)\n",
    "    for x, y in tqdm(load_test, leave=False, desc='test'):\n",
    "        x = x.float().to(device)\n",
    "        y = y.long().to(device)\n",
    "        \n",
    "        pred = model(x)\n",
    "        loss = loss_func(pred, y)\n",
    "\n",
    "        preds.append(to_numpy(pred))\n",
    "        true.append(to_numpy(y))\n",
    "        test_loss.append(loss.item())\n",
    "\n",
    "    preds = np.concatenate(preds, 0).argmax(axis=-1)\n",
    "    true = np.concatenate(true, 0)\n",
    "    test_accuracy = score_fn(true, preds)\n",
    "    return preds, true, np.mean(test_loss), test_accuracy\n",
    "\n",
    "def training_loop(x_train, y_train, x_test, y_test, mode, epochs=1, bs=128, max_epoch_iters=128*128):\n",
    "    all_losses = []\n",
    "    all_accuracys = []\n",
    "    try:\n",
    "        _, _, test_loss, test_acc = test_epoch(x_test, y_test, model, max_epoch_iters=max_epoch_iters)\n",
    "        print(\n",
    "                f\"Start: Test Loss = {test_loss:.2f}, Test accuracy = {test_acc:.3f}\"\n",
    "            )\n",
    "        for epoch in tqdm(range(epochs), desc='epochs'):\n",
    "            loss, acc = train_epoch(x_train, y_train, model, bs=bs, max_epoch_iters=max_epoch_iters)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}: Training Loss = {loss:.2f}, Train accuracy = {acc:.3f}\")\n",
    "            \n",
    "            _, _, test_loss, test_acc = test_epoch(x_test, y_test, model, max_epoch_iters=max_epoch_iters)\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{epochs}: Test Loss = {test_loss:.2f}, Test accuracy = {test_acc:.3f}\"\n",
    "            )\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "            all_losses.append([loss, test_loss])\n",
    "            all_accuracys.append([acc, test_acc])\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        # This lets you stop manually. and still get the results\n",
    "        pass\n",
    "\n",
    "    # Visualising the results\n",
    "    all_losses = np.array(all_losses)\n",
    "    plt.plot(all_losses[:, 0], label=\"Training\")\n",
    "    plt.plot(all_losses[:, 1], label=\"Test\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    all_accuracys = np.array(all_accuracys)\n",
    "    plt.plot(all_accuracys[:, 0], label=\"Training\")\n",
    "    plt.plot(all_accuracys[:, 1], label=\"Test\")\n",
    "    plt.title(\"accuracy\")\n",
    "    plt.legend()\n",
    "    \n",
    "    return all_losses, all_accuracys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T15:04:40.893852Z",
     "start_time": "2020-09-21T15:04:40.888277Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:31.084537Z",
     "start_time": "2020-10-05T06:44:27.883237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(22, 64, num_layers=3, batch_first=True)\n",
       "  (linear): Linear(in_features=64, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init the model\n",
    "model = LSTM(\n",
    "    input_size=x_train[0].shape[-1],\n",
    "    hidden_size=64,\n",
    "    num_layers=3,\n",
    "    output_size=output_size,\n",
    ")\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T06:44:31.089552Z",
     "start_time": "2020-10-05T06:44:31.086285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Init the optimiser, and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = torch.nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T06:44:16.610Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='test', max=8.0, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: Test Loss = 2.58, Test accuracy = 0.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787feeb9a02142de9f69e870fcb9a94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epochs', max=10.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b11765e710c4c5a860e6658e8014891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=646.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loop(x_train, y_train, x_test, y_test, model, epochs=10, bs=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it overfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T06:44:16.617Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds, true, loss, acc = test_epoch(x_test, y_test, model)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T01:40:55.581670Z",
     "start_time": "2020-10-05T01:40:55.554871Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T00:02:17.716826Z",
     "start_time": "2020-10-05T00:02:17.707884Z"
    }
   },
   "source": [
    "This beats the baseline, so the model is doing better than the naive answer of \"the same again\". But lets break it down by lithology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T06:44:16.627Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "\n",
    "def classification_report(*args, **kwargs):\n",
    "    out_df = pd.DataFrame(sklearn.metrics.classification_report(*args, **kwargs, output_dict=True)).T\n",
    "    # Order cols\n",
    "    out_df[[\"precision\",\"recall\",\"f1-score\",\"support\"]]  \n",
    "    # Round\n",
    "    out_df[[\"precision\",\"recall\",\"f1-score\"]]= out_df[[\"precision\",\"recall\",\"f1-score\"]].apply(lambda x: round(x,2))\n",
    "    out_df[[\"support\"]]= out_df[[\"support\"]].apply(lambda x: x.astype(np.int))\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T06:44:16.632Z"
    }
   },
   "outputs": [],
   "source": [
    "# pred_baseline = np.roll(true, shift=shift_length)\n",
    "# df_report = classification_report(true, pred_baseline, labels=range(len(encoder.classes_)), target_names=encoder.classes_)\n",
    "# df_report[df_report.support>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T06:44:16.639Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_report = classification_report(true, preds, labels=range(len(encoder.classes_)), target_names=encoder.classes_)\n",
    "df_report[df_report.support>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T06:44:16.644Z"
    }
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(true, preds):\n",
    "    cm = sklearn.metrics.confusion_matrix(true, preds, labels=range(len(encoder.classes_)))\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title('Confusion Matrix')\n",
    "    ax=plt.gca()\n",
    "    disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                  display_labels=encoder.classes_)\n",
    "    disp.plot(ax=ax, xticks_rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T06:44:16.649Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(true, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T06:44:16.655Z"
    }
   },
   "outputs": [],
   "source": [
    "from deep_ml_curriculum.visualization.well_log import plot_well_pred\n",
    "\n",
    "def plot_well(df, model, depth_min=0, depth_max=18000, well_name=\"30_4-1\", device=device):\n",
    "    logs = df.loc[well_name].sort_index()\n",
    "    x_test, y_test = get_sequences(logs)\n",
    "    x_test = torch.Tensor(x_test)\n",
    "    preds = to_numpy(model(x_test.to(device)).argmax(axis=-1))\n",
    "    acc = score_fn(y_test, preds)\n",
    "    df_log_results = logs.iloc[10:].copy()\n",
    "    df_log_results['pred'] = pd.Categorical(encoder.inverse_transform(preds), categories=df_log_results.LITHOLOGY_GEOLINK.values.categories)\n",
    "    \n",
    "    # Lets zoom in on an interesting interval a:b\n",
    "    plot_well_pred(f'{well_name} acc={acc:2.2f}', df_log_results.loc[depth_min:depth_max],\n",
    "                   facies_true=df_log_results.loc[depth_min:depth_max].LITHOLOGY_GEOLINK.values, \n",
    "                   facies_pred=df_log_results.loc[depth_min:depth_max].pred.values)\n",
    "    plt.show()\n",
    "    return df_log_results[['LITHOLOGY_GEOLINK', 'pred']]\n",
    "    \n",
    "plot_well(df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T06:44:16.660Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'{n_wells} wells. {max_lithologies} lithologies')\n",
    "print(f'context length of {0.15*seq_length} m or {seq_length} intervals')\n",
    "print(f'model can see human labels up to {shift_length*0.15}m above. Or {shift_length} intervals')\n",
    "print(f'baseline accuracy {score_prev_base:2.2%} for prev {shift_length} facies values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T06:44:16.664Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_well(df, model, depth_min=5000, depth_max=6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model requires hyper parameter tuning and possibly training over 100s of epochs to reach the best results. However, in this example due to large size of dataset and the model we stopped after `10` epochs. \n",
    "\n",
    "There are number ways we can improve it:\n",
    "\n",
    "- Training for longer. Instead of stopping after 10 `epochs` go for longer. (might overfit)\n",
    "- Increase or decrease the `hidden_size`. (might overfit)\n",
    "- Increase the size of the sequences `seq_length` so the model get to look further in the history. (might underfit)\n",
    "- Increase the learning rate or decrease batch size `bs` (might overfit)\n",
    "- (advanced) Increase the size of training data by adding data from more wells to training. `max_wells` (might underfit)\n",
    "\n",
    "#### Exercise 2\n",
    "\n",
    "Try one of the options above to improve the model. (hint search for \"# CHANGE ME\",  change values, then rerun notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <h2>Exercise</h2>\n",
    "\n",
    "  Try one of the options above to improve the model. \n",
    "    \n",
    "  To help we've collected and summarised all the code below, so you can change and run the cells below\n",
    "    \n",
    "    \n",
    "  ```python\n",
    "# Params\n",
    "seq_length = 400  # CHANGE ME\n",
    "\n",
    "# Prepare data\n",
    "x_train, y_train = get_sequences(df_train, seq_length=seq_length)\n",
    "x_test, y_test = get_sequences(df_test, seq_length=seq_length)\n",
    "\n",
    "# Init the model\n",
    "model = LSTM(\n",
    "    input_size=x_train[0].shape[-1],\n",
    "    hidden_size=64, # CHANGE ME\n",
    "    num_layers=3, # CHANGE ME\n",
    "    output_size=output_size,\n",
    ").to(device)\n",
    "\n",
    "# Init the optimiser, and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # CHANGE ME\n",
    "loss_func = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Train\n",
    "training_loop(x_train, y_train, x_test, y_test, model, epochs=10, bs=128) # Change me\n",
    "\n",
    "# Measure baseline\n",
    "pred_baseline = np.roll(np.array(y_test), shift=shift_length)\n",
    "score_prev_base=score_fn(y_test, pred_baseline)\n",
    "print(f'baseline accuracy {score_prev_base:2.2%} for prev {shift_length} facies values')\n",
    "print(f'{n_wells} wells. {max_lithologies} lithologies')\n",
    "print(f'context length of {0.15*seq_length} m or {seq_length} intervals')\n",
    "print(f'model can see human labels up to {shift_length*0.15}m above. Or {shift_length} intervals')\n",
    "print(f'baseline accuracy {score_prev_base:2.2%} for prev {shift_length} facies values')\n",
    "\n",
    "# Test\n",
    "preds, true, loss, acc = test_epoch(x_test, y_test, model)\n",
    "print('acc', acc)\n",
    "\n",
    "df_report = classification_report(true, preds, labels=range(len(encoder.classes_)), target_names=encoder.classes_)\n",
    "display(df_report[df_report.support>0])\n",
    "\n",
    "plot_well(df, model)\n",
    "confusion_matrix(true, preds)\n",
    "1\n",
    "  ```\n",
    "\n",
    "  <details>\n",
    "  <summary><b>→ Hints</b></summary>\n",
    "      \n",
    "  - The model is close to over fitting to just increasing epochs, or hidden size likely wont help\n",
    "\n",
    "  - To change a value\n",
    "      - Hint search for \"# CHANGE ME\" below\n",
    "      - Change values\n",
    "      - then run the cells\n",
    "      - wait, some values will take longer\n",
    "\n",
    "  </details>\n",
    "\n",
    "  <br/>\n",
    "  <br/>\n",
    "  <details>\n",
    "  <summary>\n",
    "    <b>→ Solution</b>\n",
    "  </summary>\n",
    "\n",
    "  ```python\n",
    "  # this helps a lot\n",
    "  seq_length = 1000 \n",
    "  ```\n",
    "\n",
    "  </details>\n",
    "\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T06:44:16.670Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "seq_length = 400  # CHANGE ME\n",
    "\n",
    "# Prepare data\n",
    "x_train, y_train = get_sequences(df_train, seq_length=seq_length)\n",
    "x_test, y_test = get_sequences(df_test, seq_length=seq_length)\n",
    "\n",
    "# Init the model\n",
    "model = LSTM(\n",
    "    input_size=x_train[0].shape[-1],\n",
    "    hidden_size=64, # CHANGE ME\n",
    "    num_layers=3, # CHANGE ME\n",
    "    output_size=output_size,\n",
    ").to(device)\n",
    "\n",
    "# Init the optimiser, and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # CHANGE ME\n",
    "loss_func = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Train\n",
    "training_loop(x_train, y_train, x_test, y_test, model, epochs=10, bs=128) # Change me\n",
    "\n",
    "# Measure baseline\n",
    "pred_baseline = np.roll(np.array(y_test), shift=shift_length)\n",
    "score_prev_base=score_fn(y_test, pred_baseline)\n",
    "print(f'baseline accuracy {score_prev_base:2.2%} for prev {shift_length} facies values')\n",
    "print(f'{n_wells} wells. {max_lithologies} lithologies')\n",
    "print(f'context length of {0.15*seq_length} m or {seq_length} intervals')\n",
    "print(f'model can see human labels up to {shift_length*0.15}m above. Or {shift_length} intervals')\n",
    "print(f'baseline accuracy {score_prev_base:2.2%} for prev {shift_length} facies values')\n",
    "\n",
    "# Test\n",
    "preds, true, loss, acc = test_epoch(x_test, y_test, model)\n",
    "print('acc', acc)\n",
    "\n",
    "df_report = classification_report(true, preds, labels=range(len(encoder.classes_)), target_names=encoder.classes_)\n",
    "display(df_report[df_report.support>0])\n",
    "\n",
    "plot_well(df, model)\n",
    "confusion_matrix(true, preds)\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T03:43:57.397359Z",
     "start_time": "2020-10-05T03:43:55.789815Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "- [Introduction to RNN](http://slazebni.cs.illinois.edu/spring17/lec02_rnn.pdf)\n",
    "- [A friendly introduction to Recurrent Neural Networks](https://www.youtube.com/watch?v=UNmqTiOnRfg)\n",
    "- [Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM)](https://www.youtube.com/watch?v=WCUNPb-5EYI&t=97s)\n",
    "- [Introduction to LSTM](https://medium.com/x8-the-ai-community/a-7-minute-introduction-to-lstm-5e1480e6f52a)\n",
    "- [LSTM and GRU](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)\n",
    "- [Time Series Prediction with LSTM](https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/)\n",
    "- [Building RNN from scratch](https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Recurrent Neural Networks.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "deep_ml_curriculum",
   "language": "python",
   "name": "deep_ml_curriculum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0de1f271c85a490db7b212f29a2e98db": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bb877b53ce64c5c89a0e0fddf99510f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f31d4f3e4f343c2b45596c7a8acd798",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9113c8e51cb44ccba8f7d76dcaf1f2b3",
      "value": 100
     }
    },
    "2249f632765e44fb873c5b52e38952b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2c444039590c49d7b0ba75e37b9396a2",
       "IPY_MODEL_779b8d08fe4d424296bd06322a8c055b"
      ],
      "layout": "IPY_MODEL_ea24cf68548440d6bb27527e1e8b231a"
     }
    },
    "239a06e64dee49a0bc6a64ae48782dfa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2708bb5b48024a0a97470b123004e914": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2c444039590c49d7b0ba75e37b9396a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_239a06e64dee49a0bc6a64ae48782dfa",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2708bb5b48024a0a97470b123004e914",
      "value": 500
     }
    },
    "2e9111de005e458faa5dadf8f4757ce0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c46c1b220494ef4830e6c1f6c75f2d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e2682af756042e5808bb471c318a154": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70ccc0ca7efc48599f9514c6201b2073": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "779b8d08fe4d424296bd06322a8c055b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0de1f271c85a490db7b212f29a2e98db",
      "placeholder": "​",
      "style": "IPY_MODEL_ec7d5619230044ab8149273a33c7d1db",
      "value": " 500/500 [00:13&lt;00:00, 38.17it/s]"
     }
    },
    "8f31d4f3e4f343c2b45596c7a8acd798": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9113c8e51cb44ccba8f7d76dcaf1f2b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "967cb446a5ee4a5a9f592104126b6aeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c46c1b220494ef4830e6c1f6c75f2d3",
      "placeholder": "​",
      "style": "IPY_MODEL_996b5d7e77e14820ac4694ce102f3d2d",
      "value": " 100/100 [06:03&lt;00:00,  3.64s/it]"
     }
    },
    "996b5d7e77e14820ac4694ce102f3d2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a37da43322f54d0cb3a587c85f87f146": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1bb877b53ce64c5c89a0e0fddf99510f",
       "IPY_MODEL_967cb446a5ee4a5a9f592104126b6aeb"
      ],
      "layout": "IPY_MODEL_2e9111de005e458faa5dadf8f4757ce0"
     }
    },
    "a41a857b0bcf4d16b95599f019f125bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bf8163e5e5d640dc94e74413ce3137b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e2682af756042e5808bb471c318a154",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a41a857b0bcf4d16b95599f019f125bf",
      "value": 500
     }
    },
    "c1048481b4694b12ab408fcb1ddb8b31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf8163e5e5d640dc94e74413ce3137b5",
       "IPY_MODEL_d6d149b77d024d8a81f0df42ee176200"
      ],
      "layout": "IPY_MODEL_c17715512f7c44ca9a1126844f832a41"
     }
    },
    "c17715512f7c44ca9a1126844f832a41": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6d149b77d024d8a81f0df42ee176200": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3806fac15e545f597473d41d3708200",
      "placeholder": "​",
      "style": "IPY_MODEL_70ccc0ca7efc48599f9514c6201b2073",
      "value": " 500/500 [00:08&lt;00:00, 56.35it/s]"
     }
    },
    "ea24cf68548440d6bb27527e1e8b231a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec7d5619230044ab8149273a33c7d1db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3806fac15e545f597473d41d3708200": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
