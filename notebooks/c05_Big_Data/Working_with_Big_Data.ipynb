{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Dask\n",
    "There are many occasions when we have to work with datasets that are so big we can't just load all of it into memory. If we have to work with such a data, what is the solution? One of the libraries in python for this type of problems is __Dask__. Dask is a library for parallel computing. It helps us perform common pandas and numpy opperations on large datasets. In this tutorial we will learn about some of the features of Dask and how it can help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:31:19.195732Z",
     "start_time": "2020-10-04T06:31:19.188717Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "import logging\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the beginning to see the difference in the performance of Dask vs Pandas, let's read a 70 MB csv file with both libraries. Of course 70 MB is not considered a large file and we can easily fit it into memory, but it is large enough to see the advantage of using Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:31:39.154079Z",
     "start_time": "2020-10-04T06:31:39.149238Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"../../data/processed/MNIST/train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also defining a function to report memory usage, so we can see how each method affect the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:31:40.926005Z",
     "start_time": "2020-10-04T06:31:40.918246Z"
    }
   },
   "outputs": [],
   "source": [
    "def memory_usage():\n",
    "    \"\"\"String with current memory usage in MB. Requires `psutil` package.\"\"\"\n",
    "    pid = os.getpid()\n",
    "    mem_bytes = psutil.Process(pid).memory_info().rss\n",
    "    print('[Process {} uses {:.1f}MB]'.format(pid, mem_bytes / 1024 / 1024))\n",
    "    return mem_bytes / 1024 / 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:31:49.877819Z",
     "start_time": "2020-10-04T06:31:49.868979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Process 3292192 uses 2024.4MB]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2024.40625"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see the amount of used memory.<br>\n",
    "Now let's load the data with pandas and see how long it takes to load and how much memory it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:32:07.282456Z",
     "start_time": "2020-10-04T06:32:03.589951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.5 s, sys: 176 ms, total: 3.68 s\n",
      "Wall time: 3.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df1 = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:32:07.290162Z",
     "start_time": "2020-10-04T06:32:07.284838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Process 3292192 uses 2156.4MB]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2156.35546875"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory usage has gone up by about ~250 MB.<br>\n",
    "Now do the same with Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:32:27.500035Z",
     "start_time": "2020-10-04T06:32:27.268433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 220 ms, sys: 7.62 ms, total: 227 ms\n",
      "Wall time: 225 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df2=dd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:32:34.223521Z",
     "start_time": "2020-10-04T06:32:34.215573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Process 3292192 uses 2156.4MB]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2156.35546875"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask read the file in a fraction of a second and used only about 3 MB of memory. How is that possible?\n",
    "\n",
    "It's because Dask doesn't load the data into memory. The data is still on the disk. It only reads the data when it needs to perform calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate the mean for the first 100 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:33:04.006531Z",
     "start_time": "2020-10-04T06:33:03.983532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 ms, sys: 519 µs, total: 12.6 ms\n",
      "Wall time: 10.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label       4.456643\n",
       "pixel0      0.000000\n",
       "pixel1      0.000000\n",
       "pixel2      0.000000\n",
       "pixel3      0.000000\n",
       "             ...    \n",
       "pixel94     3.768381\n",
       "pixel95     5.713881\n",
       "pixel96     7.751238\n",
       "pixel97    10.048857\n",
       "pixel98    12.067738\n",
       "Length: 100, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df1.iloc[:,:100].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see pandas does the calculations in a fraction of a second. <br>\n",
    "Let's try Dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:33:25.381965Z",
     "start_time": "2020-10-04T06:33:25.276083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 99.1 ms, sys: 991 µs, total: 100 ms\n",
      "Wall time: 97.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "avg = df2.iloc[:,100:200].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is also did the operation very quickly. Let's have a look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:33:40.598124Z",
     "start_time": "2020-10-04T06:33:40.588801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=1\n",
       "pixel100    float64\n",
       "pixel99         ...\n",
       "dtype: float64\n",
       "Dask Name: dataframe-mean, 15 tasks"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not returning any numbers. What is happening?<br>\n",
    "The reason is Dask has not calculated the result yet. It only creates a dependency graph (also called Directed Acyclec Graph - DAG), which is basically how the calculations will take place. We need to execute the graph to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:34:24.332298Z",
     "start_time": "2020-10-04T06:34:20.276226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.45 s, sys: 404 ms, total: 4.86 s\n",
      "Wall time: 4.04 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pixel99     13.404952\n",
       "pixel100    13.072714\n",
       "pixel101    11.573810\n",
       "pixel102     9.295500\n",
       "pixel103     6.708333\n",
       "              ...    \n",
       "pixel194     0.345714\n",
       "pixel195     0.025024\n",
       "pixel196     0.000000\n",
       "pixel197     0.017810\n",
       "pixel198     0.112476\n",
       "Length: 100, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "avg.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the results. Also, we can see that this step is the most time consuming step of all. It's because this is where Dask actually goes to disk and reads the data. If you add up the time for all the steps (reading the file and performing calculations) you will see that both take almost the same amount of time to do the operation, with pandas being slightly faster. This shows that Dask is not doing any magic. It's doing the same steps but it's doing it without using as much memory. However, Dask can perform operations in parallel using multiple cpu cores and even multiple machines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mentioned that Dask creates a dependency graph before doing the calculations. We can have a look at this graph and see how it is taking place:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-danger'>To see the graph you need a library called <b>GraphViz</b>. If this library is not installed on your system you will not be able to see the graph.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is one we prepared earlier:\n",
    "\n",
    "![](img/dask_graphviz.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:45:19.902653Z",
     "start_time": "2020-10-04T06:45:19.898726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try commenting this out\n",
    "# # avg.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a progress bar for each computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:36:56.525857Z",
     "start_time": "2020-10-04T06:36:56.432996Z"
    }
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "avg = df2.iloc[:, 100:200].mean()\n",
    "task = avg.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T05:48:45.857630Z",
     "start_time": "2020-10-04T05:48:45.846756Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:37:01.275287Z",
     "start_time": "2020-10-04T06:36:57.381507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  3.9s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    task.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dask dataframe](https://docs.dask.org/en/latest/dataframe-api.html) is very similar to pandas dataframe. It's mostly a subset of the pandas api. Even though the functionalities are limited but you will find many methods from pandas dataframe in Dask as well.\n",
    "\n",
    "A few operations are missing, and some are especially expensive: those that read the whole array. An example is sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:37:24.873504Z",
     "start_time": "2020-10-04T06:37:24.516614Z"
    }
   },
   "outputs": [],
   "source": [
    "task = df2.rolling(window=10).mean().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:37:30.063713Z",
     "start_time": "2020-10-04T06:37:24.876292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  5.2s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    ma_max = task.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:38:17.350268Z",
     "start_time": "2020-10-04T06:38:17.340289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       7.8\n",
       "pixel0      0.0\n",
       "pixel1      0.0\n",
       "pixel2      0.0\n",
       "pixel3      0.0\n",
       "           ... \n",
       "pixel779    6.2\n",
       "pixel780    0.0\n",
       "pixel781    0.0\n",
       "pixel782    0.0\n",
       "pixel783    0.0\n",
       "Length: 785, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:39:15.852533Z",
     "start_time": "2020-10-04T06:39:15.804920Z"
    }
   },
   "outputs": [],
   "source": [
    "task = df2[[\"label\", \"pixel100\", \"pixel300\", \"pixel500\"]].groupby(\"label\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T05:50:04.474976Z",
     "start_time": "2020-10-04T05:49:59.485425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  5.0s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    result = task.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:39:23.890114Z",
     "start_time": "2020-10-04T06:39:23.876428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel100</th>\n",
       "      <th>pixel300</th>\n",
       "      <th>pixel500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.214182</td>\n",
       "      <td>159.355034</td>\n",
       "      <td>12.281704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.353117</td>\n",
       "      <td>3.631298</td>\n",
       "      <td>0.230145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.265262</td>\n",
       "      <td>80.125209</td>\n",
       "      <td>20.892267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.035164</td>\n",
       "      <td>44.818433</td>\n",
       "      <td>0.851299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.815570</td>\n",
       "      <td>86.038802</td>\n",
       "      <td>1.606582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.061660</td>\n",
       "      <td>26.764954</td>\n",
       "      <td>2.630303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79.729272</td>\n",
       "      <td>21.919749</td>\n",
       "      <td>10.156877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>107.960918</td>\n",
       "      <td>0.960464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.739109</td>\n",
       "      <td>111.389614</td>\n",
       "      <td>1.482402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.106256</td>\n",
       "      <td>0.142550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pixel100    pixel300   pixel500\n",
       "label                                  \n",
       "0       5.214182  159.355034  12.281704\n",
       "1       1.353117    3.631298   0.230145\n",
       "2      36.265262   80.125209  20.892267\n",
       "3       5.035164   44.818433   0.851299\n",
       "4       0.815570   86.038802   1.606582\n",
       "5       3.061660   26.764954   2.630303\n",
       "6      79.729272   21.919749  10.156877\n",
       "7       0.000000  107.960918   0.960464\n",
       "8       0.739109  111.389614   1.482402\n",
       "9       0.000000   77.106256   0.142550"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:40:44.790440Z",
     "start_time": "2020-10-04T06:40:43.466984Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-success\">\n",
    "  <h2>Exercise</h2>\n",
    "\n",
    "Use Dask dataframe of MNIST (df2) and follow these steps:\n",
    "    \n",
    "1. Add a new column called `sum` to the dataframe which contains sum of all the pixels\n",
    "2. Use groupby to find the mean value for `sum` for each label\n",
    "      \n",
    "\n",
    "  <details>\n",
    "  <summary><b>→ Hints</b></summary>\n",
    "\n",
    "  * Columns 1 onwards are the pixels. You can access them with `pixels=df2.iloc[:, 1:]`\n",
    "  * Instead of `df['sum']=pixels.sum()` try `df['sum']=pixels.sum(axis=1)` because we want to sum along columns, not rows\n",
    "  * If the dask output is confusing, try with df1 first\n",
    "  * to groupby use `df2.groupby('label').?`, where you replace the `?` with the aggregation operation\n",
    "\n",
    "  </details>\n",
    "\n",
    "  <br/>\n",
    "  <br/>\n",
    "  <details>\n",
    "  <summary>\n",
    "    <b>→ Solution</b>\n",
    "  </summary>\n",
    "\n",
    "  ```python\n",
    "    # With pandas\n",
    "    pixels = df1.loc[:, ['pixel' in c for c in df1.columns]]\n",
    "    df1['sum']=pixels.sum(axis=1)\n",
    "    task = df1[['label','sum']].groupby('label').mean()\n",
    "    print(result)\n",
    "\n",
    "    # With dask\n",
    "    pixels = df2.loc[:, ['pixel' in c for c in df2.columns]]\n",
    "    df2['sum']=pixels.sum(axis=1)\n",
    "    task = df2[['label','sum']].groupby('label').mean()\n",
    "    with ProgressBar():\n",
    "        result=task.compute() \n",
    "    print(result)\n",
    "  ```\n",
    "\n",
    "  </details>\n",
    "\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use Dask DataFrame?\n",
    "\n",
    "Lets visit [the dask page](https://docs.dask.org/en/latest/dataframe.html#common-uses-and-anti-uses) to look at when we should use it\n",
    "\n",
    "It is harder so only if you dataset is larger than memory.\n",
    "\n",
    "If fact also consider:\n",
    "- a database (if you have lots of structured queries)\n",
    "- https://downloadmoreram.com/ ;p\n",
    "- dask array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask Array\n",
    "Dask is not just used to replace pandas. There are also multiple numpy functions which can be replaced by Dask. Dask array is Dask equivalent of a numpy array. By doing so, we can perform the computations in parallel and get the results faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:00:04.227603Z",
     "start_time": "2020-10-04T07:00:04.222872Z"
    }
   },
   "outputs": [],
   "source": [
    "from dask import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:00:04.682018Z",
     "start_time": "2020-10-04T07:00:04.671200Z"
    }
   },
   "outputs": [],
   "source": [
    "big_array = array.random.normal(size=(10000000, 100), chunks=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:00:04.994928Z",
     "start_time": "2020-10-04T07:00:04.985195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 8.00 GB </td> <td> 160.00 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (10000000, 100) </td> <td> (200000, 100) </td></tr>\n",
       "    <tr><th> Count </th><td> 50 Tasks </td><td> 50 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"2\" x2=\"25\" y2=\"2\" />\n",
       "  <line x1=\"0\" y1=\"4\" x2=\"25\" y2=\"4\" />\n",
       "  <line x1=\"0\" y1=\"7\" x2=\"25\" y2=\"7\" />\n",
       "  <line x1=\"0\" y1=\"9\" x2=\"25\" y2=\"9\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"14\" x2=\"25\" y2=\"14\" />\n",
       "  <line x1=\"0\" y1=\"16\" x2=\"25\" y2=\"16\" />\n",
       "  <line x1=\"0\" y1=\"19\" x2=\"25\" y2=\"19\" />\n",
       "  <line x1=\"0\" y1=\"21\" x2=\"25\" y2=\"21\" />\n",
       "  <line x1=\"0\" y1=\"24\" x2=\"25\" y2=\"24\" />\n",
       "  <line x1=\"0\" y1=\"26\" x2=\"25\" y2=\"26\" />\n",
       "  <line x1=\"0\" y1=\"28\" x2=\"25\" y2=\"28\" />\n",
       "  <line x1=\"0\" y1=\"31\" x2=\"25\" y2=\"31\" />\n",
       "  <line x1=\"0\" y1=\"33\" x2=\"25\" y2=\"33\" />\n",
       "  <line x1=\"0\" y1=\"36\" x2=\"25\" y2=\"36\" />\n",
       "  <line x1=\"0\" y1=\"38\" x2=\"25\" y2=\"38\" />\n",
       "  <line x1=\"0\" y1=\"40\" x2=\"25\" y2=\"40\" />\n",
       "  <line x1=\"0\" y1=\"43\" x2=\"25\" y2=\"43\" />\n",
       "  <line x1=\"0\" y1=\"45\" x2=\"25\" y2=\"45\" />\n",
       "  <line x1=\"0\" y1=\"48\" x2=\"25\" y2=\"48\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"25\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"52\" x2=\"25\" y2=\"52\" />\n",
       "  <line x1=\"0\" y1=\"55\" x2=\"25\" y2=\"55\" />\n",
       "  <line x1=\"0\" y1=\"57\" x2=\"25\" y2=\"57\" />\n",
       "  <line x1=\"0\" y1=\"60\" x2=\"25\" y2=\"60\" />\n",
       "  <line x1=\"0\" y1=\"62\" x2=\"25\" y2=\"62\" />\n",
       "  <line x1=\"0\" y1=\"64\" x2=\"25\" y2=\"64\" />\n",
       "  <line x1=\"0\" y1=\"67\" x2=\"25\" y2=\"67\" />\n",
       "  <line x1=\"0\" y1=\"69\" x2=\"25\" y2=\"69\" />\n",
       "  <line x1=\"0\" y1=\"72\" x2=\"25\" y2=\"72\" />\n",
       "  <line x1=\"0\" y1=\"74\" x2=\"25\" y2=\"74\" />\n",
       "  <line x1=\"0\" y1=\"76\" x2=\"25\" y2=\"76\" />\n",
       "  <line x1=\"0\" y1=\"79\" x2=\"25\" y2=\"79\" />\n",
       "  <line x1=\"0\" y1=\"81\" x2=\"25\" y2=\"81\" />\n",
       "  <line x1=\"0\" y1=\"84\" x2=\"25\" y2=\"84\" />\n",
       "  <line x1=\"0\" y1=\"86\" x2=\"25\" y2=\"86\" />\n",
       "  <line x1=\"0\" y1=\"88\" x2=\"25\" y2=\"88\" />\n",
       "  <line x1=\"0\" y1=\"91\" x2=\"25\" y2=\"91\" />\n",
       "  <line x1=\"0\" y1=\"93\" x2=\"25\" y2=\"93\" />\n",
       "  <line x1=\"0\" y1=\"96\" x2=\"25\" y2=\"96\" />\n",
       "  <line x1=\"0\" y1=\"98\" x2=\"25\" y2=\"98\" />\n",
       "  <line x1=\"0\" y1=\"100\" x2=\"25\" y2=\"100\" />\n",
       "  <line x1=\"0\" y1=\"103\" x2=\"25\" y2=\"103\" />\n",
       "  <line x1=\"0\" y1=\"105\" x2=\"25\" y2=\"105\" />\n",
       "  <line x1=\"0\" y1=\"108\" x2=\"25\" y2=\"108\" />\n",
       "  <line x1=\"0\" y1=\"110\" x2=\"25\" y2=\"110\" />\n",
       "  <line x1=\"0\" y1=\"112\" x2=\"25\" y2=\"112\" />\n",
       "  <line x1=\"0\" y1=\"115\" x2=\"25\" y2=\"115\" />\n",
       "  <line x1=\"0\" y1=\"117\" x2=\"25\" y2=\"117\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 25.412617,0.000000 25.412617,120.000000 0.000000,120.000000\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >100</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">10000000</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<normal, shape=(10000000, 100), dtype=float64, chunksize=(200000, 100), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data takes 8 GB if we wanted to store it in RAM. But Dask only generates the numbers in chunks when it needs them. So at each steps it has to deal with a chunk which is ~160 MB in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:01:00.467983Z",
     "start_time": "2020-10-04T07:00:52.401105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  8.0s\n"
     ]
    }
   ],
   "source": [
    "task = (big_array * big_array).mean(axis=1)\n",
    "with ProgressBar():\n",
    "    res = task.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set the chunk size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:01:10.065676Z",
     "start_time": "2020-10-04T07:01:10.052351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 8.00 GB </td> <td> 419.43 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (10000000, 100) </td> <td> (524288, 100) </td></tr>\n",
       "    <tr><th> Count </th><td> 20 Tasks </td><td> 20 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"6\" x2=\"25\" y2=\"6\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"18\" x2=\"25\" y2=\"18\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" />\n",
       "  <line x1=\"0\" y1=\"31\" x2=\"25\" y2=\"31\" />\n",
       "  <line x1=\"0\" y1=\"37\" x2=\"25\" y2=\"37\" />\n",
       "  <line x1=\"0\" y1=\"44\" x2=\"25\" y2=\"44\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"25\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"25\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"62\" x2=\"25\" y2=\"62\" />\n",
       "  <line x1=\"0\" y1=\"69\" x2=\"25\" y2=\"69\" />\n",
       "  <line x1=\"0\" y1=\"75\" x2=\"25\" y2=\"75\" />\n",
       "  <line x1=\"0\" y1=\"81\" x2=\"25\" y2=\"81\" />\n",
       "  <line x1=\"0\" y1=\"88\" x2=\"25\" y2=\"88\" />\n",
       "  <line x1=\"0\" y1=\"94\" x2=\"25\" y2=\"94\" />\n",
       "  <line x1=\"0\" y1=\"100\" x2=\"25\" y2=\"100\" />\n",
       "  <line x1=\"0\" y1=\"106\" x2=\"25\" y2=\"106\" />\n",
       "  <line x1=\"0\" y1=\"113\" x2=\"25\" y2=\"113\" />\n",
       "  <line x1=\"0\" y1=\"119\" x2=\"25\" y2=\"119\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 25.412617,0.000000 25.412617,120.000000 0.000000,120.000000\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >100</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">10000000</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<normal, shape=(10000000, 100), dtype=float64, chunksize=(524288, 100), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_array = array.random.normal(size=(10000000, 100), chunks=(2 ** 19, 100))\n",
    "big_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:01:32.721045Z",
     "start_time": "2020-10-04T07:01:23.635013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  9.0s\n"
     ]
    }
   ],
   "source": [
    "task = (big_array * big_array).mean(axis=1)\n",
    "with ProgressBar():\n",
    "    res = task.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply most of common numpy functions to the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:06:05.928222Z",
     "start_time": "2020-10-04T06:05:53.642721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 12.3s\n"
     ]
    }
   ],
   "source": [
    "task = np.sin(big_array).mean(axis=0)\n",
    "with ProgressBar():\n",
    "    res = task.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:02:27.687302Z",
     "start_time": "2020-10-04T07:02:27.678261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 80.00 MB </td> <td> 4.19 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (10000000,) </td> <td> (524288,) </td></tr>\n",
       "    <tr><th> Count </th><td> 80 Tasks </td><td> 20 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"6\" y1=\"0\" x2=\"6\" y2=\"25\" />\n",
       "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"25\" />\n",
       "  <line x1=\"18\" y1=\"0\" x2=\"18\" y2=\"25\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"25\" />\n",
       "  <line x1=\"31\" y1=\"0\" x2=\"31\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"44\" y1=\"0\" x2=\"44\" y2=\"25\" />\n",
       "  <line x1=\"50\" y1=\"0\" x2=\"50\" y2=\"25\" />\n",
       "  <line x1=\"56\" y1=\"0\" x2=\"56\" y2=\"25\" />\n",
       "  <line x1=\"62\" y1=\"0\" x2=\"62\" y2=\"25\" />\n",
       "  <line x1=\"69\" y1=\"0\" x2=\"69\" y2=\"25\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"25\" />\n",
       "  <line x1=\"81\" y1=\"0\" x2=\"81\" y2=\"25\" />\n",
       "  <line x1=\"88\" y1=\"0\" x2=\"88\" y2=\"25\" />\n",
       "  <line x1=\"94\" y1=\"0\" x2=\"94\" y2=\"25\" />\n",
       "  <line x1=\"100\" y1=\"0\" x2=\"100\" y2=\"25\" />\n",
       "  <line x1=\"106\" y1=\"0\" x2=\"106\" y2=\"25\" />\n",
       "  <line x1=\"113\" y1=\"0\" x2=\"113\" y2=\"25\" />\n",
       "  <line x1=\"119\" y1=\"0\" x2=\"119\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 120.000000,0.000000 120.000000,25.412617 0.000000,25.412617\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >10000000</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<mean_agg-aggregate, shape=(10000000,), dtype=float64, chunksize=(524288,), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T06:06:05.942441Z",
     "start_time": "2020-10-04T06:06:05.932255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.44523401e-05,  2.91849147e-04,  7.97800291e-05,  4.22672647e-04,\n",
       "       -2.64893827e-04,  4.49445406e-05, -1.97220457e-04,  2.57375507e-04,\n",
       "        1.24339347e-04, -1.67133372e-04, -1.59123909e-04, -1.96977795e-04,\n",
       "        2.57346442e-04,  9.05701269e-06, -3.81254536e-04,  2.88215978e-04,\n",
       "       -5.77480898e-05,  3.74030223e-04,  8.57886327e-06,  2.11664952e-04,\n",
       "        3.47935429e-04, -6.55157424e-05, -1.43255233e-04,  1.25077351e-04,\n",
       "        7.00398316e-05, -1.87106181e-04,  3.04475956e-05,  1.07904382e-04,\n",
       "        1.05426570e-04,  1.57521823e-04, -2.50360570e-05, -1.93330598e-04,\n",
       "        9.19008946e-05,  3.19984839e-04,  6.73998300e-05,  5.46276254e-05,\n",
       "       -4.09296259e-04,  1.00864963e-04, -1.09470789e-04,  7.88103327e-05,\n",
       "        5.77154247e-04,  2.46646913e-04, -1.52299322e-04,  3.06137183e-04,\n",
       "        2.89138717e-04,  3.14024205e-05, -1.46148689e-04,  2.01544687e-05,\n",
       "        1.88805327e-04, -4.65494275e-04,  1.68623797e-04, -7.87147689e-05,\n",
       "        3.74644162e-04,  9.94059862e-05, -1.29343368e-04, -3.05193553e-04,\n",
       "        4.73502614e-05, -3.11466714e-04, -8.24701005e-05,  8.87821228e-05,\n",
       "        2.51695441e-04,  2.70208416e-04,  3.14148851e-04,  7.78432370e-05,\n",
       "        2.01030433e-04,  2.35190610e-05,  9.99065091e-05,  2.01424702e-04,\n",
       "       -2.75263311e-05,  7.08076620e-05, -1.68827747e-04,  2.04224778e-04,\n",
       "        6.14735180e-06, -1.86098500e-04,  3.40030452e-05, -1.25325242e-04,\n",
       "        2.07121851e-04, -6.36723954e-06, -1.85826715e-04,  2.78518444e-04,\n",
       "        4.63926284e-05,  8.41849945e-05, -1.00447928e-04,  2.44582759e-04,\n",
       "       -4.13152836e-04, -2.82853381e-05, -2.96947218e-04,  1.48168903e-04,\n",
       "       -3.92813591e-04,  1.60736803e-04, -1.52340278e-04, -4.06562958e-05,\n",
       "       -1.61326430e-04, -1.60360607e-04, -9.09992793e-05, -7.19626335e-06,\n",
       "       -1.86758147e-04, -1.16011632e-05,  3.14771298e-04,  4.69042108e-05])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Create two Dask random arrays of size 10,000,000-by-100. \n",
    "- Find the difference between the two `y = ..`\n",
    "- and pass it to `array.linalg.norm` using argument `axis=1`. \n",
    "- Calculate the result and create a histogram of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T05:26:34.023645Z",
     "start_time": "2020-10-04T05:26:24.225Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:04:25.331001Z",
     "start_time": "2020-10-04T07:04:25.308406Z"
    }
   },
   "source": [
    " <div class=\"alert alert-success\">\n",
    "  <h2>Exercise</h2>\n",
    "\n",
    "  Description:\n",
    "\n",
    "- Create two Dask random arrays of size 10,000,000-by-100. \n",
    "- Find the difference between the two `y = ..`\n",
    "- and pass it to `array.linalg.norm` using argument `axis=1`. \n",
    "- Calculate the result and create a histogram of it.\n",
    "      \n",
    "\n",
    "  <details>\n",
    "  <summary><b>→ Hints</b></summary>\n",
    "      \n",
    "      Replace the question marks `?`\n",
    "\n",
    "```python\n",
    "a = array.random.normal(size=(10000000, 100), chunks=200000)\n",
    "b = array.random.normal(size=(10000000, 100), chunks=200000)\n",
    "r = array.linalg.norm(?, axis=1)\n",
    "r.?\n",
    "```\n",
    "\n",
    "  </details>\n",
    "\n",
    "  <br/>\n",
    "  <br/>\n",
    "  <details>\n",
    "  <summary>\n",
    "    <b>→ Solution</b>\n",
    "  </summary>\n",
    "\n",
    "  ```python\n",
    "    x1 = array.random.random(size=(10000000,100))\n",
    "    x2 = array.random.random(size=(10000000,100))\n",
    "    y = x2-x1\n",
    "    d = array.linalg.norm(y,axis=1)\n",
    "    with ProgressBar():\n",
    "        result = d.compute()\n",
    "    hist(result,bins=100);\n",
    "  ```\n",
    "\n",
    "  </details>\n",
    "\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delayed\n",
    "Dask delayed is a method for parallelising code where you can't write your code directly as dataframe or array operation. `Dask.delayed` is an easy-to-use tool to quickly parallelise these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following functions. The first one takes an input, waits for one second and returns the value. The second function takes two inputs, waits for one second and returns the sum. We are using these functions to represent tasks that are time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:08:48.800785Z",
     "start_time": "2020-10-04T07:08:48.794890Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "\n",
    "def task1(x):\n",
    "    sleep(1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def task2(x, y):\n",
    "    sleep(1)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we pass two values separately into the first function and then pass the results into the second function, we will have the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:08:53.787353Z",
     "start_time": "2020-10-04T07:08:50.776346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.77 ms, sys: 96 µs, total: 4.86 ms\n",
      "Wall time: 3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x1 = task1(1)\n",
    "x2 = task1(2)\n",
    "y = task2(x1,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each of these functions are taking one second; therefore, the entire block takes three seconds. But the calculation for `x1` is totally independent of the calculation for `x2`. If we were able to do these operation simultaneously we could save time. This is where `Dask.delayed` comes into play. We need to convert the functions into `delayed` functions so Dask can handle parallelisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:09:01.974666Z",
     "start_time": "2020-10-04T07:09:01.969037Z"
    }
   },
   "outputs": [],
   "source": [
    "task1_delayed = dask.delayed(task1)\n",
    "task2_delayed = dask.delayed(task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now instead of the original function we use the delayed functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:09:03.512910Z",
     "start_time": "2020-10-04T07:09:03.505322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.3 ms, sys: 158 µs, total: 1.46 ms\n",
      "Wall time: 836 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x1 = task1_delayed(1)\n",
    "x2 = task1_delayed(2)\n",
    "y = task2_delayed(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:09:09.900863Z",
     "start_time": "2020-10-04T07:09:07.888165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.09 ms, sys: 114 µs, total: 7.21 ms\n",
      "Wall time: 2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we saved one second! `x1` and `x2` where calculated in parallel, and then `y` was calculated using `x1` and `x2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly create delayed functions using `dask.delayed` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:09:37.762838Z",
     "start_time": "2020-10-04T07:09:37.755379Z"
    }
   },
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def task1(x):\n",
    "    sleep(1)\n",
    "    return x\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def task2(x, y):\n",
    "    sleep(1)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:09:40.024964Z",
     "start_time": "2020-10-04T07:09:38.011370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.42 ms, sys: 3.91 ms, total: 7.32 ms\n",
      "Wall time: 2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "x1 = task1(1)\n",
    "x2 = task1(2)\n",
    "y = task2(x1,x2)\n",
    "y.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Numba?\n",
    "\n",
    "Numba is a **just-in-time**, **type-specializing**, **function compiler** for accelerating **numerically-focused** Python.  That's a long list, so let's break down those terms:\n",
    "\n",
    " * **function compiler**: Numba compiles Python functions, not entire applications, and not parts of functions.  Numba does not replace your Python interpreter, but is just another Python module that can turn a function into a (usually) faster function. \n",
    " * **type-specializing**: Numba speeds up your function by generating a specialized implementation for the specific data types you are using.  Python functions are designed to operate on generic data types, which makes them very flexible, but also very slow.  In practice, you only will call a function with a small number of argument types, so Numba will generate a fast implementation for each set of types.\n",
    " * **just-in-time**: Numba translates functions when they are first called.  This ensures the compiler knows what argument types you will be using.  This also allows Numba to be used interactively in a Jupyter notebook just as easily as a traditional application\n",
    " * **numerically-focused**: Currently, Numba is focused on numerical data types, like `int`, `float`, and `complex`.  There is very limited string processing support, and many string use cases are not going to work well on the GPU.  To get best results with Numba, you will likely be using NumPy arrays.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Steps\n",
    "\n",
    "Let's write our first Numba function and compile it for the **CPU**.  The Numba compiler is typically enabled by applying a *decorator* to a Python function.  Decorators are functions that transform Python functions.  Here we will use the CPU compilation decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:10:37.915855Z",
     "start_time": "2020-10-04T07:10:37.233114Z"
    }
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import math\n",
    "\n",
    "\n",
    "@jit\n",
    "def hypot(x, y):\n",
    "    # Implementation from https://en.wikipedia.org/wiki/Hypot\n",
    "    x = abs(x)\n",
    "    y = abs(y)\n",
    "    t = min(x, y)\n",
    "    x = max(x, y)\n",
    "    t = t / x\n",
    "    return x * math.sqrt(1 + t * t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is equivalent to writing:\n",
    "``` python\n",
    "def hypot(x, y):\n",
    "    x = abs(x);\n",
    "    y = abs(y);\n",
    "    t = min(x, y);\n",
    "    x = max(x, y);\n",
    "    t = t / x;\n",
    "    return x * math.sqrt(1+t*t)\n",
    "    \n",
    "hypot = jit(hypot)\n",
    "```\n",
    "This means that the Numba compiler is just a function you can call whenever you want!\n",
    "\n",
    "Let's try out our hypotenuse calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:10:38.996595Z",
     "start_time": "2020-10-04T07:10:38.670589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypot(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time we call `hypot`, the compiler is triggered and compiles a machine code implementation for float inputs.  Numba also saves the original Python implementation of the function in the `.py_func` attribute, so we can call the original Python code to make sure we get the same answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:10:40.711443Z",
     "start_time": "2020-10-04T07:10:40.704609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypot.py_func(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking\n",
    "\n",
    "An important part of using Numba is measuring the performance of your new code.  Let's see if we actually sped anything up.  The easiest way to do this in the Jupyter notebook is to use the `%timeit` magic function.  Let's first measure the speed of the original Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:10:55.117242Z",
     "start_time": "2020-10-04T07:10:45.511235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17 µs ± 9.04 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hypot.py_func(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%timeit` magic runs the statement many times to get an accurate estimate of the run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:10:57.748686Z",
     "start_time": "2020-10-04T07:10:55.119955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324 ns ± 13.2 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hypot(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba did a pretty good job with this function.  It's 3x faster than the pure Python version.\n",
    "\n",
    "Of course, the `hypot` function is already present in the Python module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:11:13.647876Z",
     "start_time": "2020-10-04T07:10:57.752041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 ns ± 4.87 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit math.hypot(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's built-in is even faster than Numba!  This is because Numba does introduce some overhead to each function call that is larger than the function call overhead of Python itself.  Extremely fast functions (like the above one) will be hurt by this.\n",
    "\n",
    "(However, if you call one Numba function from another one, there is very little function overhead, sometimes even zero if the compiler inlines the function into the other one.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does Numba work?\n",
    "\n",
    "The first time we called our Numba-wrapped `hypot` function, the following process was initiated:\n",
    "\n",
    "![Numba Flowchart](img/numba_flowchart.png \"The compilation process\")\n",
    "\n",
    "We can see the result of type inference by using the `.inspect_types()` method, which prints an annotated version of the source code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:11:13.655723Z",
     "start_time": "2020-10-04T07:11:13.650710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypot (float64, float64)\n",
      "--------------------------------------------------------------------------------\n",
      "# File: <ipython-input-110-6918c9bc301b>\n",
      "# --- LINE 5 --- \n",
      "# label 0\n",
      "\n",
      "@jit\n",
      "\n",
      "# --- LINE 6 --- \n",
      "\n",
      "def hypot(x, y):\n",
      "\n",
      "    # --- LINE 7 --- \n",
      "\n",
      "    # Implementation from https://en.wikipedia.org/wiki/Hypot\n",
      "\n",
      "    # --- LINE 8 --- \n",
      "    #   x = arg(0, name=x)  :: float64\n",
      "    #   y = arg(1, name=y)  :: float64\n",
      "    #   $0.1 = global(abs: <built-in function abs>)  :: Function(<built-in function abs>)\n",
      "    #   $0.3 = call $0.1(x, func=$0.1, args=[Var(x, <ipython-input-110-6918c9bc301b> (8))], kws=(), vararg=None)  :: (float64,) -> float64\n",
      "    #   del x\n",
      "    #   del $0.1\n",
      "    #   x.1 = $0.3  :: float64\n",
      "    #   del $0.3\n",
      "\n",
      "    x = abs(x)\n",
      "\n",
      "    # --- LINE 9 --- \n",
      "    #   $0.4 = global(abs: <built-in function abs>)  :: Function(<built-in function abs>)\n",
      "    #   $0.6 = call $0.4(y, func=$0.4, args=[Var(y, <ipython-input-110-6918c9bc301b> (8))], kws=(), vararg=None)  :: (float64,) -> float64\n",
      "    #   del y\n",
      "    #   del $0.4\n",
      "    #   y.1 = $0.6  :: float64\n",
      "    #   del $0.6\n",
      "\n",
      "    y = abs(y)\n",
      "\n",
      "    # --- LINE 10 --- \n",
      "    #   $0.7 = global(min: <built-in function min>)  :: Function(<built-in function min>)\n",
      "    #   $0.10 = call $0.7(x.1, y.1, func=$0.7, args=[Var(x.1, <ipython-input-110-6918c9bc301b> (8)), Var(y.1, <ipython-input-110-6918c9bc301b> (9))], kws=(), vararg=None)  :: (float64, float64) -> float64\n",
      "    #   del $0.7\n",
      "    #   t = $0.10  :: float64\n",
      "    #   del $0.10\n",
      "\n",
      "    t = min(x, y)\n",
      "\n",
      "    # --- LINE 11 --- \n",
      "    #   $0.11 = global(max: <built-in function max>)  :: Function(<built-in function max>)\n",
      "    #   $0.14 = call $0.11(x.1, y.1, func=$0.11, args=[Var(x.1, <ipython-input-110-6918c9bc301b> (8)), Var(y.1, <ipython-input-110-6918c9bc301b> (9))], kws=(), vararg=None)  :: (float64, float64) -> float64\n",
      "    #   del y.1\n",
      "    #   del x.1\n",
      "    #   del $0.11\n",
      "    #   x.2 = $0.14  :: float64\n",
      "    #   del $0.14\n",
      "\n",
      "    x = max(x, y)\n",
      "\n",
      "    # --- LINE 12 --- \n",
      "    #   $0.17 = t / x.2  :: float64\n",
      "    #   del t\n",
      "    #   t.1 = $0.17  :: float64\n",
      "    #   del $0.17\n",
      "\n",
      "    t = t / x\n",
      "\n",
      "    # --- LINE 13 --- \n",
      "    #   $0.19 = global(math: <module 'math' from '/home/wassname/.pyenv/versions/3.7.3/lib/python3.7/lib-dynload/math.cpython-37m-x86_64-linux-gnu.so'>)  :: Module(<module 'math' from '/home/wassname/.pyenv/versions/3.7.3/lib/python3.7/lib-dynload/math.cpython-37m-x86_64-linux-gnu.so'>)\n",
      "    #   $0.20 = getattr(value=$0.19, attr=sqrt)  :: Function(<built-in function sqrt>)\n",
      "    #   del $0.19\n",
      "    #   $const0.21 = const(int, 1)  :: Literal[int](1)\n",
      "    #   $0.24 = t.1 * t.1  :: float64\n",
      "    #   del t.1\n",
      "    #   $0.25 = $const0.21 + $0.24  :: float64\n",
      "    #   del $const0.21\n",
      "    #   del $0.24\n",
      "    #   $0.26 = call $0.20($0.25, func=$0.20, args=[Var($0.25, <ipython-input-110-6918c9bc301b> (13))], kws=(), vararg=None)  :: (float64,) -> float64\n",
      "    #   del $0.25\n",
      "    #   del $0.20\n",
      "    #   $0.27 = x.2 * $0.26  :: float64\n",
      "    #   del x.2\n",
      "    #   del $0.26\n",
      "    #   $0.28 = cast(value=$0.27)  :: float64\n",
      "    #   del $0.27\n",
      "    #   return $0.28\n",
      "\n",
      "    return x * math.sqrt(1 + t * t)\n",
      "\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "hypot.inspect_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Numba's type names tend to mirror the NumPy type names, so a Python `float` is a `float64` (also called \"double precision\" in other languages).  Taking a look at the data types can sometimes be important in GPU code because the performance of `float32` and `float64` computations will be very different on CUDA devices.  An accidental upcast can dramatically slow down a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When Things Go Wrong\n",
    "\n",
    "Numba cannot compile all Python code.  Some functions don't have a Numba-translation, and some kinds of Python types can't be efficiently compiled at all (yet).  For example, Numba does not support `FrozenSet` (as of this tutorial):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:11:13.727826Z",
     "start_time": "2020-10-04T07:11:13.658059Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-117-93f85c190644>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"cannot_compile\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: typing of argument at <ipython-input-117-93f85c190644> (3)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-117-93f85c190644>\", line 3:\u001b[0m\n",
      "\u001b[1mdef cannot_compile(x):\n",
      "\u001b[1m    return \"a\" in x\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "/home/wassname/.pyenv/versions/jup3.7.3/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"cannot_compile\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-117-93f85c190644>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef cannot_compile(x):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/home/wassname/.pyenv/versions/jup3.7.3/lib/python3.7/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-117-93f85c190644>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef cannot_compile(x):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit\n",
    "def cannot_compile(x):\n",
    "    return \"a\" in x\n",
    "\n",
    "\n",
    "cannot_compile(frozenset((\"a\", \"b\", \"c\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, what happened??  By default, Numba will fall back to a mode, called \"object mode,\" which does not do type-specialization.  Object mode exists to enable other Numba functionality, but in many cases, you want Numba to tell you if type inference fails.  You can force \"nopython mode\" (the other compilation mode) by passing arguments to the decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:11:13.745541Z",
     "start_time": "2020-10-04T07:11:13.730487Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed in nopython mode pipeline (step: nopython frontend)\n",
      "\u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: typing of argument at <ipython-input-118-13ba80368805> (3)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-118-13ba80368805>\", line 3:\u001b[0m\n",
      "\u001b[1mdef cannot_compile(x):\n",
      "\u001b[1m    return \"a\" in x\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\n",
      "This error may have been caused by the following argument(s):\n",
      "- argument 0: \u001b[1mcannot determine Numba type of <class 'frozenset'>\u001b[0m\n",
      "\n",
      "This is not usually a problem with Numba itself but instead often caused by\n",
      "the use of unsupported features or an issue in resolving types.\n",
      "\n",
      "To see Python/NumPy features supported by the latest release of Numba visit:\n",
      "http://numba.pydata.org/numba-doc/latest/reference/pysupported.html\n",
      "and\n",
      "http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html\n",
      "\n",
      "For more information about typing errors and how to debug them visit:\n",
      "http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile\n",
      "\n",
      "If you think your code should work with Numba, please report the error message\n",
      "and traceback, along with a minimal reproducer at:\n",
      "https://github.com/numba/numba/issues/new\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-118-13ba80368805>\", line 6, in <module>\n",
      "    cannot_compile(frozenset((\"a\", \"b\", \"c\")))\n",
      "  File \"/home/wassname/.pyenv/versions/jup3.7.3/lib/python3.7/site-packages/numba/dispatcher.py\", line 401, in _compile_for_args\n",
      "    error_rewrite(e, 'typing')\n",
      "  File \"/home/wassname/.pyenv/versions/jup3.7.3/lib/python3.7/site-packages/numba/dispatcher.py\", line 344, in error_rewrite\n",
      "    reraise(type(e), e, None)\n",
      "  File \"/home/wassname/.pyenv/versions/jup3.7.3/lib/python3.7/site-packages/numba/six.py\", line 668, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)\n",
      "\u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: typing of argument at <ipython-input-118-13ba80368805> (3)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-118-13ba80368805>\", line 3:\u001b[0m\n",
      "\u001b[1mdef cannot_compile(x):\n",
      "\u001b[1m    return \"a\" in x\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\n",
      "This error may have been caused by the following argument(s):\n",
      "- argument 0: \u001b[1mcannot determine Numba type of <class 'frozenset'>\u001b[0m\n",
      "\n",
      "This is not usually a problem with Numba itself but instead often caused by\n",
      "the use of unsupported features or an issue in resolving types.\n",
      "\n",
      "To see Python/NumPy features supported by the latest release of Numba visit:\n",
      "http://numba.pydata.org/numba-doc/latest/reference/pysupported.html\n",
      "and\n",
      "http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html\n",
      "\n",
      "For more information about typing errors and how to debug them visit:\n",
      "http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile\n",
      "\n",
      "If you think your code should work with Numba, please report the error message\n",
      "and traceback, along with a minimal reproducer at:\n",
      "https://github.com/numba/numba/issues/new\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@jit(nopython=True)\n",
    "def cannot_compile(x):\n",
    "    return \"a\" in x\n",
    "\n",
    "try:\n",
    "    cannot_compile(frozenset((\"a\", \"b\", \"c\")))\n",
    "except Exception as e:\n",
    "    logging.exception(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get an exception when Numba tries to compile the function, with an error that says:\n",
    "```\n",
    "- argument 0: cannot determine Numba type of <class 'frozenset'>\n",
    "```\n",
    "which is the underlying problem. Numba doesn't know about frozenset. There are classes that we use regularly in our code but they might not be defined in Numba. An example of a common class that you cannot use in Numba is pandas data frames. <br>Now the question is: what does Numba support? Some of the types/classes that are supported by Numba are listed below:\n",
    "* Numbers (integers, floats, etc)\n",
    "* Numpy arrays\n",
    "* Strings\n",
    "* Lists and tuples (note that a list/tuple of numbers or strings is supported but a list of lists is not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we want the last example to be compiled successfully by Numba jit, we need to use a tuple or a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:11:14.547372Z",
     "start_time": "2020-10-04T07:11:13.747838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit(nopython=True)\n",
    "def can_compile(x):\n",
    "    return \"a\" in x\n",
    "\n",
    "\n",
    "can_compile((\"a\", \"b\", \"c\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Gregory–Leibniz infinite series converges to $\\pi$:\n",
    "$$\\pi = \\frac{4}{1} - \\frac{4}{3} + \\frac{4}{5} - \\frac{4}{7} + \\frac{4}{9} - \\frac{4}{11} + \\frac{4}{13} - \\cdots$$\n",
    "\n",
    "Write a Numba function which calculates the sum of first $n$ terms in this series. Then test its speed agains normal Python function for $ n = 1000000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T07:11:14.554260Z",
     "start_time": "2020-10-04T07:11:14.550953Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Solution</summary>\n",
    "\n",
    "```Python\n",
    "    @jit\n",
    "    def gl_pi(n):\n",
    "        pi = 0\n",
    "        for i in range(n):\n",
    "            if i%2 ==0:\n",
    "                pi += 4/(2*i+1)\n",
    "            else:\n",
    "                pi -= 4/(2*i+1)\n",
    "        return pi \n",
    "```\n",
    "\n",
    "<b>Numba function speed test:</b>\n",
    "```Python\n",
    "    %timeit gl_pi(1000000) \n",
    "```\n",
    "    \n",
    "<b>Normal Python function speed test:</b>\n",
    "```Python\n",
    "    %timeit gl_pi.py_func(1000000) \n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "The following sources where used for creation of this notebook:\n",
    "- https://github.com/NCAR/ncar-python-tutorial\n",
    "- https://github.com/stevesimmons/pydata-ams2017-pandas-and-dask-from-the-inside\n",
    "- https://github.com/numba/euroscipy2019-numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Reading\n",
    "- [Dask documentation](https://docs.dask.org/en/latest/)\n",
    "- [Why Dask?](https://docs.dask.org/en/latest/why.html)\n",
    "- [Distributed Machine Learning with Python and Dask](https://towardsdatascience.com/distributed-machine-learning-with-python-and-dask-2d6bae91a726)\n",
    "- [Speeding up your Algorithms — Dask](https://towardsdatascience.com/speeding-up-your-algorithms-part-4-dask-7c6ed79994ef)\n",
    "- [Speeding Up your Algorithms — Numba](https://towardsdatascience.com/speed-up-your-algorithms-part-2-numba-293e554c5cc1)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
