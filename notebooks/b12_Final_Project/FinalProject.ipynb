{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualisation and Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Welcome to the final project of Data Visualisation and Data Science!__ \n",
    "\n",
    "Sometimes the biggest step in learning is going from the ordered tutorial environment into the wild. It can be confusing and frustrating, so it's best to give it a try now, while you can get help.\n",
    "\n",
    "In this project, you will explore a geological image dataset by applying some popular supervised and unsupervised machine learning techniques using scikit-learn. \n",
    "\n",
    "This notebook will walk you through some of the steps for preprocessing and preparing the dataset. As part of the final project, you will need to complete this notebook by building some models, creating visualisation to better represent the data and evaluating those models.\n",
    "\n",
    "For this final project you will try to do the following tasks:\n",
    "\n",
    "- Data preparation: Dimensionality Reduction and plot\n",
    "- Model Development: Clustering vs Supervised learning and plot\n",
    "- Evaluation: Evaluate the best model based on metrics\n",
    "  \n",
    "# Proceedure\n",
    "  \n",
    "This is hard, so you will need to ask the instructors for guidance in how to do it. We suggest:\n",
    "1. The instructor will walk you through the problem and starter code\n",
    "2. Feel confused, and realise this is hard\n",
    "3. Read the whole problem\n",
    "4. Read the whole notebook\n",
    "5. Try to understand the what the first step is\n",
    "6. Look for code you can use in previous notebooks you can copy\n",
    "7. Encounter a problem, ask for help\n",
    "8. Repeat\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from ipywidgets import interact, widgets\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Magic Function\n",
    "%matplotlib inline\n",
    "# Hide all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "\n",
    "This data is from the [DeepRock-SR](https://www.digitalrocksportal.org/projects/215) dataset. [Paper](https://arxiv.org/abs/1907.07131)\n",
    "\n",
    "The 2D dataset comprises of twelve thousand 500x500 HR unsegmented slices of various digital rocks with image resolution ranging from 2.7 to 25 um.\n",
    "\n",
    "- Rocks: Sandstone, Carbonate, and Coal Datasets\n",
    "- Images are taken with [micro‚Äêcomputed tomography](https://en.wikipedia.org/wiki/X-ray_microtomography). This uses x-ray from many differen't angles to producee pixel sizes of the cross-sections are in the micrometre range\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project we will used a preproceseed version of the dataset. Please check the notebook ***** to understand the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path(\"../../data/processed/deep-rock-sr/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at what data is available\n",
    "sorted(datadir.glob(\"**/*train_*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2D Images\n",
    "data_train = torchvision.datasets.ImageFolder(\n",
    "    \"../../data/processed/deep-rock-sr/DeepRockSR-2D/\",\n",
    "    is_valid_file=lambda f: (\"train_LR_default_X4\" in f) and not (\"shuffle\" in f),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset have three types of rock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualise the first image in the dataset\n",
    "data_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images in the dataset\n",
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this dataset, the first\n",
    "data_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first position there is a PIL image and the second one correspond to the label:\n",
    "\n",
    "0: carbonate2D\n",
    "1: coal2D\n",
    "2: sandstone3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(interval):\n",
    "    print(\"label:\", data_train[interval][1])\n",
    "    print(\"label_str:\", data_train.classes[data_train[interval][1]])\n",
    "    display(data_train[interval][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (advanced) Now let's visualise all images in the dataset using `interact`.\n",
    "# We can pass any python function followed by arguments (e.g. `interval` to the show_image function)\n",
    "interact(show_image, interval=(0, len(data_train) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are a type of data. For colored images they usually range from 0 to 255 and have 3 dimensions for every channel (R)ed, (G)reen, (B)lue.\n",
    "\n",
    "More information related to the RGB colors space: https://en.wikipedia.org/wiki/RGB_color_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check any random image\n",
    "img = data_train[4799][0]\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That same image can be analyse as a multidimensional array where every pixel has 3 values in the RGB color space.\n",
    "\n",
    "To check the values we will first need to convert the PIL image to an array. We will do so using the numpy library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to flatten out the array to one single dimension we would have a vector with size 46875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "125 * 125 * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we have an image with a size of 125x125 and 3 channels (RGB channels). Let's have a look at the data inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the images are actually gray-scale images (no colored) they will only need one channel instead of three.\n",
    "\n",
    "We can take only one channel instead of three, whichseems to be duplicated data  in these case. But first, let's convert the images into arrays and split it into the features `X` and target `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.array(img) for (img, target) in data_train])\n",
    "y = np.array(data_train.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this line of code we are selecting only the first channel and reshaping our features array\n",
    "X = X[:, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "len_before = 125 * 125 * 3\n",
    "len_after = 125 * 125\n",
    "print(\"No. fearures before:\", len_before)\n",
    "print(\"No. features now:\", len_after)\n",
    "print(\n",
    "    \"So we just removed a 1/3 of the redundant data. That's about {} less than before\".format(len_before - len_after)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0])\n",
    "print(\"Shape:\", X[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if remove the right channels. We can use `Image.fromarray` to convert back an array to a PIL Image. We will do this just to visually check if the new array is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image.fromarray(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "Complete the code and organise your code in a clear way. Add comments to your code the best as you can to explain your approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation and visualisation\n",
    "\n",
    "  - Apply 3 different techniques of unsupervised learning for Dimensionality Reduction.\n",
    "  - Select the appropiate number of features for each tecnique applied.\n",
    "  - Visualise the 2d plots for the 3 different clusters (Each cluster representing one type of rock)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Development\n",
    "\n",
    "  - Use 2 different techniques of clustering and create 2d plots to visualise those.\n",
    "      <div class=\"alert alert-info\" style=\"font-size:100%\">\n",
    "<b>HINT</b>: <br>\n",
    "        Use the same reduced data you used for the 2d plots. You might find that some tecniques works better than other. So it is worth to explore and visualise different 2d clusters.\n",
    "      </div>\n",
    "    \n",
    "  - Use 3 different supervised learning techniques to predict if an image corresponds to `carbonate`,`coal`, or `sandstone` and evaluate their performance.\n",
    "  - Choose the best one based on the metrics below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation\n",
    "\n",
    "  - Evaluate the supervised learning models created using TP,TN, FP, FN, accuracy, recall, precision, confusion matrixc, F1-Score, AUC and ROC curves. Create visualisations when possible for those metrics (For example, AUC, Confusion Matrix and ROC). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
