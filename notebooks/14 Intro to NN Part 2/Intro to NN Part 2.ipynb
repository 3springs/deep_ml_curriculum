{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:13.843444Z",
     "start_time": "2020-08-10T13:19:13.367535Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's import some libraries first\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import  nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction to Pytorch \n",
    "There are different architectures for Neural Networks (NNs). Those architectures are defined by blocks called layers. In this notebook we will learn how to use common layers to build a neural networks from scratch. We will also learn how to train the neural network using the `Pytorch` library and evaluate its performance.\n",
    "\n",
    "In Pytorch, we can organise those layers using containers. The most common one that we will use is the `torch.nn.Sequential` layer.\n",
    "\n",
    "In a sequential container, the modules (including activation functions and layers) will be added to it in the order they are passed. Alternatively, an ordered dictionary of modules can also be passed in.\n",
    "\n",
    "To make it easier to understand, here is a small example:\n",
    "\n",
    "Source: [Pytorch Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
    "\n",
    "```python\n",
    "\n",
    "# Import OrderedDict, which is in the standard collection library for python\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Import nn to use basic building blocks\n",
    "import torch.nn as nn\n",
    "\n",
    "# Example of using Sequential\n",
    "model = nn.Sequential(\n",
    "          nn.Conv2d(1,20,5), # This is a Convolutional Layer \n",
    "          nn.ReLU(),         # This is an activation function\n",
    "          nn.Conv2d(20,64,5),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "\n",
    "# Example of using Sequential with OrderedDict\n",
    "# This is equivalent to the first model\n",
    "model = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv2d(1,20,5)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv2d(20,64,5)),\n",
    "          ('relu2', nn.ReLU())\n",
    "        ]))\n",
    "```\n",
    "\n",
    "As you can notice from the examples, `nn` contains the basic building blocks for Neural Networks as well as activiation functions, loss functions and some other useful functions.\n",
    "\n",
    "## 1. Layers in Pytorch\n",
    "\n",
    "\n",
    "### 1.2 Linear (or Dense) Layer\n",
    "\n",
    "Fully connected neural networks (FCNNs) are a type of artificial neural network where  all the neurones, in one layer are connected to the neurones in the next layer. This type of layer is defined in Pytorch by [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear).\n",
    "\n",
    "### 1.3 Convolutional Neural Networks\n",
    "\n",
    "Convolutional layer\n",
    "The convolutional layer is the core building block of a CNN. The layer's parameters consist of a set of learnable filters (or kernels), which have a small receptive field, but extend through the full depth of the input volume. During the forward pass, each filter is convolved across the width and height of the input volume, computing the dot product between the entries of the filter and the input and producing a 2-dimensional activation map of that filter. As a result, the network learns filters that activate when it detects some specific type of feature at some spatial position in the input\n",
    "\n",
    "Source: [CNNs](https://en.wikipedia.org/wiki/Convolutional_neural_network)\n",
    "\n",
    "> In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to images. They have applications in image and video recognition, recommender systems, image classification, medical image analysis, natural language processing, and financial time series. <br/>\n",
    "CNNs are regularized versions of multilayer perceptrons. Multilayer perceptrons usually mean fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The \"fully-connectedness\" of these networks makes them prone to overfitting data. Typical ways of regularization include adding some form of magnitude measurement of weights to the loss function. CNNs take a different approach towards regularization: they take advantage of the hierarchical pattern in data and assemble more complex patterns using smaller and simpler patterns. Therefore, on the scale of connectedness and complexity, CNNs are on the lower extreme.\n",
    "\n",
    "<h4>Architecture in a CNN:</h4>\n",
    "\n",
    "> A convolutional neural network consists of an input and an output layer, as well as multiple hidden layers. The hidden layers of a CNN typically consist of a series of convolutional layers that convolve with a multiplication or other dot product. The activation function is commonly a RELU layer, and is subsequently followed by additional convolutions such as pooling layers, fully connected layers and normalization layers, referred to as hidden layers because their inputs and outputs are masked by the activation function and final convolution.\n",
    "\n",
    "<h4> CNN Layer: </h4>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"font-size:100%\">\n",
    "\n",
    "**NOTE:** <br>\n",
    "Use `nn.Conv2d` in Pytorch for 2d Convolutions.\n",
    "</div>\n",
    "\n",
    "> When programming a CNN, the input is a tensor with shape (number of images) x (image height) x (image width) x (image depth). Then after passing through a convolutional layer, the image becomes abstracted to a feature map, with shape (number of images) x (feature map height) x (feature map width) x (feature map channels). A convolutional layer within a neural network should have the following attributes:\n",
    "- Convolutional kernels defined by a width and height (hyper-parameters).\n",
    "- The number of input channels and output channels (hyper-parameter).\n",
    "- The depth of the Convolution filter (the input channels) must be equal to the number channels (depth) of the input feature map. <br>\n",
    "\n",
    "In a CNNs, feature maps are extracted and the they are downsampled until the last layer where it usually have fully connected layer. Look at the examples in the image below:\n",
    "\n",
    "[Source Image](https://en.wikipedia.org/wiki/Convolutional_neural_network#/media/File:Typical_cnn.png)\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png' width=800 height=300>\n",
    "\n",
    "\n",
    "> In neural networks, each neuron receives input from some number of locations in the previous layer. In a fully connected layer, each neuron receives input from every element of the previous layer. In a convolutional layer, neurons receive input from only a restricted subarea of the previous layer. Typically the subarea is of a square shape (e.g., size 5 by 5). The input area of a neuron is called its receptive field. So, in a fully connected layer, the receptive field is the entire previous layer. In a convolutional layer, the receptive area is smaller than the entire previous layer. The subarea of the original input image in the receptive field is increasingly growing as getting deeper in the network architecture. This is due to applying over and over again a convolution which takes into account the value of a specific pixel, but also some surrounding pixels.\n",
    "\n",
    "<h4> Pooling Layers</h4>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"font-size:100%\">\n",
    "\n",
    "**NOTE:** <br>\n",
    "Use `nn.maxpoo2d` in Pytorch for 2d Max Pooling.\n",
    "</div>\n",
    "\n",
    "> Another important concept of CNNs is pooling, which is a form of non-linear down-sampling. There are several non-linear functions to implement pooling among which max pooling is the most common. It partitions the input image into a set of non-overlapping rectangles and, for each such sub-region, outputs the maximum.\n",
    "\n",
    "The example below, shows Max pooling with a 2x2 filter and stride = 2. In every sub-region, the max value obtained.\n",
    "\n",
    "[Source Image](https://en.wikipedia.org/wiki/Convolutional_neural_network#/media/File:Max_pooling.png)\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png' width=400 heigh=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN implementation in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: https://dataunderground.org/dataset/landmass-f3\n",
    "\n",
    "Credits to researchers at Georgia Tech, Agile Geoscience\n",
    "License CCbySA\n",
    "\n",
    "In this notebook, we will be using the landmass dataset, which have been preprocessed already. In this dataset, we have images of 4 different types of landmass: 'Chaotic Horizon', 'Fault', 'Horizon', 'Salt Dome'.\n",
    "\n",
    "We will train a CNN to learn how to classify images into those 4 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:14.013499Z",
     "start_time": "2020-08-10T13:19:13.845904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset LandmassF3Patches\n",
      "    Number of datapoints: 13250\n",
      "    Root location: /home/wassname/notebooks/deep_ml_curriculum_private/data/processed/landmass-f3\n",
      "    Split: Train\n",
      "Dataset LandmassF3Patches\n",
      "    Number of datapoints: 4417\n",
      "    Root location: /home/wassname/notebooks/deep_ml_curriculum_private/data/processed/landmass-f3\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "# Let's import the Patches\n",
    "from deep_ml_curriculum.data.landmass_f3 import LandmassF3Patches\n",
    "from deep_ml_curriculum.config import project_dir\n",
    "\n",
    "landmassf3_train = LandmassF3Patches(project_dir / 'data/processed/landmass-f3', train=True)\n",
    "landmassf3_test = LandmassF3Patches(project_dir / 'data/processed/landmass-f3', train=False)\n",
    "print(landmassf3_train)\n",
    "print(landmassf3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:14.021834Z",
     "start_time": "2020-08-10T13:19:14.016965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13250, 99, 99])\n",
      "torch.Size([4417, 99, 99])\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look at the dataset\n",
    "print(landmassf3_train.data.shape)\n",
    "print(landmassf3_test.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:14.038491Z",
     "start_time": "2020-08-10T13:19:14.025220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deep_ml_curriculum.data.landmass_f3.LandmassF3Patches"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LandmassF3Patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, we have a total of 13250 gray-scale images of 99x99 pixels.\n",
    "\n",
    "Let's display the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:14.057520Z",
     "start_time": "2020-08-10T13:19:14.040964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Chaotic Horizon\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=99x99 at 0x7F0D49BEF4A8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=landmassf3_train[4]\n",
    "print('Class:', landmassf3_train.classes[y])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:14.071037Z",
     "start_time": "2020-08-10T13:19:14.065505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chaotic Horizon', 'Fault', 'Horizon', 'Salt Dome']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmassf3_train.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: [Neural Networks](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py)\n",
    "\n",
    "Now let's implement our first NN from scratch using Pytorch. A typical training procedure for a neural network is as follows:\n",
    "\n",
    "- Define the neural network that has some learnable parameters (or weights)\n",
    "- Iterate over a dataset of inputs\n",
    "- Process input through the network\n",
    "- Compute the loss (how far is the output from being correct)\n",
    "- Propagate gradients back into the networkâ€™s parameters\n",
    "- Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Create a python class with `nn.Module`\n",
    "2. Let's define two functions:\n",
    "   - The first one `__init__` also called contructor. Here we wil define the blocks that we will use.\n",
    "   - Define a `forward` function. In Pytorch, `forward` is a reserved name for a function that takes the input and returns and output. You can define the flow of the architecture here.\n",
    "   \n",
    "   \n",
    "<h3> Define the network</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:14.085884Z",
     "start_time": "2020-08-10T13:19:14.075234Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 23 * 23, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:14.103993Z",
     "start_time": "2020-08-10T13:19:14.089085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=8464, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of your network\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T07:44:29.932104Z",
     "start_time": "2020-08-07T07:44:29.927928Z"
    }
   },
   "source": [
    "Let's try a random 99x99 input. The input image to follow this convention:\n",
    "\n",
    "(N, C, W, H)\n",
    "- N: Number of images in the batch\n",
    "- C: Number of channels. Use 1 for grayscale or 3 for colored images (RGB)\n",
    "- W: Width\n",
    "- H: Height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:14.120374Z",
     "start_time": "2020-08-10T13:19:14.106214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0580,  0.0611,  0.0498, -0.0283]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(1,1,99,99)\n",
    "out = net(input)\n",
    "\n",
    "# An array with 4 output, each one corresponding to \n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T07:20:09.184731Z",
     "start_time": "2020-08-07T07:20:09.180677Z"
    }
   },
   "source": [
    "Now let's define a function for training our ConvNet.\n",
    "\n",
    "But first, we will define some hyperparameters:\n",
    "\n",
    "- `n_epochs`: is the number of iterations over all dataset\n",
    "- `learning_rate`: is the size of the steps in the optimization process.\n",
    "- `momentum`: helps accelerate gradients vectors in the right directions, thus leading to faster converging.\n",
    "- `bs`: batch size corresponds to the number of images evaluated at the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:14.134374Z",
     "start_time": "2020-08-10T13:19:14.123554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0d9c5c62d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's define some hyperparameter first\n",
    "n_epochs = 3         \n",
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "bs = 64\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define Optimizer. In this case, we will use Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "# Let's disable GPU for this example\n",
    "torch.backends.cudnn.enabled = False\n",
    "# For reproducibility\n",
    "torch.manual_seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:14.840598Z",
     "start_time": "2020-08-10T13:19:14.136831Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = landmassf3_train.data / 255.\n",
    "y_train = landmassf3_train.targets\n",
    "x_test = landmassf3_test.data / 255.\n",
    "y_test = landmassf3_test.targets\n",
    "n = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the function for training:\n",
    "\n",
    "[Source of code](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:14.853409Z",
     "start_time": "2020-08-10T13:19:14.843745Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, x, y, criterion, optimizer, n_epochs=1, bs=64):\n",
    "    # Set model in train mode\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range((x_train.shape[0] - 1) // bs + 1):\n",
    "            # Let's divide the data in batches\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            inputs = x_train[start_i:end_i].unsqueeze(1).float()\n",
    "            labels = y_train[start_i:end_i].long()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)              # Get the prediction here\n",
    "            loss = criterion(outputs, labels)  # Calculate loss\n",
    "            loss.backward()                    # Do backpropagation\n",
    "            optimizer.step()                   # Update weights\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:14.863188Z",
     "start_time": "2020-08-10T13:19:14.855634Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, x, y):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for idx, image in enumerate(x):\n",
    "        pred = model(image.unsqueeze(0).unsqueeze(0)).argmax()\n",
    "        if int(pred) == int(y[idx]):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    \n",
    "    print(correct, total)\n",
    "    accuracy = 100 * (correct/total)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:19:47.359156Z",
     "start_time": "2020-08-10T13:19:14.866135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.007\n",
      "[1,    20] loss: 0.007\n",
      "[1,    30] loss: 0.007\n",
      "[1,    40] loss: 0.007\n",
      "[1,    50] loss: 0.007\n",
      "[1,    60] loss: 0.007\n",
      "[1,    70] loss: 0.006\n",
      "[1,    80] loss: 0.006\n",
      "[1,    90] loss: 0.006\n",
      "[1,   100] loss: 0.006\n",
      "[1,   110] loss: 0.006\n",
      "[1,   120] loss: 0.006\n",
      "[1,   130] loss: 0.006\n",
      "[1,   140] loss: 0.006\n",
      "[1,   150] loss: 0.006\n",
      "[1,   160] loss: 0.006\n",
      "[1,   170] loss: 0.006\n",
      "[1,   180] loss: 0.006\n",
      "[1,   190] loss: 0.006\n",
      "[1,   200] loss: 0.006\n",
      "Finished Training\n",
      "2371 4417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53.678967625084894"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Optimizer. In this case, we will use Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "# Now let's train the model\n",
    "model = train(net, x_train, y_train, criterion, optimizer)\n",
    "test(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try again with 1 more epochs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:20:42.869696Z",
     "start_time": "2020-08-10T13:19:47.361299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.006\n",
      "[1,    20] loss: 0.006\n",
      "[1,    30] loss: 0.006\n",
      "[1,    40] loss: 0.006\n",
      "[1,    50] loss: 0.006\n",
      "[1,    60] loss: 0.006\n",
      "[1,    70] loss: 0.006\n",
      "[1,    80] loss: 0.006\n",
      "[1,    90] loss: 0.006\n",
      "[1,   100] loss: 0.006\n",
      "[1,   110] loss: 0.006\n",
      "[1,   120] loss: 0.006\n",
      "[1,   130] loss: 0.006\n",
      "[1,   140] loss: 0.006\n",
      "[1,   150] loss: 0.006\n",
      "[1,   160] loss: 0.006\n",
      "[1,   170] loss: 0.006\n",
      "[1,   180] loss: 0.006\n",
      "[1,   190] loss: 0.006\n",
      "[1,   200] loss: 0.006\n",
      "[2,    10] loss: 0.010\n",
      "[2,    20] loss: 0.006\n",
      "[2,    30] loss: 0.006\n",
      "[2,    40] loss: 0.006\n",
      "[2,    50] loss: 0.006\n",
      "[2,    60] loss: 0.006\n",
      "[2,    70] loss: 0.006\n",
      "[2,    80] loss: 0.006\n",
      "[2,    90] loss: 0.006\n",
      "[2,   100] loss: 0.006\n",
      "[2,   110] loss: 0.006\n",
      "[2,   120] loss: 0.006\n",
      "[2,   130] loss: 0.006\n",
      "[2,   140] loss: 0.006\n",
      "[2,   150] loss: 0.006\n",
      "[2,   160] loss: 0.006\n",
      "[2,   170] loss: 0.006\n",
      "[2,   180] loss: 0.006\n",
      "[2,   190] loss: 0.006\n",
      "[2,   200] loss: 0.006\n",
      "Finished Training\n",
      "Testing accuracy on unseen data...\n",
      "2371 4417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53.678967625084894"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = Net()\n",
    "# Define Optimizer. In this case, we will use Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(net2.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "model = train(net, x_train, y_train, criterion, optimizer, n_epochs=2)\n",
    "print('Testing accuracy on unseen data...')\n",
    "test(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:23:05.003235Z",
     "start_time": "2020-08-10T13:20:42.871694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.006\n",
      "[1,    20] loss: 0.006\n",
      "[1,    30] loss: 0.006\n",
      "[1,    40] loss: 0.006\n",
      "[1,    50] loss: 0.006\n",
      "[1,    60] loss: 0.006\n",
      "[1,    70] loss: 0.006\n",
      "[1,    80] loss: 0.006\n",
      "[1,    90] loss: 0.006\n",
      "[1,   100] loss: 0.006\n",
      "[1,   110] loss: 0.006\n",
      "[1,   120] loss: 0.006\n",
      "[1,   130] loss: 0.006\n",
      "[1,   140] loss: 0.006\n",
      "[1,   150] loss: 0.006\n",
      "[1,   160] loss: 0.006\n",
      "[1,   170] loss: 0.006\n",
      "[1,   180] loss: 0.006\n",
      "[1,   190] loss: 0.006\n",
      "[1,   200] loss: 0.006\n",
      "[2,    10] loss: 0.010\n",
      "[2,    20] loss: 0.006\n",
      "[2,    30] loss: 0.006\n",
      "[2,    40] loss: 0.006\n",
      "[2,    50] loss: 0.006\n",
      "[2,    60] loss: 0.006\n",
      "[2,    70] loss: 0.006\n",
      "[2,    80] loss: 0.006\n",
      "[2,    90] loss: 0.006\n",
      "[2,   100] loss: 0.006\n",
      "[2,   110] loss: 0.006\n",
      "[2,   120] loss: 0.006\n",
      "[2,   130] loss: 0.006\n",
      "[2,   140] loss: 0.006\n",
      "[2,   150] loss: 0.006\n",
      "[2,   160] loss: 0.006\n",
      "[2,   170] loss: 0.006\n",
      "[2,   180] loss: 0.006\n",
      "[2,   190] loss: 0.006\n",
      "[2,   200] loss: 0.006\n",
      "[3,    10] loss: 0.010\n",
      "[3,    20] loss: 0.006\n",
      "[3,    30] loss: 0.006\n",
      "[3,    40] loss: 0.006\n",
      "[3,    50] loss: 0.006\n",
      "[3,    60] loss: 0.006\n",
      "[3,    70] loss: 0.006\n",
      "[3,    80] loss: 0.006\n",
      "[3,    90] loss: 0.006\n",
      "[3,   100] loss: 0.006\n",
      "[3,   110] loss: 0.006\n",
      "[3,   120] loss: 0.006\n",
      "[3,   130] loss: 0.006\n",
      "[3,   140] loss: 0.006\n",
      "[3,   150] loss: 0.006\n",
      "[3,   160] loss: 0.006\n",
      "[3,   170] loss: 0.006\n",
      "[3,   180] loss: 0.006\n",
      "[3,   190] loss: 0.006\n",
      "[3,   200] loss: 0.006\n",
      "[4,    10] loss: 0.010\n",
      "[4,    20] loss: 0.006\n",
      "[4,    30] loss: 0.006\n",
      "[4,    40] loss: 0.006\n",
      "[4,    50] loss: 0.006\n",
      "[4,    60] loss: 0.006\n",
      "[4,    70] loss: 0.006\n",
      "[4,    80] loss: 0.006\n",
      "[4,    90] loss: 0.006\n",
      "[4,   100] loss: 0.006\n",
      "[4,   110] loss: 0.006\n",
      "[4,   120] loss: 0.006\n",
      "[4,   130] loss: 0.006\n",
      "[4,   140] loss: 0.006\n",
      "[4,   150] loss: 0.006\n",
      "[4,   160] loss: 0.006\n",
      "[4,   170] loss: 0.006\n",
      "[4,   180] loss: 0.006\n",
      "[4,   190] loss: 0.006\n",
      "[4,   200] loss: 0.006\n",
      "[5,    10] loss: 0.010\n",
      "[5,    20] loss: 0.006\n",
      "[5,    30] loss: 0.006\n",
      "[5,    40] loss: 0.006\n",
      "[5,    50] loss: 0.006\n",
      "[5,    60] loss: 0.006\n",
      "[5,    70] loss: 0.006\n",
      "[5,    80] loss: 0.006\n",
      "[5,    90] loss: 0.006\n",
      "[5,   100] loss: 0.006\n",
      "[5,   110] loss: 0.006\n",
      "[5,   120] loss: 0.006\n",
      "[5,   130] loss: 0.006\n",
      "[5,   140] loss: 0.006\n",
      "[5,   150] loss: 0.006\n",
      "[5,   160] loss: 0.006\n",
      "[5,   170] loss: 0.006\n",
      "[5,   180] loss: 0.006\n",
      "[5,   190] loss: 0.006\n",
      "[5,   200] loss: 0.006\n",
      "Finished Training\n",
      "Testing accuracy on unseen data...\n",
      "2371 4417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53.678967625084894"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = Net()\n",
    "# Define Optimizer. In this case, we will use Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(net2.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "model = train(net, x_train, y_train, criterion, optimizer, n_epochs=5)\n",
    "print('Testing accuracy on unseen data...')\n",
    "test(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained the same model using `SGD` for 1, 2, and 5 epochs. At some point, it seems like the model is not converging in it got stucked in a local minima. To improve the results we will tray a couple of things:\n",
    "\n",
    "1. Create a new model with `Batch Normalization`, it is often used in modern CNN architectures because it helps to create more general models (regularization) preventing overfitting.\n",
    "2. Change `SGD` for `Adam` optimizer. `Adam` is known to converge faster than `SGD`.\n",
    "3. We will train longer (more epochs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:23:05.037648Z",
     "start_time": "2020-08-10T13:23:05.006237Z"
    }
   },
   "outputs": [],
   "source": [
    "class BetterCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BetterCNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=128*10*10, out_features=512)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        #print(out.shape)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #print(out.shape)\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see first the results training the new model using only 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:28:41.263179Z",
     "start_time": "2020-08-10T13:23:05.075493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.066\n",
      "[1,    20] loss: 0.012\n",
      "[1,    30] loss: 0.003\n",
      "[1,    40] loss: 0.002\n",
      "[1,    50] loss: 0.001\n",
      "[1,    60] loss: 0.000\n",
      "[1,    70] loss: 0.001\n",
      "[1,    80] loss: 0.000\n",
      "[1,    90] loss: 0.000\n",
      "[1,   100] loss: 0.000\n",
      "[1,   110] loss: 0.000\n",
      "[1,   120] loss: 0.000\n",
      "[1,   130] loss: 0.000\n",
      "[1,   140] loss: 0.000\n",
      "[1,   150] loss: 0.000\n",
      "[1,   160] loss: 0.000\n",
      "[1,   170] loss: 0.000\n",
      "[1,   180] loss: 0.000\n",
      "[1,   190] loss: 0.000\n",
      "[1,   200] loss: 0.000\n",
      "Finished Training\n",
      "2151 4417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48.69821145573919"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnet = BetterCNN()\n",
    "optimizer = torch.optim.Adam(convnet.parameters(), lr=learning_rate)\n",
    "model = train(convnet, x_train, y_train, criterion, optimizer)\n",
    "test(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check the loss, we can notice that Adam is converging faster. However, the model is clearly underfitted. Let's train now the model for 10 epochs more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-10T14:17:48.165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.061\n",
      "[1,    20] loss: 0.011\n",
      "[1,    30] loss: 0.003\n",
      "[1,    40] loss: 0.001\n",
      "[1,    50] loss: 0.001\n",
      "[1,    60] loss: 0.000\n",
      "[1,    70] loss: 0.001\n",
      "[1,    80] loss: 0.000\n",
      "[1,    90] loss: 0.000\n",
      "[1,   100] loss: 0.000\n",
      "[1,   110] loss: 0.000\n",
      "[1,   120] loss: 0.000\n",
      "[1,   130] loss: 0.000\n",
      "[1,   140] loss: 0.000\n",
      "[1,   150] loss: 0.000\n",
      "[1,   160] loss: 0.000\n",
      "[1,   170] loss: 0.000\n",
      "[1,   180] loss: 0.000\n",
      "[1,   190] loss: 0.000\n",
      "[1,   200] loss: 0.000\n",
      "[2,    10] loss: 0.019\n",
      "[2,    20] loss: 0.003\n",
      "[2,    30] loss: 0.001\n",
      "[2,    40] loss: 0.000\n",
      "[2,    50] loss: 0.000\n",
      "[2,    60] loss: 0.000\n",
      "[2,    70] loss: 0.000\n",
      "[2,    80] loss: 0.000\n",
      "[2,    90] loss: 0.000\n",
      "[2,   100] loss: 0.000\n",
      "[2,   110] loss: 0.000\n",
      "[2,   120] loss: 0.000\n",
      "[2,   130] loss: 0.000\n",
      "[2,   140] loss: 0.000\n",
      "[2,   150] loss: 0.000\n",
      "[2,   160] loss: 0.000\n",
      "[2,   170] loss: 0.000\n",
      "[2,   180] loss: 0.000\n",
      "[2,   190] loss: 0.000\n",
      "[2,   200] loss: 0.000\n",
      "[3,    10] loss: 0.031\n",
      "[3,    20] loss: 0.006\n",
      "[3,    30] loss: 0.003\n",
      "[3,    40] loss: 0.001\n",
      "[3,    50] loss: 0.001\n",
      "[3,    60] loss: 0.001\n",
      "[3,    70] loss: 0.001\n",
      "[3,    80] loss: 0.001\n",
      "[3,    90] loss: 0.000\n",
      "[3,   100] loss: 0.000\n",
      "[3,   110] loss: 0.000\n",
      "[3,   120] loss: 0.000\n",
      "[3,   130] loss: 0.000\n",
      "[3,   140] loss: 0.000\n",
      "[3,   150] loss: 0.000\n",
      "[3,   160] loss: 0.000\n",
      "[3,   170] loss: 0.000\n",
      "[3,   180] loss: 0.000\n",
      "[3,   190] loss: 0.000\n",
      "[3,   200] loss: 0.000\n",
      "[4,    10] loss: 0.047\n",
      "[4,    20] loss: 0.006\n",
      "[4,    30] loss: 0.001\n",
      "[4,    40] loss: 0.001\n",
      "[4,    50] loss: 0.000\n",
      "[4,    60] loss: 0.000\n",
      "[4,    70] loss: 0.000\n",
      "[4,    80] loss: 0.000\n",
      "[4,    90] loss: 0.000\n",
      "[4,   100] loss: 0.000\n",
      "[4,   110] loss: 0.000\n",
      "[4,   120] loss: 0.000\n",
      "[4,   130] loss: 0.000\n",
      "[4,   140] loss: 0.000\n",
      "[4,   150] loss: 0.000\n",
      "[4,   160] loss: 0.000\n",
      "[4,   170] loss: 0.000\n",
      "[4,   180] loss: 0.000\n",
      "[4,   190] loss: 0.000\n",
      "[4,   200] loss: 0.000\n",
      "[5,    10] loss: 0.000\n",
      "[5,    20] loss: 0.000\n",
      "[5,    30] loss: 0.000\n",
      "[5,    40] loss: 0.000\n",
      "[5,    50] loss: 0.000\n",
      "[5,    60] loss: 0.000\n",
      "[5,    70] loss: 0.000\n",
      "[5,    80] loss: 0.000\n",
      "[5,    90] loss: 0.000\n",
      "[5,   100] loss: 0.000\n",
      "[5,   110] loss: 0.000\n",
      "[5,   120] loss: 0.000\n",
      "[5,   130] loss: 0.000\n",
      "[5,   140] loss: 0.000\n",
      "[5,   150] loss: 0.000\n",
      "[5,   160] loss: 0.000\n",
      "[5,   170] loss: 0.000\n",
      "[5,   180] loss: 0.000\n",
      "[5,   190] loss: 0.000\n",
      "[5,   200] loss: 0.000\n",
      "[6,    10] loss: 0.000\n",
      "[6,    20] loss: 0.000\n",
      "[6,    30] loss: 0.000\n",
      "[6,    40] loss: 0.000\n",
      "[6,    50] loss: 0.000\n",
      "[6,    60] loss: 0.000\n",
      "[6,    70] loss: 0.000\n",
      "[6,    80] loss: 0.000\n",
      "[6,    90] loss: 0.000\n",
      "[6,   100] loss: 0.000\n",
      "[6,   110] loss: 0.000\n",
      "[6,   120] loss: 0.000\n",
      "[6,   130] loss: 0.000\n",
      "[6,   140] loss: 0.000\n",
      "[6,   150] loss: 0.000\n",
      "[6,   160] loss: 0.000\n",
      "[6,   170] loss: 0.000\n",
      "[6,   180] loss: 0.000\n",
      "[6,   190] loss: 0.000\n",
      "[6,   200] loss: 0.000\n",
      "[7,    10] loss: 0.000\n",
      "[7,    20] loss: 0.000\n",
      "[7,    30] loss: 0.000\n",
      "[7,    40] loss: 0.000\n",
      "[7,    50] loss: 0.000\n",
      "[7,    60] loss: 0.000\n",
      "[7,    70] loss: 0.000\n",
      "[7,    80] loss: 0.000\n",
      "[7,    90] loss: 0.000\n",
      "[7,   100] loss: 0.000\n",
      "[7,   110] loss: 0.000\n",
      "[7,   120] loss: 0.000\n",
      "[7,   130] loss: 0.000\n",
      "[7,   140] loss: 0.000\n",
      "[7,   150] loss: 0.000\n",
      "[7,   160] loss: 0.000\n",
      "[7,   170] loss: 0.000\n",
      "[7,   180] loss: 0.000\n",
      "[7,   190] loss: 0.000\n",
      "[7,   200] loss: 0.000\n",
      "[8,    10] loss: 0.000\n",
      "[8,    20] loss: 0.000\n",
      "[8,    30] loss: 0.000\n",
      "[8,    40] loss: 0.000\n",
      "[8,    50] loss: 0.000\n",
      "[8,    60] loss: 0.000\n",
      "[8,    70] loss: 0.000\n",
      "[8,    80] loss: 0.000\n",
      "[8,    90] loss: 0.000\n",
      "[8,   100] loss: 0.000\n",
      "[8,   110] loss: 0.000\n",
      "[8,   120] loss: 0.000\n",
      "[8,   130] loss: 0.000\n",
      "[8,   140] loss: 0.000\n",
      "[8,   150] loss: 0.000\n",
      "[8,   160] loss: 0.000\n",
      "[8,   170] loss: 0.000\n",
      "[8,   180] loss: 0.000\n",
      "[8,   190] loss: 0.000\n",
      "[8,   200] loss: 0.000\n",
      "[9,    10] loss: 0.000\n",
      "[9,    20] loss: 0.000\n",
      "[9,    30] loss: 0.000\n",
      "[9,    40] loss: 0.000\n",
      "[9,    50] loss: 0.000\n",
      "[9,    60] loss: 0.000\n",
      "[9,    70] loss: 0.000\n",
      "[9,    80] loss: 0.000\n",
      "[9,    90] loss: 0.000\n",
      "[9,   100] loss: 0.000\n",
      "[9,   110] loss: 0.000\n",
      "[9,   120] loss: 0.000\n",
      "[9,   130] loss: 0.000\n",
      "[9,   140] loss: 0.000\n",
      "[9,   150] loss: 0.000\n",
      "[9,   160] loss: 0.000\n",
      "[9,   170] loss: 0.000\n",
      "[9,   180] loss: 0.000\n",
      "[9,   190] loss: 0.000\n",
      "[9,   200] loss: 0.000\n",
      "[10,    10] loss: 0.000\n",
      "[10,    20] loss: 0.000\n",
      "[10,    30] loss: 0.000\n",
      "[10,    40] loss: 0.000\n",
      "[10,    50] loss: 0.000\n",
      "[10,    60] loss: 0.000\n",
      "[10,    70] loss: 0.000\n",
      "[10,    80] loss: 0.000\n",
      "[10,    90] loss: 0.000\n",
      "[10,   100] loss: 0.000\n",
      "[10,   110] loss: 0.000\n",
      "[10,   120] loss: 0.000\n",
      "[10,   130] loss: 0.000\n",
      "[10,   140] loss: 0.000\n",
      "[10,   150] loss: 0.000\n",
      "[10,   160] loss: 0.000\n",
      "[10,   170] loss: 0.000\n",
      "[10,   180] loss: 0.000\n",
      "[10,   190] loss: 0.000\n",
      "[10,   200] loss: 0.000\n",
      "Finished Training\n",
      "4339 4417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.23409553995924"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "convnet2 = BetterCNN()\n",
    "optimizer = torch.optim.Adam(convnet2.parameters(), lr=learning_rate)\n",
    "model = train(convnet2, x_train, y_train, criterion, optimizer, n_epochs=10)\n",
    "test(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally ! After changing the optimizer, creating a better CNN architecture and train for a couple of epochs we got an accuracy of over 99% on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T13:28:41.326675Z",
     "start_time": "2020-08-10T13:28:41.268663Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now that we finished the training let's save our best model\n",
    "PATH = './landmass_net.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load a new model to check that the performance of the saved model.\n",
    "\n",
    "Check more information about how to save models in Pytorch [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and further reading\n",
    "\n",
    "[Artificial Neural Networks](https://en.wikipedia.org/wiki/Artificial_neural_network)\n",
    "\n",
    "[Pytorch](https://pytorch.org/)\n",
    "\n",
    "[Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
    "\n",
    "[Adam](https://arxiv.org/pdf/1412.6980.pdf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
